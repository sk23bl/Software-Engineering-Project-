Author,Prompt,Prompts
Tommie1236,"i want to make something that requires launching and managing a minecraft java server i have seen a bedrock server gui somewhere that did exactly what i wanted but it is a exe and the source code is not available i dont know when it released but maybe you have some info on it foxynotails mcbeplay
what i want to do is for a python script to launch the server and after that keep reading the output and be able to input to the same procces

how would i be able to do something like that",want make something requires launching managing minecraft java server . seen bedrock server gui somewhere exactly wanted .exe source code available . ( n't know released maybe info ( foxynotail 's mcbe-play ) ) want python script launch server keep reading output able input procces . would able something like ?
ariel1985,"I have a django and rasa application rasa is a moduleapp inside django 
I want to put the url for the rasa application somewhere where I can access it from anywhere in the django app 
How should I do that","django rasa application ( rasa module\app inside django ) , want put url rasa application somewhere access anywhere django app ?"
yuyu31,"web


 html  headerhtml
DOCTYPE html
html langja
head
    meta charsetUTF8
    link relstylesheet hrefcssmainstylecss
    link relstylesheet hrefcssheadercss
    meta nameviewport contentwidthdevicewidth initialscale10
    meta namegooglesiteverification contentysFG4KwAvFrSzk64WwAOpDuSu5cj8oLhYTS4GXqk  Google Search Console
    titletitle
head
body
header
    div classtitle
        a hrefindexhtmlimg srclastedsmalllogojpg alta
        h1a hrefindexhtmlabrh1

        button typebutton classbtn jsbtn
            span classbtnlinespan
        button

        nav
            ul classcontainer 
                lia hrefindexhtmlali
                lia hrefkatsudorinenhtmlali
                lia hrefsyakaitekiigihtmlali
                lia hrefcontentsmenuhtmlali
                lia hrefmemberintrohtmlali
                lia hrefhowtoenterhtmlali
            ul
        nav
        div classhamburger9776div
    div

    script srcscriptjsscript
header
body
html

 css  headercss

css
before  after 
	boxsizing inherit

button 
	margin 0
	padding 0
	outline 0
	border 0
	borderradius 0
	background transparent
	color inherit
	verticalalign middle
	textalign inherit
	font inherit
	webkitappearance none
	appearance none




media only screen and minwidth 767px 
     600px 
    hamburger 
      display none
    
  
  
    
  hamburger 
    position fixed
    top 20px
    right 20px
    fontsize 24px
    cursor pointer
  
  
    
  container 
    display none
    position fixed
    top 70px
    right 20px
    backgroundcolor f9f9f9
    padding 10px
    border 1px solid ddd
  
  
  container li 
    marginbottom 10px
  
  
  container li a 
    color 333
    textdecoration none
  
  
   js 
  containeractive 
    display block
  

  container
container
	fontsize 20px
	display flex
	margintop 20px
	margin 0
	padding 0
	liststyle none
	marginleft auto
  
  
  container li container
	display inlineblock
	margin 0 20px 0 0
	padding 0 10px 2
	marginleft 20px
  
  
  media screen and maxwidth 767px 
	container li
	  display inlineblock
	  writingmode verticalrl 
	  margin 0px
	  padding 0px
	
  

 JavaScript  scriptjs

documentaddEventListenerDOMContentLoaded function  
    const hamburger  documentquerySelectorhamburger
    const menu  documentquerySelectorcontainer

    hamburgeraddEventListenerclick function  
        menuclassListtogglecontaineractive
    

","あなたはwebデザイナーです。ハンバーガーメニューを実装したところ、初めからメニューの内容が表示されていて、表示非表示を切り替えられません。 以下のようなコードを用意しているとき、どのような修正が考えられますか。 # html ファイル `` header.html '' < ! DOCTYPE html > < html lang= '' ja '' > < head > < meta charset= '' UTF-8 '' > < link rel= '' stylesheet '' href= '' /css/mainstyle.css '' > < link rel= '' stylesheet '' href= '' /css/header.css '' > < meta name= '' viewport '' content= '' width=device-width , initial-scale=1.0 '' > < meta name= '' google-site-verification '' content= '' ysFG4KwAvFr_Szk64WwAOpDuSu5cj8oLhY_TS4G-Xqk '' / > < ! -- Google Search Console -- > < title > 楽習隊（がくしゅうたい） < /title > < /head > < body > < header > < div class= '' title '' > < href= '' /index.html '' > < img src= '' /lasted_smalllogo.jpg '' alt= '' 楽習隊 '' > < /a > < h1 > < href= '' /index.html '' > 楽習隊 < /a > < ! -- < br > エンタメを学問する -- > < /h1 > < button type= '' button '' class= '' btn js-btn '' > < span class= '' btn-line '' > < /span > < /button > < nav > < ul class= '' container '' > < ! -- バナー表示。全部横並びでスクロールさせたい。 -- > < li > < href= '' /index.html '' > ホーム < /a > < /li > < li > < href= '' /katsudo_rinen.html '' > 活動理念 < /a > < /li > < li > < href= '' /syakaiteki_igi.html '' > 社会的意義 < /a > < /li > < li > < href= '' /contents/menu.html '' > 楽習コンテンツ < /a > < /li > < li > < href= '' /member_intro.html '' > 隊員紹介 < /a > < /li > < li > < href= '' /howtoenter.html '' > 入隊方法 < /a > < /li > < /ul > < /nav > < div class= '' hamburger '' > & # 9776 ; < /div > < /div > < script src= '' script.js '' > < /script > < /header > < /body > < /html > # css ファイル `` header.css '' / * デフォルトcss * / : :before , : :after { box-sizing : inherit ; } button { margin : 0 ; padding : 0 ; outline : 0 ; border : 0 ; border-radius : 0 ; background : transparent ; color : inherit ; vertical-align : middle ; text-align : inherit ; font : inherit ; -webkit-appearance : none ; appearance : none ; } @ media screen ( min-width : 767px ) { / * 600px以上の画面サイズではハンバーガーメニューを非表示にする * / .hamburger { display : none ; } } / * ハンバーガーメニューのスタイル * / .hamburger { position : fixed ; top : 20px ; right : 20px ; font-size : 24px ; cursor : pointer ; } / * メニューのスタイル * / .container { display : none ; position : fixed ; top : 70px ; right : 20px ; background-color : # f9f9f9 ; padding : 10px ; border : 1px solid # ddd ; } .container li { margin-bottom : 10px ; } .container li { color : # 333 ; text-decoration : none ; } / * メニューを表示するクラスを追加した際にメニューを表示する ( js用 ) * / .container-active { display : block ; } / * container全体にかかる * / .container { font-size : 20px ; display : flex ; margin-top : 20px ; margin : 0 ; padding : 0 ; list-style : none ; margin-left : auto ; } .container li { / * containerのそれぞれにかかる * / display : inline-block ; margin : 0 20px 0 0 ; padding : 0 10px ; / * 2つ目の値で要素の間隔を規定 * / margin-left : 20px ; } @ media screen ( max-width : 767px ) { .container li { display : inline-block ; writing-mode : vertical-rl ; / * 縦書き * / margin : 0px ; padding : 0px ; } } # JavaScript ファイル `` script.js '' document.addEventListener ( `` DOMContentLoaded '' , function ( ) { const hamburger = document.querySelector ( `` .hamburger '' ) ; const menu = document.querySelector ( `` .container '' ) ; hamburger.addEventListener ( `` click '' , function ( ) { menu.classList.toggle ( `` container-active '' ) ; } ) ; } ) ;"
jabrena,How to add a java class in a generic container from testcontainers in order to run later,add java class generic container testcontainers order run later
purpleslurple,Can I use local storage in the browser to store the url of the page Im viewing ,use local storage browser store url page ’ viewing
byronwall,"I have a nice table describing a curriculum for teaching blends in a phonics settings  Can you create the same detailed tabled for Double consonants  Output a table that is as complete and detailed as possible  Do not skip details  Only include the columns below

Weeks	Topic	SubTopic	Sample Words
1	LBlends	bl	black blue blow blend blink block bluff blunder
1	LBlends	cl	clock clap clean cliff clone clash clover clump
1	LBlends	fl	flag flip flow flame flat flock flash flinch
1	LBlends	gl	glass glow glue glint glide glaze glory glisten","nice table describing curriculum teaching blends phonics settings . create detailed tabled `` Double consonants '' ? Output table complete detailed possible . skip details . include columns -- - Week ( ) Topic Sub-Topic Sample Words 1 L-Blends bl black , blue , blow , blend , blink , block , bluff , blunder 1 L-Blends cl clock , clap , clean , cliff , clone , clash , clover , clump 1 L-Blends fl flag , flip , flow , flame , flat , flock , flash , flinch 1 L-Blends gl glass , glow , glue , glint , glide , glaze , glory , glisten"
DovieW,using the autoindex directive in nginx is there any way to chose how the files should be sorted,"using autoindex directive nginx , way chose files sorted ?"
DovieW,"const fs  requirefs
const multer  requiremulter
const puppeteer  requirepuppeteer
const express  requireexpress
const app  express
const port  3001
const path  requirepath
const storage  multerdiskStorage
  destination functionreq file cb 
    cbnull uploads
  
  filename functionreq file cb 
    const date  new Date
    const formattedDate  dategetFullYeardategetMonth  1dategetDatedategetHoursdategetMinutesdategetSeconds
    const fileName  formattedDatefileoriginalname
    cbnull fileName
  

const upload  multer storage storage 
const serveIndex  requireserveindex

 appusegenerated expressstaticpathjoindirname generated serveIndexpathjoindirname generated icons true
 appuseuploads expressstaticpathjoindirname uploads serveIndexpathjoindirname uploads icons true

apppostapiupload uploadsinglefile req res  
  const bookName fontSize papersCount  reqquery

  const date  new Date
  const id  dategetFullYeardategetMonth  1dategetDatedategetHoursdategetMinutesdategetSecondsbookNamefontSize

  function writeToInProgresstext 
    consolelogtext
    const inProgressPath  pathjoindirname generated INPROGRESSidtxt
    fswriteFileSyncinProgressPath text
  

  setImmediateasync   
    try 
      await runreq id bookName fontSize
     catch error 
      consoleerrorerror
      writeToInProgressERROR   errortoString
    
  

  async function runreq id bookName fontSize 
    const browser  await puppeteerlaunch
      protocolTimeout 1000000
    
    const page  await browsernewPage
    const inProgressPath  pathjoindirname generated INPROGRESSidtxt

    pageonconsole pageIndex  
      writeToInProgressCreating sheet pageIndextext  2 of papersCountish
    

     await pagesetViewport width 816 height 1056 

    let text  fsreadFileSyncreqfilepath utf8
    
    await pagegotofiledirnamepagehtml
    
    await pageaddStyleTagcontent body  fontsize fontSizepx 

    writeToInProgressCreating bookName

    await pageevaluatetext bookName  
      let pageIndex  0
      let isCurrentPageFront  true  tracks whether the next page to be rendered is on the front of the double sided sheet the side with the big header

      function createNewPagewordsLeft 
        consolelogpageIndex1
        const page  documentcreateElementdiv
        pageclassName  page

         create grid cells
        const grid  documentcreateElementdiv
        gridclassName  gridcontainer
        for let i  0 i  16 i 
          const gridItem  documentcreateElementdiv
          gridItemclassName  griditem

           Determine padding classes for Improved Padding
          let paddingClass  
           Rows
          if i  4   Row 1 bottom padding
            paddingClass  padbottom 
           else if i  4  i  12   Rows 2 and 3 top and bottom padding
            paddingClass  padtop padbottom 
           else   Row 4 top padding
            paddingClass  padtop 
          
           Columns
          if i  4  1   Second cell from the left in each row right padding for crease
            paddingClass  padright
           else if i  4  2   Third cell from the left in each row left padding for crease
            paddingClass  padleft
          
          gridItemclassName   paddingClass

          if i  0  isCurrentPageFront  
            gridItemid  header  pageIndex
           else if i  4  0   if its the first cell in a row
            const miniSheetNum  documentcreateElementspan
            miniSheetNumclassListaddminiSheetNum  pageIndex
            miniSheetNumclassListaddminiSheetNum
            miniSheetNumtextContent  0000
            gridItemappendChildminiSheetNum
          
          gridappendChildgridItem
        

        pageappendChildgrid
        documentbodyappendChildpage

        if isCurrentPageFront 
          isCurrentPageFront  false
          const header  documentcreateElementdiv
          const sheetNum  documentcreateElementh3
          const title  documentcreateElementh3
          
          headerclassName  header
          sheetNumtextContent  0000
          sheetNumid  sheetNum  pageIndex
          if bookName titletextContent      bookName

          headerappendChildsheetNum
          headerappendChildtitle

          const wordCountEl  documentcreateElementh4
          wordCountEltextContent      IntlNumberFormatformatwordsLeft   words 
          headerappendChildwordCountEl

          documentquerySelectorheader  pageIndexappendChildheader
         else 
          isCurrentPageFront  true
        
        
        blocks  ArrayfromdocumentquerySelectorAllgriditem

        pageIndex
      

       Populate grid items
      const words  textsplit 
      let blocks  
      createNewPagewordslength
      let currentBlockIndex  0
      let currentBlock
      let wordsInBlock  
      currentBlock  blockscurrentBlockIndex
      for let i  0 i  wordslength i 
        currentBlockinnerHTML     wordsi

         If the word made the block overflow remove it from the block
        if currentBlockscrollHeight  currentBlockclientHeight 
          currentBlockinnerHTML  currentBlockinnerHTMLslice0 currentBlockinnerHTMLlength  wordsilength

           Move to the next block
          currentBlockIndex
          if currentBlockIndex  blockslength 
            createNewPagewordslength  i  Create a new page if all blocks are filled
            currentBlockIndex  blockslength  16  Reset the block index to the first block of the new page
          
          currentBlock  blockscurrentBlockIndex
          currentBlockinnerHTML     wordsi  Add the word to the new block
        
      

       Populate headers
      const SHEETSAMOUNT  MathceilpageIndex  2
      isCurrentPageFront  true
      for let i  0 i  pageIndex i 
        const SHEETNUM  Mathceili1  2SHEETSAMOUNT
        let miniSheetNums  documentquerySelectorAllminiSheetNum  i

        forlet i  0 i  miniSheetNumslength i 
          miniSheetNumsitextContent  SHEETNUM
        

        if isCurrentPageFront 
          isCurrentPageFront  false
          documentquerySelectorsheetNum  itextContent  SHEETNUM
         else 
          isCurrentPageFront  true
        
      

       remove empty grid items on final page
      const allGridItems  documentquerySelectorAllgriditem
      const last16GridItems  ArrayfromallGridItemsslice15
      last16GridItemsforEachblock index  
        const cloneBlock  blockcloneNodetrue
        const spanElement  cloneBlockquerySelectorminiSheetNum
        if spanElement 
          spanElementremove
        
        if cloneBlocktextContenttrim   
          blockremove
        
      
     text bookName

    writeToInProgressFinished creating pages Writing to file

    let htmlContent  await pagecontent
    const pageHtml  pathjoindirname pageHtmlhtml
    fswriteFileSyncpageHtml htmlContent

    const pdf  await pagepdf format Letter 
    const pdfOutput  pathjoindirname generated idpdf
    fswriteFileSyncpdfOutput pdf

    await browserclose

     Delete the INPROGRESS file after PDF is created
    if fsexistsSyncinProgressPath 
      fsunlinkSyncinProgressPath
    
  
  
  resjson message PDF creation started id 


appgetapidownload req res  
  const  id   reqquery
  const pdfOutput  pathjoindirname generated idpdf
  const inProgressPath  pathjoindirname generated INPROGRESSidtxt

  if fsexistsSyncpdfOutput 
    resredirectgeneratedidpdf
   else if fsexistsSyncinProgressPath 
    ressendfsreadFileSyncinProgressPath utf8
   else 
    return ressendNot started Its either in the queue or failed entirely
  


applistenport   
  consolelogListening on port port



how could i improve the readability of this what can be moved to different files for example and how","const fs = require ( 'fs ' ) ; const multer = require ( 'multer ' ) ; const puppeteer = require ( 'puppeteer ' ) ; const express = require ( 'express ' ) ; const app = express ( ) ; const port = 3001 ; const path = require ( 'path ' ) ; const storage = multer.diskStorage ( { destination : function ( req , file , cb ) { cb ( null , 'uploads/ ' ) } , filename : function ( req , file , cb ) { const date = new Date ( ) ; const formattedDate = ` $ { date.getFullYear ( ) } $ { date.getMonth ( ) + 1 } $ { date.getDate ( ) } $ { date.getHours ( ) } $ { date.getMinutes ( ) } $ { date.getSeconds ( ) } ` ; const fileName = ` $ { formattedDate } _ $ { file.originalname } ` ; cb ( null , fileName ) ; } } ) ; const upload = multer ( { storage : storage } ) ; const serveIndex = require ( 'serve-index ' ) ; // app.use ( '/generated ' , express.static ( path.join ( __dirname , 'generated ' ) ) , serveIndex ( path.join ( __dirname , 'generated ' ) , { 'icons ' : true } ) ) ; // app.use ( '/uploads ' , express.static ( path.join ( __dirname , 'uploads ' ) ) , serveIndex ( path.join ( __dirname , 'uploads ' ) , { 'icons ' : true } ) ) ; app.post ( '/api/upload ' , upload.single ( 'file ' ) , ( req , res ) = > { const { bookName , fontSize , papersCount } = req.query ; const date = new Date ( ) ; const id = ` $ { date.getFullYear ( ) } $ { date.getMonth ( ) + 1 } $ { date.getDate ( ) } $ { date.getHours ( ) } $ { date.getMinutes ( ) } $ { date.getSeconds ( ) } _ $ { bookName } _ $ { fontSize } ` ; function writeToInProgress ( text ) { console.log ( ` $ { text } ` ) ; const inProgressPath = path.join ( __dirname , 'generated ' , ` IN_PROGRESS_ $ { id } .txt ` ) ; fs.writeFileSync ( inProgressPath , text ) ; } setImmediate ( async ( ) = > { try { await run ( req , id , bookName , fontSize ) ; } catch ( error ) { console.error ( error ) ; writeToInProgress ( 'ERROR : ' + error.toString ( ) ) ; } } ) ; async function run ( req , id , bookName , fontSize ) { const browser = await puppeteer.launch ( { protocolTimeout : 1000000 } ) ; const page = await browser.newPage ( ) ; const inProgressPath = path.join ( __dirname , 'generated ' , ` IN_PROGRESS_ $ { id } .txt ` ) ; page.on ( 'console ' , pageIndex = > { writeToInProgress ( ` Creating sheet $ { pageIndex.text ( ) / 2 } $ { papersCount } -ish. ` ) ; } ) ; // await page.setViewport ( { width : 816 , height : 1056 } ) ; let text = fs.readFileSync ( req.file.path , 'utf8 ' ) ; await page.goto ( ` file : // $ { __dirname } /page.html ` ) ; await page.addStyleTag ( { content : ` body { font-size : $ { fontSize } px ; } ` } ) ; writeToInProgress ( ` Creating : $ { bookName } ` ) ; await page.evaluate ( ( text , bookName ) = > { let pageIndex = 0 ; let isCurrentPageFront = true ; // tracks whether next page rendered front double sided sheet . side big header function createNewPage ( wordsLeft ) { console.log ( pageIndex+1 ) ; const page = document.createElement ( 'div ' ) ; page.className = 'page ' ; // create grid cells const grid = document.createElement ( 'div ' ) ; grid.className = 'grid-container ' ; ( let = 0 ; < 16 ; i++ ) { const gridItem = document.createElement ( 'div ' ) ; gridItem.className = 'grid-item ' ; // Determine padding classes Improved Padding let paddingClass = `` ; // Rows ( < 4 ) { // Row 1 ( bottom padding ) paddingClass += 'pad-bottom ' ; } else ( > = 4 & & < 12 ) { // Rows 2 3 ( top bottom padding ) paddingClass += 'pad-top pad-bottom ' ; } else { // Row 4 ( top padding ) paddingClass += 'pad-top ' ; } // Columns ( % 4 === 1 ) { // Second cell left row , right padding crease paddingClass += 'pad-right ' ; } else ( % 4 === 2 ) { // Third cell left row , left padding crease paddingClass += 'pad-left ' ; } gridItem.className += ` $ { paddingClass } ` ; ( === 0 & & isCurrentPageFront ) { gridItem.id = 'header ' + pageIndex ; } else ( % 4 === 0 ) { // 's first cell row const miniSheetNum = document.createElement ( 'span ' ) ; miniSheetNum.classList.add ( 'miniSheetNum ' + pageIndex ) ; miniSheetNum.classList.add ( 'miniSheetNum ' ) ; miniSheetNum.textContent = '00/00 ' ; gridItem.appendChild ( miniSheetNum ) ; } grid.appendChild ( gridItem ) ; } page.appendChild ( grid ) ; document.body.appendChild ( page ) ; ( isCurrentPageFront ) { isCurrentPageFront = false ; const header = document.createElement ( 'div ' ) ; const sheetNum = document.createElement ( 'h3 ' ) ; const title = document.createElement ( 'h3 ' ) ; header.className = 'header ' ; sheetNum.textContent = '00/00 ' ; sheetNum.id = 'sheetNum ' + pageIndex ; ( bookName ) title.textContent = ' - ' + bookName ; header.appendChild ( sheetNum ) ; header.appendChild ( title ) ; const wordCountEl = document.createElement ( 'h4 ' ) ; wordCountEl.textContent = ' [ ' + Intl.NumberFormat ( ) .format ( wordsLeft ) + ' words ] ' ; header.appendChild ( wordCountEl ) ; document.querySelector ( ' # header ' + pageIndex ) .appendChild ( header ) ; } else { isCurrentPageFront = true ; } blocks = Array.from ( document.querySelectorAll ( '.grid-item ' ) ) ; pageIndex++ ; } // Populate grid items const words = text.split ( ' ' ) ; let blocks = [ ] ; createNewPage ( words.length ) ; let currentBlockIndex = 0 ; let currentBlock ; let wordsInBlock = [ ] ; currentBlock = blocks [ currentBlockIndex ] ; ( let = 0 ; < words.length ; i++ ) { currentBlock.innerHTML += ' ' + words [ ] ; // word made block overflow , remove block ( currentBlock.scrollHeight > currentBlock.clientHeight ) { currentBlock.innerHTML = currentBlock.innerHTML.slice ( 0 , currentBlock.innerHTML.length - words [ ] .length ) ; // Move next block currentBlockIndex++ ; ( currentBlockIndex > = blocks.length ) { createNewPage ( words.length - ) ; // Create new page blocks filled currentBlockIndex = blocks.length - 16 ; // Reset block index first block new page } currentBlock = blocks [ currentBlockIndex ] ; currentBlock.innerHTML += ' ' + words [ ] ; // Add word new block } } // Populate headers const SHEETS_AMOUNT = Math.ceil ( pageIndex / 2 ) ; isCurrentPageFront = true ; ( let = 0 ; < pageIndex ; i++ ) { const SHEET_NUM = ` $ { Math.ceil ( ( i+1 ) / 2 ) } / $ { SHEETS_AMOUNT } ` ; let miniSheetNums = document.querySelectorAll ( '.miniSheetNum ' + ) ; ( let = 0 ; < miniSheetNums.length ; i++ ) { miniSheetNums [ ] .textContent = SHEET_NUM ; } ( isCurrentPageFront ) { isCurrentPageFront = false ; document.querySelector ( ' # sheetNum ' + ) .textContent = SHEET_NUM ; } else { isCurrentPageFront = true ; } } // remove empty grid items final page const allGridItems = document.querySelectorAll ( '.grid-item ' ) ; const last16GridItems = Array.from ( allGridItems ) .slice ( -15 ) ; last16GridItems.forEach ( ( block , index ) = > { const cloneBlock = block.cloneNode ( true ) ; const spanElement = cloneBlock.querySelector ( '.miniSheetNum ' ) ; ( spanElement ) { spanElement.remove ( ) ; } ( cloneBlock.textContent.trim ( ) === `` ) { block.remove ( ) ; } } ) ; } , text , bookName ) ; writeToInProgress ( 'Finished creating pages . Writing file ... ' ) ; let htmlContent = await page.content ( ) ; const pageHtml = path.join ( __dirname , ` pageHtml.html ` ) ; fs.writeFileSync ( pageHtml , htmlContent ) ; const pdf = await page.pdf ( { format : 'Letter ' } ) ; const pdfOutput = path.join ( __dirname , 'generated ' , ` $ { id } .pdf ` ) ; fs.writeFileSync ( pdfOutput , pdf ) ; await browser.close ( ) ; // Delete IN_PROGRESS file PDF created ( fs.existsSync ( inProgressPath ) ) { fs.unlinkSync ( inProgressPath ) ; } } res.json ( { message : 'PDF creation started . ' , id } ) ; } ) ; app.get ( '/api/download/ ' , ( req , res ) = > { const { id } = req.query ; const pdfOutput = path.join ( __dirname , 'generated ' , ` $ { id } .pdf ` ) ; const inProgressPath = path.join ( __dirname , 'generated ' , ` IN_PROGRESS_ $ { id } .txt ` ) ; ( fs.existsSync ( pdfOutput ) ) { res.redirect ( ` /generated/ $ { id } .pdf ` ) ; } else ( fs.existsSync ( inProgressPath ) ) { res.send ( fs.readFileSync ( inProgressPath , 'utf8 ' ) ) ; } else { return res.send ( 'Not started . It\ 's either queue , failed entirely . ' ) ; } } ) ; app.listen ( port , ( ) = > { console.log ( ` Listening port $ { port } ` ) ; } ) ; could improve readability ? moved different files example"
aretrace,Show a concrete example of Segmentation with Paging translating a logical addresses of the form s p w into corresponding physical addresses f w,"Show concrete example Segmentation Paging translating logical addresses form ( , p , w ) corresponding physical addresses ( f , w )"
harupy,"diagnose the following issue


 System information

 OS Platform and Distribution eg Linux Ubuntu 1604
 MLflow installed from source or binary
 MLflow version run mlflow version 260
 Python version


 Code to reproduce issue

Hi Team

I am trying to install mlflow application using latest version ie v260 in our kubernetes cluster but mlflow becomes inaccessible

First I have created Dockerfile and below is the code

FROM ghcriomlflowmlflowv260

RUN aptget update  aptget install y procps  rm rf varlibaptlists
RUN pip install PyMySQL

After this I have build this docker file and created a custom image ie v267

Post that I have created helm chart where I am using above custom image Below is the code for Deploymentyaml  secretsyaml and serviceyaml

Deploymentyaml

   artifactCommandPrefix  defaultartifactroot 
 artifactCommand  printf smlruns artifactCommandPrefix 

 if ValuesartifactRootproxiedArtifactStorage 
   artifactCommandPrefix  artifactsdestination 
   artifactCommand  printf smlartifacts artifactCommandPrefix 
 end 

 if ValuesartifactRoots3enabled 
   artifactCommand  printf ss3ss artifactCommandPrefix ValuesartifactRoots3path ValuesartifactRoots3bucket 
 end 

 dbConnectionDriver   
 if and ValuesbackendStoremysqlenabled ValuesbackendStoremysqldriver 
   dbConnectionDriver  printf s ValuesbackendStoremysqldriver 
 end 
apiVersion appsv1
kind Deployment
metadata
  name  include mlflowfullname  
  namespace  Valuesk8sNamespace 
  labels
     include mlflowlabels   nindent 4 
spec
  replicas  ValuesreplicaCount 
  selector
    matchLabels
       include mlflowselectorLabels   nindent 6 
  template
    metadata
       with ValuespodAnnotations 
      annotations
         toYaml   nindent 8 
       end 
      labels
         include mlflowselectorLabels   nindent 8 
    spec
      imagePullSecrets
         name  include mlflowdockerlogincred  
      serviceAccountName  include mlflowserviceAccountName  
      securityContext
         toYaml ValuespodSecurityContext  nindent 8 
      containers
         name  ChartName 
          securityContext
             toYaml ValuessecurityContext  nindent 12 
          image  Valuesdockerimage  Valuesdockertag 
          imagePullPolicy  ValuesdockerpullPolicy 
          command mlflow
          args
             server
             host0000
             port Valuesserviceport 
             backendstoreurimysql dbConnectionDriver MYSQLUSERNAMEMYSQLPWDMYSQLHOSTMYSQLTCPPORTMYSQLDATABASE
             gunicornoptsloglevel warning
              artifactCommand 
           if ValuesartifactRootproxiedArtifactStorage 
             serveartifacts
           end 
           if ValuesserviceMonitorenabled 
             exposeprometheusmlflowmetrics
           end 
          ports
             name  Valuesservicename 
              containerPort  Valuesserviceport 
              protocol TCP
           livenessProbe
             httpGet
               path 
               port  Valuesserviceport 
            with ValueslivenessProbe 
              toYaml   nindent 12 
            end 
           readinessProbe
             httpGet
               path 
               port  Valuesserviceport 
            with ValuesreadinessProbe 
              toYaml   nindent 12 
            end 
          resources
             toYaml Valuesresources  nindent 12 
          env
             name MLFLOWVERSION
              value 260
           range key value  ValuesextraEnvVars 
             name  upper key 
              value  value  quote 
           end 
          envFrom
             configMapRef
                name  template mlflowfullname  envconfigmap
             secretRef
                name  template mlflowfullname  envsecret
           range ValuesextraSecretNamesForEnvFrom 
             secretRef
                name   
           end 
           with ValuesextraVolumeMounts 
          volumeMounts
             toYaml   nindent 12 
           end 
       with ValuesextraContainers 
         toYaml   nindent 8 
       end 
       with ValuesnodeSelector 
      nodeSelector
         toYaml   nindent 8 
       end 
       with Valuesaffinity 
      affinity
         toYaml   nindent 8 
       end 
       with Valuestolerations 
      tolerations
         toYaml   nindent 8 
       end 
       if or and ValuesbackendStoremysqlenabled or ValuesbackendStoredatabaseConnectionCheck ValuesbackendStoredatabaseMigration  ValuesextraVolumes 
      volumes
         if and ValuesbackendStoremysqlenabled ValuesbackendStoredatabaseConnectionCheck 
         name dbchecker
          configMap
            name  template mlflowfullname  dbchecker
            defaultMode 0777
         end 
         if and ValuesbackendStoremysqlenabled ValuesbackendStoredatabaseMigration 
         name migrationsconfig
          configMap
            name  template mlflowfullname  migrations
         end 
       with ValuesextraVolumes 
         toYaml   nindent 8 
       end 
       end 


serviceyaml

apiVersion v1
kind Service
metadata
  name  include mlflowfullname  
  namespace  Valuesk8sNamespace 
  labels
     include mlflowlabels   nindent 4 
   with Valuesserviceannotations 
  annotations
     toYaml   nindent 4 
   end 
spec
  type  Valuesservicetype 
  ports
     port  Valuesserviceport 
      targetPort  ValuesservicetargetPort 
      protocol TCP
      name  Valuesservicename 
  selector
     include mlflowselectorLabels   nindent 4 



secretsyaml

apiVersion v1
kind Secret
metadata
  name  template mlflowfullname  envsecret
  namespace  Valuesk8sNamespace 
  labels
    app  template mlflowname  
    chart  template mlflowchart  
    release  ReleaseName 
    heritage  ReleaseService 
type Opaque
data
  ARTIFACTORYAPIKEY  Valuesartifactoryapikey  quote  b64enc
  MYSQLUSERNAME  required mysql user must be specified ValuesbackendStoremysqluser  b64enc 
  MYSQLPWD  required mysql password must be specified ValuesbackendStoremysqlpassword  b64enc 
  MINIOACCESSKEY  ValuesartifactRoots3AccessKeyId  b64enc 
  MINIOSECRETKEY  ValuesartifactRoots3SecretAccessKey  b64enc 

valuesyaml


replicaCount 1
docker
  image XXXXcorpxxxxcomXXXXXXdockermlflow
  pullPolicy Always
  tag v267

imagePullSecrets 

k8sNamespace autxxxxx

nameOverride 

fullnameOverride mlflow

imageCredentials
    registry xxxxxcorpxxxxcom
    username servicexxxx
    password xxxxxxxxxx

artifactory
    apikey xxxxxxx

serviceAccount
  create true
  annotations 
  name mlflow

podAnnotations 

podSecurityContext 

securityContext 

service
  type ClusterIP
  port 5000
  targetPort 5000
  name http
  annotations 

backendStore
  databaseMigration true
  databaseConnectionCheck true

  postgres
    enabled false
    host 
    port 5432
    database 
    user 
    password 
    driver 

  mysql
    enabled true
    host mysqlheadlessautomotivesvcclusterlocal
    port 3306
    database xxxx
    user xxx
    password xxxx
    driver pymysql

artifactRoot
  proxiedArtifactStorage true
  s3
    enabled true
    bucket automotiveartifacts
    path xxxxcorpxxxxcom9000
    AccessKeyId xxxx
    SecretAccessKey xxxx

extraArgs 

extraFlags 

extraEnvVars
   MinIO configuration
  MLFLOWS3IGNORETLS true
  MLFLOWS3ENDPOINTURL httpsxxxxcorpxxxcom9000
  MINIOROOTUSER xxxxxxxuser
  MINIOROOTPASSWORD xxxpassword
   MINIOSTORAGEUSEHTTPS False
  MINIOSERVERURL httpsxxxxxcorpxxxcom
  MINIOPORT 9000
  MLFLOWBUCKETNAME xxxartifacts

extraSecretNamesForEnvFrom 

ingress
  enabled true
  className xxxlvnginx
   annotations
     kubernetesioingressclass xxlvnginx
  hosts
     host xxxxxxcorpxxxxcom
      paths
         path 
          pathType Prefix
          backend
            serviceName mlflow
            servicePort 5000          
  tls
     secretName tlsingressmlflowsecret
      hosts
         xxxxxxxxxxxxcorpxxxxcom

resources
  limits 
    cpu 1000m
    memory 5500Mi
  requests 
    cpu 1000m
    memory 5500Mi

serviceMonitor
  enabled true
  useServicePort false
  namespace monitoring
  interval 30s
  telemetryPath metrics
  labels
    release prometheus
  timeout 10s
  targetLabels 

  metricRelabelings 

nodeSelector 
  flowapp true
  datacenter las1

tolerations 

affinity 

initContainers 

extraContainers 

extraVolumes 

extraVolumeMounts 

livenessProbe 
   initialDelaySeconds 500
   periodSeconds 10
   timeoutSeconds 1
   failureThreshold 3

  Readiness probe configurations Please look to herehttpskubernetesiodocstasksconfigurepodcontainerconfigurelivenessreadinessstartupprobesconfigureprobes
readinessProbe 
   initialDelaySeconds 500
   periodSeconds 10
   timeoutSeconds 1
   failureThreshold 3



 Describe the problem

Hi Team

I am trying to install mlflow application using latest version ie v260 in our kubernetes cluster but mlflow becomes inaccessible
After installing helm chart mlflow pod is showing running but when I am unable to access it via UI


mlflow76db8cb58cphw95                            11     Running   0          15m

On further troubleshooting I found issue at pod level where If I am running kubectl exec command 

kubectl exec it mlflow76db8cb58cphw95  binbash
rootmlflow76db8cb58cphw95 ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
rootmlflow76db8cb58cphw95 ps efmore
UID          PID    PPID  C STIME TTY          TIME CMD
root           1       0  5 1538         000001 usrlocalbinpython usrlocalbinmlflow server 
host0000 port5000 backendstoreurimysqlpymysqlxxxxxxxmysqlheadlessauto
motivesvcclusterlocal3306xxx gunicornoptsloglevel warning artifactsdestination
s3xxxcorpxxxxcom9000xartifxx serveartifacts exposeprometheusmlflowmetrics
root          22       0  0 1539 pts0    000000 binbash
root          29      22  0 1539 pts0    000000 ps ef
root          30      22  0 1539 pts0    000000 more


Can someone please help me why I am not able to access mlflow application in my kubernetes cluster

 Other info  logs

No response
","diagnose following issue -- - # # # System information - * * OS Platform Distribution ( e.g. , Linux Ubuntu 16.04 ) * * : - * * MLflow installed ( source binary ) * * : - * * MLflow version ( run `` mlflow -- version `` ) * * : 2.6.0 - * * Python version * * : # # # Code reproduce issue Hi Team , trying install mlflow application using latest version i.e . v2.6.0 kubernetes cluster mlflow becomes inaccessible . First created Dockerfile code : `` ` ghcr.io/mlflow/mlflow : v2.6.0 RUN apt-get update & & apt-get install -y procps & & rm -rf /var/lib/apt/lists/ * RUN pip install PyMySQL `` ` build docker file created custom image i.e . v2.6.7 . Post , created helm chart using custom image . code Deployment.yaml , secrets.yaml service.yaml Deployment.yaml `` ` { { - $ artifactCommandPrefix : = `` default-artifact-root '' } } { { - $ artifactCommand : = printf `` -- % s=./mlruns '' $ artifactCommandPrefix } } { { - .Values.artifactRoot.proxiedArtifactStorage } } { { - $ artifactCommandPrefix = `` artifacts-destination '' } } { { - $ artifactCommand = printf `` -- % s=./mlartifacts '' $ artifactCommandPrefix } } { { - end } } { { - .Values.artifactRoot.s3.enabled } } { { - $ artifactCommand = printf `` -- % s=s3 : // % s/ % '' $ artifactCommandPrefix .Values.artifactRoot.s3.path .Values.artifactRoot.s3.bucket } } { { - end } } { { - $ dbConnectionDriver : = `` '' } } { { - .Values.backendStore.mysql.enabled .Values.backendStore.mysql.driver } } { { - $ dbConnectionDriver = printf `` + % '' .Values.backendStore.mysql.driver } } { { - end } } apiVersion : apps/v1 kind : Deployment metadata : name : { { include `` mlflow.fullname '' . } } namespace : { { .Values.k8sNamespace } } labels : { { - include `` mlflow.labels '' . | nindent 4 } } spec : replicas : { { .Values.replicaCount } } selector : matchLabels : { { - include `` mlflow.selectorLabels '' . | nindent 6 } } template : metadata : { { - .Values.podAnnotations } } annotations : { { - toYaml . | nindent 8 } } { { - end } } labels : { { - include `` mlflow.selectorLabels '' . | nindent 8 } } spec : imagePullSecrets : - name : { { include `` mlflow.docker-login-cred '' . } } serviceAccountName : { { include `` mlflow.serviceAccountName '' . } } securityContext : { { - toYaml .Values.podSecurityContext | nindent 8 } } containers : - name : { { .Chart.Name } } securityContext : { { - toYaml .Values.securityContext | nindent 12 } } image : `` { { .Values.docker.image } } : { { .Values.docker.tag } } '' imagePullPolicy : { { .Values.docker.pullPolicy } } command : [ `` mlflow '' ] args : - server - -- host=0.0.0.0 - -- port= { { .Values.service.port } } - -- backend-store-uri=mysql { { $ dbConnectionDriver } } : // $ ( MYSQL_USERNAME ) : $ ( MYSQL_PWD ) @ $ ( MYSQL_HOST ) : $ ( MYSQL_TCP_PORT ) / $ ( MYSQL_DATABASE ) - -- gunicorn-opts= '' -- log-level warning '' - { { $ artifactCommand } } { { - .Values.artifactRoot.proxiedArtifactStorage } } - -- serve-artifacts { { - end } } { { - .Values.serviceMonitor.enabled } } - -- expose-prometheus=/mlflow/metrics { { - end } } ports : - name : { { .Values.service.name } } containerPort : { { .Values.service.port } } protocol : TCP # livenessProbe : # httpGet : # path : / # port : { { .Values.service.port } } # { { - .Values.livenessProbe } } # { { - toYaml . | nindent 12 } } # { { - end } } # readinessProbe : # httpGet : # path : / # port : { { .Values.service.port } } # { { - .Values.readinessProbe } } # { { - toYaml . | nindent 12 } } # { { - end } } resources : { { - toYaml .Values.resources | nindent 12 } } env : - name : MLFLOW_VERSION value : `` 2.6.0 '' { { - range $ key , $ value : = .Values.extraEnvVars } } - name : { { upper $ key } } value : { { $ value | quote } } { { - end } } envFrom : - configMapRef : name : { { template `` mlflow.fullname '' . } } -env-configmap - secretRef : name : { { template `` mlflow.fullname '' . } } -env-secret { { - range .Values.extraSecretNamesForEnvFrom } } - secretRef : name : { { . } } { { - end } } { { - .Values.extraVolumeMounts } } volumeMounts : { { toYaml . | nindent 12 } } { { - end } } { { - .Values.extraContainers } } { { - toYaml . | nindent 8 } } { { - end } } { { - .Values.nodeSelector } } nodeSelector : { { - toYaml . | nindent 8 } } { { - end } } { { - .Values.affinity } } affinity : { { - toYaml . | nindent 8 } } { { - end } } { { - .Values.tolerations } } tolerations : { { - toYaml . | nindent 8 } } { { - end } } { { - ( .Values.backendStore.mysql.enabled ( .Values.backendStore.databaseConnectionCheck .Values.backendStore.databaseMigration ) ) .Values.extraVolumes } } volumes : { { - .Values.backendStore.mysql.enabled .Values.backendStore.databaseConnectionCheck } } - name : dbchecker configMap : name : { { template `` mlflow.fullname '' . } } -dbchecker defaultMode : 0777 { { - end } } { { - .Values.backendStore.mysql.enabled .Values.backendStore.databaseMigration } } - name : migrations-config configMap : name : { { template `` mlflow.fullname '' . } } -migrations { { - end } } { { - .Values.extraVolumes } } { { - toYaml . | nindent 8 } } { { - end } } { { - end } } `` ` service.yaml `` ` apiVersion : v1 kind : Service metadata : name : { { include `` mlflow.fullname '' . } } namespace : { { .Values.k8sNamespace } } labels : { { - include `` mlflow.labels '' . | nindent 4 } } { { - .Values.service.annotations } } annotations : { { - toYaml . | nindent 4 } } { { - end } } spec : type : { { .Values.service.type } } ports : - port : { { .Values.service.port } } targetPort : { { .Values.service.targetPort } } protocol : TCP name : { { .Values.service.name } } selector : { { - include `` mlflow.selectorLabels '' . | nindent 4 } } `` ` secrets.yaml `` ` apiVersion : v1 kind : Secret metadata : name : { { template `` mlflow.fullname '' . } } -env-secret namespace : { { .Values.k8sNamespace } } labels : app : { { template `` mlflow.name '' . } } chart : { { template `` mlflow.chart '' . } } release : { { .Release.Name } } heritage : { { .Release.Service } } type : Opaque data : ARTIFACTORY_API_KEY : { { .Values.artifactory.api_key | quote | b64enc } } MYSQL_USERNAME : { { required `` mysql user must specified '' .Values.backendStore.mysql.user | b64enc } } MYSQL_PWD : { { required `` mysql password must specified '' .Values.backendStore.mysql.password | b64enc } } MINIO_ACCESS_KEY : { { .Values.artifactRoot.s3.AccessKeyId | b64enc } } MINIO_SECRET_KEY : { { .Values.artifactRoot.s3.SecretAccessKey | b64enc } } `` ` values.yaml `` ` replicaCount : 1 docker : image : XXXX.corp.xxxx.com/XXXX-XX-docker/mlflow pullPolicy : Always tag : v2.6.7 imagePullSecrets : [ ] k8sNamespace : autxxxxx nameOverride : `` '' fullnameOverride : `` mlflow '' imageCredentials : registry : xxxxx.corp.xxxx.com username : service-xxxx password : xxxxxxxxxx artifactory : api_key : xxxxxxx serviceAccount : create : true annotations : { } name : `` mlflow '' podAnnotations : { } podSecurityContext : { } securityContext : { } service : type : ClusterIP port : 5000 targetPort : 5000 name : http annotations : { } backendStore : databaseMigration : true databaseConnectionCheck : true postgres : enabled : false host : `` '' port : 5432 database : `` '' user : `` '' password : `` '' driver : `` '' mysql : enabled : true host : `` mysql-headless.automotive.svc.cluster.local '' port : 3306 database : `` xxxx '' user : `` xxx '' password : `` xxxx '' driver : `` pymysql '' artifactRoot : proxiedArtifactStorage : true s3 : enabled : true bucket : `` automotive-artifacts '' path : `` xxxx.corp.xxxx.com:9000 '' AccessKeyId : `` xxxx '' SecretAccessKey : `` xxxx '' extraArgs : { } extraFlags : [ ] extraEnvVars : # MinIO configuration MLFLOW_S3_IGNORE_TLS : true MLFLOW_S3_ENDPOINT_URL : https : //xxxx.corp.xxx.com:9000 MINIO_ROOT_USER : 'xxxx-xxx-user' MINIO_ROOT_PASSWORD : 'xxx-password' # MINIO_STORAGE_USE_HTTPS : False MINIO_SERVER_URL : 'https : //xxxxx.corp.xxx.com' MINIO_PORT : 9000 MLFLOW_BUCKET_NAME : `` xxx-artifacts '' extraSecretNamesForEnvFrom : [ ] ingress : enabled : true className : xxx-lv-nginx # annotations : # kubernetes.io/ingress.class : xx-lv-nginx hosts : - host : xx-x-xxx.corp.xxxx.com paths : - path : / pathType : Prefix backend : serviceName : `` mlflow '' servicePort : `` 5000 '' tls : - secretName : tls-ingress-mlflow-secret hosts : - xxxx-xxxx-xxxx.corp.xxxx.com resources : limits : cpu : 1000m memory : 5500Mi requests : cpu : 1000m memory : 5500Mi serviceMonitor : enabled : true useServicePort : false namespace : monitoring interval : 30s telemetryPath : /metrics labels : release : prometheus timeout : 10s targetLabels : [ ] metricRelabelings : [ ] nodeSelector : flowapp : `` true '' datacenter : `` las1 '' tolerations : [ ] affinity : { } initContainers : [ ] extraContainers : [ ] extraVolumes : [ ] extraVolumeMounts : [ ] livenessProbe : { } # initialDelaySeconds : 500 # periodSeconds : 10 # timeoutSeconds : 1 # failureThreshold : 3 # -- Readiness probe configurations . Please look [ ] ( https : //kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/ # configure-probes ) . readinessProbe : { } # initialDelaySeconds : 500 # periodSeconds : 10 # timeoutSeconds : 1 # failureThreshold : 3 `` ` # # # Describe problem Hi Team , trying install mlflow application using latest version i.e . v2.6.0 kubernetes cluster mlflow becomes inaccessible . installing helm chart , mlflow pod showing running unable access via UI . `` ` mlflow-76db8cb58c-phw95 1/1 Running 0 15m `` ` troubleshooting , found issue pod level running `` kubectl exec command `` `` ` kubectl exec -it mlflow-76db8cb58c-phw95 -- /bin/bash root @ mlflow-76db8cb58c-phw95 : / # ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root @ mlflow-76db8cb58c-phw95 : / # ps -ef|more UID PID PPID C STIME TTY TIME CMD root 1 0 5 15:38 ? 00:00:01 /usr/local/bin/python /usr/local/bin/mlflow server -- host=0.0.0.0 -- port=5000 -- backend-store-uri=mysql+pymysql : //xxx : xxxx @ mysql-headless.auto motive.svc.cluster.local:3306/xxx -- gunicorn-opts= '' -- log-level warning '' -- artifacts-destination= s3 : //xxx.corp.xxxx.com:9000/x-artifxx -- serve-artifacts -- expose-prometheus=/mlflow/metrics root 22 0 0 15:39 pts/0 00:00:00 /bin/bash root 29 22 0 15:39 pts/0 00:00:00 ps -ef root 30 22 0 15:39 pts/0 00:00:00 `` ` someone please help able access mlflow application kubernetes cluster . # # # info / logs _No response_ -- -"
purpleslurple,Can I use local storage in the browser to store the url of the page Im viewing ,use local storage browser store url page ’ viewing
jabrena,"How using this example public class Main 

    public static void mainString args 

        Connector connector  new Connector
        connectorsetPort8080

        Tomcat tomcat  new Tomcat
        tomcatgetServiceaddConnectorconnector

        File base  new FileSystemgetPropertyjavaiotmpdir
        Context context  tomcataddContext basegetAbsolutePath

        HttpServlet myServlet  new MyServlet
        Wrapper servletWrapper  TomcataddServletcontext MyServlet myServlet
        servletWrapperaddMappinghello

        try 
            tomcatstart
            tomcatgetServerawait
         catch LifecycleException e 
            eprintStackTrace
        
    
 how to add JSP support programaticatically","using example , public class Main { public static void main ( String [ ] args ) { Connector connector = new Connector ( ) ; connector.setPort ( 8080 ) ; Tomcat tomcat = new Tomcat ( ) ; tomcat.getService ( ) .addConnector ( connector ) ; File base = new File ( System.getProperty ( `` java.io.tmpdir '' ) ) ; Context context = tomcat.addContext ( `` '' , base.getAbsolutePath ( ) ) ; HttpServlet myServlet = new MyServlet ( ) ; Wrapper servletWrapper = Tomcat.addServlet ( context , `` MyServlet '' , myServlet ) ; servletWrapper.addMapping ( `` /hello '' ) ; try { tomcat.start ( ) ; tomcat.getServer ( ) .await ( ) ; } catch ( LifecycleException e ) { e.printStackTrace ( ) ; } } } add JSP support programaticatically ?"
Matejkob,I have a script that is responsible for running all other scripts which are required to pass CI tests Id love to add an Easter egg related to The Lord of the Rings Can you suggest something,script responsible running scripts required pass CI tests . 'd love add Easter egg related `` Lord Rings . '' suggest something ?
purpleslurple,"Any suggestions on how I might optimize this code The processing time seems a bit slow 
php
 Release 104
 Config
showheader  true
showfooter  true
 End config

 Source code disclaimer  always added
psdisclaimer  
PurpleSlurple Copyright 2002 by Matthew A Schneider
PurpleSlurple code is licensed under the Open Software License version 11
This version was modified 12122006 by
Hans Fredrik Nordhaug hansnordhaugprivno
 Made it work with register globals off which is highly recommended
 Added autodetecting of location of this script
 Inserted headerdisclaimer style base and footer without
   creating invalid HTMLbreaking existing package
 Added config section might not be very useful

 PurpleSlurpleTM was created by Matthew A Schneider       
 and was inspired by Purple Augment and others            
 It was created ostensibly for the purpose of                
 facilitating my communication with Eric S Raymond          
 regarding edits to his How to Become a Hacker document   
 Im not kidding You cant make this stuff up              



 Automatically detect the location of this file
if issetSERVERPATHINFO  SERVERPATHINFO   
    filelocation  SERVERPATHINFO
 else if issetSERVERPHPSELF  SERVERPHPSELF   
   filelocation  SERVERPHPSELF
 else 
   filelocation  SERVERSCRIPTNAME

filelocation  httpsSERVERHTTPHOSTfilelocation

 If set get the url to slurp
if issetGETtheurl 
    theurl  GETtheurl
 else 
    showwelcome


function showwelcome 
    global filelocation
    echo 
titlePurpleSlurpletitle
h2Welcome to PurpleSlurple 153h2
h3Granular Addressability in HTML Documents  ON THE FLYh3
pbqSlurp up a Web page spit back Purple numbersqbphr
pIf you are not familiar with Purple numbers you may want to read Eugene Eric Kims ldquo
a hrefhttpwwweekimcomsoftwarepurplepurplehtmlAn Introduction to Purpleardquo
See also Eric Armstrongs comments on a hreffilelocation
theurlhttpswebarchiveorgweb20020705201817httpwwwtreelightcomsoftwarecollaborationwhatsWrongWithEmailhtmlpurp720granular addressabilityap
pWant oneclick Purple numbers Rightclick on this link
a hrefjavascriptlocationhreffilelocation
theurldocumentlocationhrefPurpleSlurple Bookmarkleta
and bookmark it or drag and drop this bookmark onto your browsers personal toolbar
Now when you are viewing a page on which you would like Purple numbers just click the bookmarklet
Javascript must be enabledphr
pEnter the URL of the page to which you would like to apply Purple numbersp
form methodget actionSERVERSCRIPTNAMEinput typetext nametheurl size30
eg httpssomedomaincomsomepagehtmlbrinput typesubmit valueSubmitform
hrpa hrefhttpspurpleslurplecomPurpleSlurplea 153
was created by a hrefmailtomatschsasitescomMatthew A Schneiderap
  exit


 Do not slurp self
if strpostheurlfilelocation  false
     diePurpleSlurple wont slurp itself  die do not process

 PurpleSlurple headerdisclaimer and expand  collapse link
psheader  h1This page was generated by a hreffilelocationPurpleSlurplea153
The original page can be found a hreftheurlhereah1hr

 PurpleSlurple footer
psfooter  br styleclearbothhrp styleheight 700px
a hrefhttpspurpleslurplecomPurpleSlurplea153 was created
by a hrefmailtomatschsasitescomMatthew A Schneiderap

 set base to ensure relative links work
 Thanks to httpmarctheaimsgroupcomlphpgeneralm95597547227951w2  Duh
psbase  base hreftheurl

 collapse outline hiding elements
psstyle  style typetextcssp displaynonenli displaynonenstylen

 Slurp the page
 Accept https URLs only
if strpostheurlhttps  0 
    echo h1PurpleSlurple only slurps https protocol URLS theurl is invalidh1
    exit

fcontents  filetheurl
if fcontents 
    echo h1Could not open theurlh1
    exit

 Turn off error reporting
errorreporting0

theurl  urlencodetheurl
 filelocation  urlencodefilelocation  Encode the file location as well

 Convert the array into a single string
fullHtmlContent  implode fcontents

 Create a DOMDocument object and load the HTML content
dom  new DOMDocument
libxmluseinternalerrorstrue  Suppress DOMDocument errors
domloadHTMLfullHtmlContent
libxmluseinternalerrorsfalse  Reset libxml error handling

 Create a DOMXPath object for querying the DOM
xpath  new DOMXPathdom

 Query for all p h1 to h6 and li elements
elements  xpathqueryp  h1  h2  h3  h4  h5  h6  li

 Counter for generating unique numbers
counter  0

 Initialize the variable to store the modified HTML content
pscontents  

 Iterate through the elements and add purple numbers
foreach elements as element 
    fragmentId  purp  counter
    
     Create an a element with the purple number
    aElement  domcreateElementa
     aElementsetAttributehref fragmentId
    aElementsetAttributehref filelocationtheurltheurlfragmentId

    aElementsetAttributeid fragmentId
    
    fontElement  domcreateElementfont
    fontElementsetAttributecolor purple
    fontElementtextContent  counter
    
    aElementappendChildfontElement
    
     Create a parenthesized span containing the a element
    spanElement  domcreateElementspan 
    spanElementappendChildaElement
    spanElementappendChilddomcreateTextNode 
    
     Insert the parenthesized span at the beginning of the elements content
    elementinsertBeforespanElement elementfirstChild
    
     Increment the counter
    counter


 Get the modified HTML content
pscontents  domsaveHTML


 find head and body and insert disclaimerheaderfooterstylebase
listheadbody  explodehead pscontents
if issetGETcollapse  GETcollapse  yes 
    head  strreplaceheadheadnpsstyle head

if strposbasehead 
    head  strreplaceheadheadnpsbase head


 insert disclaimerheaderfooter
head  strreplaceheadheadnpsdisclaimer head
if showheader 
    body  pregreplacebodyi0npsheaderbody

if showfooter 
    body  strreplacebodypsfooternbodybody


 Sending result to browser
echo headheadbody

","suggestions might optimize code . processing time seems bit slow : < ? php // Release 104 // Config $ show_header = true ; $ show_footer = true ; // End config // Source code disclaimer - always added $ ps_disclaimer = ' < ! -- PurpleSlurple Copyright 2002 Matthew A. Schneider . PurpleSlurple code licensed Open Software License version 1.1 . version modified 12.12.2006 Hans Fredrik Nordhaug < hans @ nordhaug.priv.no > : - Made work register globals ( highly recommended ) . - Added autodetecting location script . - Inserted header/disclaimer , style , base footer without creating invalid HTML/breaking existing package . - Added config section , might useful . * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * PurpleSlurple ( TM ) created Matthew A. Schneider * * inspired Purple , Augment , others . * * created ostensibly purpose * * facilitating communication Eric S. Raymond * * regarding edits `` Become Hacker '' document . * * I\ 'm kidding . can\'t make stuff ! * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * -- > ' ; // Automatically detect location file ( isset ( $ _SERVER [ 'PATH_INFO ' ] ) & & ( $ _SERVER [ 'PATH_INFO ' ] ! = '' '' ) ) { $ file_location = $ _SERVER [ 'PATH_INFO ' ] ; } else ( isset ( $ _SERVER [ 'PHP_SELF ' ] ) & & ( $ _SERVER [ 'PHP_SELF ' ] ! = '' '' ) ) { $ file_location = $ _SERVER [ 'PHP_SELF ' ] ; } else { $ file_location = $ _SERVER [ 'SCRIPT_NAME ' ] ; } $ file_location = `` https : // '' . $ _SERVER [ 'HTTP_HOST ' ] . $ file_location ; // set , get url slurp ( isset ( $ _GET [ 'theurl ' ] ) ) { $ theurl = $ _GET [ 'theurl ' ] ; } else { show_welcome ( ) ; } function show_welcome ( ) { global $ file_location ; echo ' < title > PurpleSlurple < /title > < h2 > Welcome PurpleSlurple & # 153 ; < /h2 > < h3 > Granular Addressability HTML Documents - FLY < /h3 > < p > < b > < q > Slurp Web page , spit back Purple numbers < /q > < /b > < /p > < hr > < p > familiar Purple numbers may want read Eugene Eric Kim\ 's & ldquo ; < href= '' http : //www.eekim.com/software/purple/purple.html '' > Introduction Purple < /a > & rdquo ; . See also Eric Armstrong\ 's comments < href= '' '. $ file_location . ' ? theurl=https : //web.archive.org/web/20020705201817/http : //www.treelight.com/software/collaboration/whatsWrongWithEmail.html # purp720 '' > granular addressability < /a > < /p > < p > Want one-click Purple numbers ? Right-click link , < href= '' javascript : location.href=\ '' . $ file_location . ' ? theurl=\'+document.location.href ; '' > PurpleSlurple Bookmarklet < /a > , bookmark , drag drop bookmark onto browser\ 's personal toolbar . viewing page would like Purple numbers click bookmarklet . ( Javascript must enabled ) . < /p > < hr > < p > Enter URL page would like apply Purple numbers. < /p > < form method= '' get '' action= '' '. $ _SERVER [ 'SCRIPT_NAME ' ] . ' '' > < input type= '' text '' name= '' theurl '' size= '' 30 '' > ( e.g. , https : //somedomain.com/somepage.html ) < br > < input type= '' submit '' value= '' Submit '' > < /form > < hr > < p > < href= '' https : //purpleslurple.com/ '' > PurpleSlurple < /a > & # 153 ; created < href= '' mailto : matsch @ sasites.com '' > Matthew A. Schneider < /a > < /p > ' ; exit ; } // slurp self ( strpos ( $ theurl , $ file_location ) ! == false ) die ( 'PurpleSlurple won\'t slurp : - ) ' ) ; //die , process // PurpleSlurple header/disclaimer expand / collapse link $ ps_header = ' < h1 > page generated < href= '' '. $ file_location. ' '' > PurpleSlurple < /a > & # 153 ; . original page found < href= '' '. $ theurl . ' '' > < /a > . < /h1 > < hr > ' ; // PurpleSlurple footer $ ps_footer = ' < br style= '' clear : '' > < hr > < p style= '' height : 700px '' > < href= '' https : //purpleslurple.com/ '' > PurpleSlurple < /a > & # 153 ; created < href= '' mailto : matsch @ sasites.com '' > Matthew A. Schneider < /a > < /p > ' ; // set base ensure relative links work // Thanks http : //marc.theaimsgroup.com/ ? l=php-general & m=95597547227951 & w=2 Duh ! $ ps_base = `` < base href= ' $ theurl ' > '' ; // collapse outline ( hiding elements ) $ ps_style = `` < style type='text/css ' > p { display : none } \nli { display : none } \n < /style > \n '' ; // Slurp page // Accept https URLs ( strpos ( $ theurl , '' https : // '' ) ! == 0 ) { echo `` < h1 > PurpleSlurple slurps https : // protocol URLS . $ theurl invalid. < /h1 > '' ; exit ; } $ fcontents = @ file ( $ theurl ) ; ( ! $ fcontents ) { echo `` < h1 > Could open $ theurl < /h1 > '' ; exit ; } // Turn error reporting error_reporting ( 0 ) ; $ theurl = urlencode ( $ theurl ) ; // $ file_location = urlencode ( $ file_location ) ; // Encode file location well // Convert array single string $ fullHtmlContent = implode ( `` , $ fcontents ) ; // Create DOMDocument object load HTML content $ dom = new DOMDocument ( ) ; libxml_use_internal_errors ( true ) ; // Suppress DOMDocument errors $ dom- > loadHTML ( $ fullHtmlContent ) ; libxml_use_internal_errors ( false ) ; // Reset libxml error handling // Create DOMXPath object querying DOM $ xpath = new DOMXPath ( $ dom ) ; // Query < p > , < h1 > < h6 > , < li > elements $ elements = $ xpath- > query ( `` //p | //h1 | //h2 | //h3 | //h4 | //h5 | //h6 | //li '' ) ; // Counter generating unique numbers $ counter = 0 ; // Initialize variable store modified HTML content $ ps_contents = `` '' ; // Iterate elements add purple numbers foreach ( $ elements $ element ) { $ fragmentId = `` purp '' . $ counter ; // Create < > element purple number $ aElement = $ dom- > createElement ( ' ' ) ; // $ aElement- > setAttribute ( 'href ' , `` # $ fragmentId '' ) ; $ aElement- > setAttribute ( 'href ' , `` $ file_location ? theurl= $ theurl # $ fragmentId '' ) ; $ aElement- > setAttribute ( 'id ' , $ fragmentId ) ; $ fontElement = $ dom- > createElement ( 'font ' ) ; $ fontElement- > setAttribute ( 'color ' , 'purple ' ) ; $ fontElement- > textContent = $ counter ; $ aElement- > appendChild ( $ fontElement ) ; // Create parenthesized span containing < > element $ spanElement = $ dom- > createElement ( 'span ' , ' ( ' ) ; $ spanElement- > appendChild ( $ aElement ) ; $ spanElement- > appendChild ( $ dom- > createTextNode ( ' ) ' ) ) ; // Insert parenthesized span beginning element 's content $ element- > insertBefore ( $ spanElement , $ element- > firstChild ) ; // Increment counter $ counter++ ; } // Get modified HTML content $ ps_contents = $ dom- > saveHTML ( ) ; // find head body insert disclaimer/header/footer/style/base list ( $ head , $ body ) = explode ( `` < /head > '' , $ ps_contents ) ; ( isset ( $ _GET [ 'collapse ' ] ) & & ( $ _GET [ 'collapse ' ] == `` yes '' ) ) { $ head = str_replace ( `` < head > '' , '' < head > \n $ ps_style '' , $ head ) ; ; } ( ! strpos ( `` < base '' , $ head ) ) { $ head = str_replace ( `` < head > '' , '' < head > \n $ ps_base '' , $ head ) ; ; } // insert disclaimer/header/footer $ head = str_replace ( `` < head > '' , '' < head > \n $ ps_disclaimer '' , $ head ) ; ( $ show_header ) { $ body = preg_replace ( `` / < body [ ^ > ] * > /i '' , '' \\0\n $ ps_header '' , $ body ) ; } ( $ show_footer ) { $ body = str_replace ( `` < /body > '' , '' $ ps_footer\n < /body > '' , $ body ) ; } // Sending result browser echo $ head . `` < /head > '' . $ body ; ? >"
purpleslurple,Can you list some of the different styles used for bibliography ,list different styles used bibliography
JarbasAl,"explain this code

import collections
import math
import os
import pickle
import typing

import nltk
from nltkcorpus import udhr
from ovosutilsxdgutils import xdgdatahome


class LMLangClassifier
    def initself pathNone
        if path
            with openpath rb as f
                selflanguagemodels  pickleloadf
            printflang models loaded from path
        else
            selffit

    def fitself saveTrue
        model  fxdgdatahomeovosclassifierslanglmspkl
        osmakedirsospathdirnamemodel existokTrue
        if ospathisfilemodel
            with openmodel rb as f
                selflanguagemodels  pickleloadf
            printflang models loaded from model
            return model

        nltkdownloadudhr   udhr  Universal Declaration of Human Rights
        languages  en de nl fr it es pt no ca da fi sw
        languageids  EnglishLatin1 GermanDeutschLatin1 DutchNederlandsLatin1 FrenchFrancaisLatin1
                        ItalianItalianoLatin1 SpanishEspanolLatin1 PortuguesePortuguesLatin1
                        NorwegianLatin1 CatalanLatin1 DanishDanskLatin1 FinnishSuomiLatin1
                        SwedishSvenskaLatin1

        rawtexts  language udhrrawlanguageid for language languageid in ziplanguages languageids

        selflanguagemodels  language selfbuildmodeltextrawtextslanguage nvalsrange1 4 for language in
                                languages
        if save
            with openmodel wb as f
                pickledumpselflanguagemodels f
            printflang models saved to model
        return model

    staticmethod
    def calculatecosinea typingDictstr float b typingDictstr float  float
        
        Calculate the cosine between two numeric vectors
        Params
            a b two dictionaries containing items and their corresponding numeric values
            eg ngrams and their corresponding probabilities
        
        numerator  sumak  bk for k in a if k in b
        denominator  mathsqrtsumak  2 for k in a  mathsqrtsumbk  2 for k in b
        return numerator  denominator

    staticmethod
    def extractxgramstext str nvals typingListint  typingListstr
        
        Extract a list of ngrams of different sizes from a text
        Params
            text the test from which to extract ngrams
            nvals the sizes of ngrams to extract
            eg 1 2 3 will produce uni bi and trigrams
        
        xgrams  

        for n in nvals
             if n  lentext then no ngrams will fit and we would return an empty list
            if n  lentext
                for i in rangelentext  n  1
                    ng  textii  n
                    xgramsappendng

        return xgrams

    classmethod
    def buildmodelcls text str nvalsrange1 4  typingDictstr int
        
        Build a simple model of probabilities of xgrams of various lengths in a text
        Parms
            text the text from which to extract the ngrams
            nvals a list of ngram sizes to extract
        Returns
            A dictionary of ngrams and their probabilities given the input text
        
        model  collectionsCounterclsextractxgramstext nvals
        numngrams  summodelvalues

        for ng in model
            modelng  modelng  numngrams

        return model

    def identifylanguageself
                          text str
                          nvalsrange1 4
                            str
        scores  selfpredicttext nvals
        return maxscoresitems keylambda k k10

    def predictself
                text str
                nvalsrange1 4
                  str
        
        Given a text and a dictionary of language models return the language model
        whose ngram probabilities best match those of the test text
        Params
            text the text whose language we want to identify
            languagemodels a Dict of Dicts where each key is a language name and
            each value is a dictionary of ngram probability pairs
            nvals a list of ngram sizes to extract to build a model of the test
            text ideally reflect the ngram sizes used in languagemodels
        
        textmodel  selfbuildmodeltext nvals
        scores  m selfcalculatecosineselflanguagemodelsm textmodel
                  for m in selflanguagemodels
        return scores


if name  main
    clf  LMLangClassifier
    text  I was taught that the way of progress was neither swift nor easylower
     Quote from Marie Curie the first woman to win a Nobel Prize the only woman to win it twice and the only human to win it in two different sciences

    printfTest text text
    printfIdentified language clfidentifylanguagetext nvalsrange1 4
     Test text i was taught that the way of progress was neither swift nor easy
     Identified language english","explain code import collections import math import os import pickle import typing import nltk nltk.corpus import udhr ovos_utils.xdg_utils import xdg_data_home class LMLangClassifier : def __init__ ( self , path=None ) : path : open ( path , `` rb '' ) f : self.language_models = pickle.load ( f ) print ( f '' lang models loaded { path } '' ) else : self.fit ( ) def fit ( self , save=True ) : model = f '' { xdg_data_home ( ) } /ovos-classifiers/lang_lms.pkl '' os.makedirs ( os.path.dirname ( model ) , exist_ok=True ) os.path.isfile ( model ) : open ( model , `` rb '' ) f : self.language_models = pickle.load ( f ) print ( f '' lang models loaded { model } '' ) return model nltk.download ( 'udhr ' ) # udhr = Universal Declaration Human Rights languages = [ 'en ' , 'de ' , 'nl ' , 'fr ' , 'it ' , 'es ' , `` pt '' , `` '' , `` ca '' , `` da '' , `` fi '' , `` sw '' ] language_ids = [ 'English-Latin1 ' , 'German_Deutsch-Latin1 ' , 'Dutch_Nederlands-Latin1 ' , 'French_Francais-Latin1 ' , 'Italian_Italiano-Latin1 ' , 'Spanish_Espanol-Latin1 ' , 'Portuguese_Portugues-Latin1 ' , 'Norwegian-Latin1 ' , `` Catalan-Latin1 '' , 'Danish_Dansk-Latin1 ' , 'Finnish_Suomi-Latin1 ' , 'Swedish_Svenska-Latin1 ' ] raw_texts = { language : udhr.raw ( language_id ) language , language_id zip ( languages , language_ids ) } self.language_models = { language : self.build_model ( text=raw_texts [ language ] , n_vals=range ( 1 , 4 ) ) language languages } save : open ( model , `` wb '' ) f : pickle.dump ( self.language_models , f ) print ( f '' lang models saved { model } '' ) return model @ staticmethod def calculate_cosine ( : typing.Dict [ str , float ] , b : typing.Dict [ str , float ] ) - > float : `` '' '' Calculate cosine two numeric vectors Params : , b : two dictionaries containing items corresponding numeric values ( e.g . ngrams corresponding probabilities ) `` '' '' numerator = sum ( [ [ k ] * b [ k ] k k b ] ) denominator = ( math.sqrt ( sum ( [ [ k ] * * 2 k ] ) ) * math.sqrt ( sum ( [ b [ k ] * * 2 k b ] ) ) ) return numerator / denominator @ staticmethod def extract_xgrams ( text : str , n_vals : typing.List [ int ] ) - > typing.List [ str ] : `` '' '' Extract list n-grams different sizes text . Params : text : test extract ngrams n_vals : sizes n-grams extract ( e.g . [ 1 , 2 , 3 ] produce uni- , bi- tri-grams ) `` '' '' xgrams = [ ] n n_vals : # n > len ( text ) ngrams fit , would return empty list n < len ( text ) : range ( len ( text ) - n + 1 ) : ng = text [ : + n ] xgrams.append ( ng ) return xgrams @ classmethod def build_model ( cls , text : str , n_vals=range ( 1 , 4 ) ) - > typing.Dict [ str , int ] : `` '' '' Build simple model probabilities xgrams various lengths text Parms : text : text extract n_grams n_vals : list n_gram sizes extract Returns : dictionary ngrams probabilities given input text `` '' '' model = collections.Counter ( cls.extract_xgrams ( text , n_vals ) ) num_ngrams = sum ( model.values ( ) ) ng model : model [ ng ] = model [ ng ] / num_ngrams return model def identify_language ( self , text : str , n_vals=range ( 1 , 4 ) ) - > str : scores = self.predict ( text , n_vals ) return max ( scores.items ( ) , key=lambda k : k [ 1 ] ) [ 0 ] def predict ( self , text : str , n_vals=range ( 1 , 4 ) ) - > str : `` '' '' Given text dictionary language models , return language model whose ngram probabilities best match test text Params : text : text whose language want identify language_models : Dict Dicts , key language name value dictionary ngram : probability pairs n_vals : list n_gram sizes extract build model test text ; ideally reflect n_gram sizes used 'language_models' `` '' '' text_model = self.build_model ( text , n_vals ) scores = { : self.calculate_cosine ( self.language_models [ ] , text_model ) self.language_models } return scores __name__ == `` __main__ '' : clf = LMLangClassifier ( ) text = `` taught way progress neither swift easy . `` .lower ( ) # Quote Marie Curie , first woman win Nobel Prize , woman win twice , human win two different sciences . print ( f '' Test text : { text } '' ) print ( f '' Identified language : { clf.identify_language ( text , n_vals=range ( 1 , 4 ) ) } '' ) # Test text : taught way progress neither swift easy . # Identified language : english"
vemv,Recommend me a data structure from the Java Collections Framework that has a maximum size and a LRU policy when that max size is hit,"Recommend data structure Java Collections Framework maximum size , LRU policy max size hit"
rane254,"Make this Java code into Android Java code so that it looks like online multiplayer Android game and also their respective XML layout
Write a full step by step code 
Mainjava
package orgexample

public class Main 
    public static void mainString args 
        new Game
    


Gamejava
package orgexample

import javautilScanner


 Handles the overall flow of the game
 It prompts the player for game mode selection creates instances of other necessary classes and orchestrates the gameplay

public class Game 
    boolean singlePlayer
    Player player
    ComputerPlayer computerPlayer
    GameLogic gameLogic

    
     Initializes the game by displaying a welcome message setting the game mode
     creating instances of other necessary classes Player ComputerPlayer and GameLogic and starting the game
    public Game 
        SystemoutprintlnWelcome to RPS Arenan
        setGameMode
        gameLogic  new GameLogic
        startGame
    

    
      Prompts the player to select the game mode singleplayer or multiplayer
      Sets the singlePlayer variable based on the user input
     
    private void setGameMode 
        Scanner userInput  new ScannerSystemin
        SystemoutprintlnSelect Game Moden
        Systemoutprintln1 Singleplayer
        Systemoutprintln2 Multiplayern

        String input  userInputnextLine
        if inputequalsIgnoreCase1 
            singlePlayer  true
            SystemoutprintlnYou have selected Singleplayer moden
            player  new Player
            computerPlayer  new ComputerPlayer
         else if inputequalsIgnoreCase2 
            singlePlayer  false
         else if inputequalsIgnoreCaseexit 
            SystemoutprintlnExiting APS Arena
            Systemexit0
        
        else 
            setGameMode
        
    

    
     Handles the main game loop It repeatedly prompts the player for their move checks if the input is exit to exit the game
     converts the input to a Moves enum value generates the opponents move either by the computer in singleplayer mode or by
     the other player in multiplayer mode determines the winner using GameLogic updates the points for the players and displays
     the result and current points
    private void startGame 
        while true 
            SystemoutprintlnEnter your move or type exit to quit the game
            SystemoutprintlnMoves ROCK PAPER SCISSORS
            String input  getPlayerInput

            if inputequalsIgnoreCaseexit 
                SystemoutprintlnnExiting RPS Arena
                Systemexit0
            

            Moves playerMove  convertToMoveinput
            if playerMove  null 
                SystemoutprintlnInvalid move Please try again
                continue
            

            Moves opponentMove
            if singlePlayer 
                opponentMove  computerPlayergenerateCPUMove
                SystemoutprintlnnComputer played   opponentMove
             else 
                opponentMove  playergetOpponentgetPlayerMove
                SystemoutprintlnplayergetOpponentgetUsername   played   opponentMove
            

            String result  gameLogicdetermineWinnerplayerMove opponentMove
            SystemoutprintlnResult   result
            updatePointsresult
        
    

    
     Prompts the player to enter their move or type exit to quit the game and returns the input as a String
    private String getPlayerInput 
        Scanner userInput  new ScannerSystemin
        return userInputnextLinetoUpperCase
    

    
     converts the input String to a corresponding Moves enum value It tries to match the input with the available
     Moves enum values ROCK PAPER SCISSORS and returns the matched enum value If the input doesnt match any
     enum value it returns null
    private Moves convertToMoveString input 
        try 
            return MovesvalueOfinput
         catch IllegalArgumentException e 
            return null
        
    

    
     updates the points for the players based on the game result
     If the result is WIN it increments the players points and displays a message indicating the players win
     If the result is LOSS it increments the opponents points computer in singleplayer or the other player in multiplayer
     and displays a message indicating the opponents win
     If the result is a tie it displays a message indicating a tie It then prints the current points for both players
    private void updatePointsString result 
        if resultequalsWIN 
            playerincrementPoints
            SystemoutprintlnplayergetUsername   wins
         else if resultequalsLOSS 
            if singlePlayer 
                computerPlayerincrementPoints
                SystemoutprintlnComputer wins
             else 
                playergetOpponentincrementPoints
                SystemoutprintlnplayergetOpponentgetUsername   wins
            
         else 
            SystemoutprintlnIts a tie
        

        SystemoutprintlnnPoints
        SystemoutprintlnplayergetUsername     playergetPlayerPoints
        if singlePlayer 
            SystemoutprintlnplayergetOpponentgetUsername     playergetOpponentgetPlayerPoints
         else 
            SystemoutprintlnComputer   computerPlayergetCpuPoints
        
        Systemoutprintln
    


GameLogicjava
package orgexample


 Contains the game rules and logic
 It determines the winner based on the moves chosen by the players
public class GameLogic 

    
      Determines the winner of the game based on the moves played by the player and the CPU
     
      param playerMove The move played by the player
      param cpuMove    The move played by the CPU
      return A string indicating the result of the game WIN if the player wins LOSS if the player loses or TIE if its a tie
     
    public String determineWinnerMoves playerMove Moves cpuMove 
        if playerMove  cpuMove 
            return TIE
         else if playerMoveequalsMovesROCK  cpuMoveequalsMovesPAPER 
                    playerMoveequalsMovesPAPER  cpuMoveequalsMovesSCISSORS 
                    playerMoveequalsMovesSCISSORS  cpuMoveequalsMovesROCK 
            return LOSS
         else 
            return WIN
        
    


Movesjava
package orgexample

public enum Moves 
    ROCK
    PAPER
    SCISSORS


ComputerPlayerjava
package orgexample

import javautilRandom


 Extends the Player class and represents the computer player in singleplayer mode
 It implements a strategy to generate a random move for the computer
public class ComputerPlayer 
    private int cpuPoints  0

    
      return returns the points of the computer
    public int getCpuPoints 
        return cpuPoints
    


    
       Increments the points of the computer
    public void incrementPoints 
        cpuPoints
    


    
      Generates a random move for the computer player
     
      return A random move from the Moves enum
     
    public Moves generateCPUMove 
        Moves moves  Movesvalues
        Random random  new Random
        int index  randomnextIntmoveslength
        return movesindex
    


HumanPlayerjava
package orgexample


   Extends the Player class and represents a human player in multiplayer mode
   It can handle input from the human player to get their move
public class HumanPlayer 


Playerjava
package orgexample

import javautilScanner


  Represents a player in the game
  It has properties such as name and points
  It provides methods to get the players move and update their points
public class Player 
    String username
    int playerPoints
    private Player opponent

    
     Initializes a player by prompting them to enter their username setting the initial points to 0 and displaying a greeting message
    public Player 
        thisplayerPoints  0
        thisusername  promptUsername
        SystemoutprintlnHello   username  n
    

    
      Sets the opponent of the player It takes a Player object as a parameter and assigns it to the opponent field of the player
    public void setOpponentPlayer opponent 
        thisopponent  opponent
    


    
     return the opponent of the player
    
    public Player getOpponent 
        return opponent
    


    
      return returns the username of the player
    public String getUsername 
        return username
    

    
      return returns the points of the player
    public int getPlayerPoints 
        return playerPoints
    

    
       Increments the points of the player
    public void incrementPoints 
        playerPoints
    

    
      Prompts the player to enter their username
     
      return The username entered by the player
     
    private String promptUsername 
        Scanner userInput  new ScannerSystemin
        SystemoutprintlnWhats your username
        return userInputnextLine
    

    
      Prompts the player to enter their move Rock Paper or Scissors
      If the user input is not valid the player is prompted again until a valid move is entered
     
      return The valid move entered by the player
     
    public Moves getPlayerMove 
        SystemoutprintlnRock Paper or Scissorsn
        Scanner userInput  new ScannerSystemin
        String input  userInputnextLinetoUpperCase

        if inputequalsMovesROCKtoString  inputequalsMovesPAPERtoString  inputequalsMovesSCISSORStoString 
            return MovesvalueOfinput
         else 
            SystemoutprintlnInvalid move Please try again
            return getPlayerMove
        
    


","Make Java code Android Java code looks like online multiplayer Android game also respective XML layout Write full step step code Main.java package org.example ; public class Main { public static void main ( String [ ] args ) { new Game ( ) ; } } Game.java package org.example ; import java.util.Scanner ; / * * Handles overall flow game . * prompts player game mode selection , creates instances necessary classes , orchestrates gameplay . * / public class Game { boolean singlePlayer ; Player player ; ComputerPlayer computerPlayer ; GameLogic gameLogic ; / * * Initializes game displaying welcome message , setting game mode , * creating instances necessary classes ( Player , ComputerPlayer , GameLogic ) , starting game . * / public Game ( ) { System.out.println ( `` Welcome RPS Arena ! \n '' ) ; setGameMode ( ) ; gameLogic = new GameLogic ( ) ; startGame ( ) ; } / * * * Prompts player select game mode ( single-player multiplayer ) . * Sets 'singlePlayer ' variable based user input . * / private void setGameMode ( ) { Scanner userInput = new Scanner ( ( System.in ) ) ; System.out.println ( `` Select Game Mode ! \n '' ) ; System.out.println ( `` 1 . Single-player '' ) ; System.out.println ( `` 2 . Multiplayer\n '' ) ; String input = userInput.nextLine ( ) ; ( input.equalsIgnoreCase ( `` 1 '' ) ) { singlePlayer = true ; System.out.println ( `` selected Single-player mode ! \n '' ) ; player = new Player ( ) ; computerPlayer = new ComputerPlayer ( ) ; } else ( input.equalsIgnoreCase ( `` 2 '' ) ) { singlePlayer = false ; } else ( input.equalsIgnoreCase ( `` exit '' ) ) { System.out.println ( `` Exiting APS Arena ... '' ) ; System.exit ( 0 ) ; } else { setGameMode ( ) ; } } / * * Handles main game loop . repeatedly prompts player move , checks input `` exit '' exit game , * converts input Moves enum value , generates opponent 's move ( either computer single-player mode * player multiplayer mode ) , determines winner using GameLogic , updates points players , displays * result current points . * / private void startGame ( ) { ( true ) { System.out.println ( `` Enter move type 'exit ' quit game : '' ) ; System.out.println ( `` Moves : ROCK , PAPER , SCISSORS '' ) ; String input = getPlayerInput ( ) ; ( input.equalsIgnoreCase ( `` exit '' ) ) { System.out.println ( `` \nExiting RPS Arena ... '' ) ; System.exit ( 0 ) ; } Moves playerMove = convertToMove ( input ) ; ( playerMove == null ) { System.out.println ( `` Invalid move . Please try . `` ) ; continue ; } Moves opponentMove ; ( singlePlayer ) { opponentMove = computerPlayer.generateCPUMove ( ) ; System.out.println ( `` \nComputer played : `` + opponentMove ) ; } else { opponentMove = player.getOpponent ( ) .getPlayerMove ( ) ; System.out.println ( player.getOpponent ( ) .getUsername ( ) + `` played : `` + opponentMove ) ; } String result = gameLogic.determineWinner ( playerMove , opponentMove ) ; System.out.println ( `` Result : `` + result ) ; updatePoints ( result ) ; } } / * * Prompts player enter move type `` exit '' quit game returns input String . * / private String getPlayerInput ( ) { Scanner userInput = new Scanner ( System.in ) ; return userInput.nextLine ( ) .toUpperCase ( ) ; } / * * converts input String corresponding Moves enum value . tries match input available * Moves enum values ( ROCK , PAPER , SCISSORS ) returns matched enum value . input n't match * enum value , returns null . * / private Moves convertToMove ( String input ) { try { return Moves.valueOf ( input ) ; } catch ( IllegalArgumentException e ) { return null ; } } / * * updates points players based game result . * result `` WIN , '' increments player 's points displays message indicating player 's win . * result `` LOSS , '' increments opponent 's points ( computer single-player player multiplayer ) * displays message indicating opponent 's win . * result tie , displays message indicating tie . prints current points players . * / private void updatePoints ( String result ) { ( result.equals ( `` WIN '' ) ) { player.incrementPoints ( ) ; System.out.println ( player.getUsername ( ) + `` wins ! `` ) ; } else ( result.equals ( `` LOSS '' ) ) { ( singlePlayer ) { computerPlayer.incrementPoints ( ) ; System.out.println ( `` Computer wins ! `` ) ; } else { player.getOpponent ( ) .incrementPoints ( ) ; System.out.println ( player.getOpponent ( ) .getUsername ( ) + `` wins ! `` ) ; } } else { System.out.println ( `` 's tie ! `` ) ; } System.out.println ( `` \nPoints : '' ) ; System.out.println ( player.getUsername ( ) + `` : `` + player.getPlayerPoints ( ) ) ; ( ! singlePlayer ) { System.out.println ( player.getOpponent ( ) .getUsername ( ) + `` : `` + player.getOpponent ( ) .getPlayerPoints ( ) ) ; } else { System.out.println ( `` Computer : `` + computerPlayer.getCpuPoints ( ) ) ; } System.out.println ( ) ; } } GameLogic.java package org.example ; / * * Contains game rules logic . * determines winner based moves chosen players . * / public class GameLogic { / * * * Determines winner game based moves played player CPU . * * @ param playerMove move played player . * @ param cpuMove move played CPU . * @ return string indicating result game : `` WIN '' player wins , `` LOSS '' player loses , `` TIE '' 's tie . * / public String determineWinner ( Moves playerMove , Moves cpuMove ) { ( playerMove == cpuMove ) { return `` TIE '' ; } else ( playerMove.equals ( Moves.ROCK ) & & cpuMove.equals ( Moves.PAPER ) || playerMove.equals ( Moves.PAPER ) & & cpuMove.equals ( Moves.SCISSORS ) || playerMove.equals ( Moves.SCISSORS ) & & cpuMove.equals ( Moves.ROCK ) ) { return `` LOSS '' ; } else { return `` WIN '' ; } } } Moves.java package org.example ; public enum Moves { ROCK , PAPER , SCISSORS } ComputerPlayer.java package org.example ; import java.util.Random ; / * * Extends Player class represents computer player single-player mode . * implements strategy generate random move computer . * / public class ComputerPlayer { private int cpuPoints = 0 ; / * * * @ return returns points computer * / public int getCpuPoints ( ) { return cpuPoints ; } / * * * Increments points computer * / public void incrementPoints ( ) { cpuPoints++ ; } / * * * Generates random move computer player . * * @ return random move Moves enum . * / public Moves generateCPUMove ( ) { Moves [ ] moves = Moves.values ( ) ; Random random = new Random ( ) ; int index = random.nextInt ( moves.length ) ; return moves [ index ] ; } } HumanPlayer.java package org.example ; / * * * Extends Player class represents human player multiplayer mode . * handle input human player get move . * / public class HumanPlayer { } Player.java package org.example ; import java.util.Scanner ; / * * * Represents player game . * properties name points . * provides methods get player 's move update points . * / public class Player { String username ; int playerPoints ; private Player opponent ; / * * Initializes player prompting enter username , setting initial points 0 , displaying greeting message . * / public Player ( ) { this.playerPoints = 0 ; this.username = promptUsername ( ) ; System.out.println ( `` Hello `` + username + `` ! \n '' ) ; } / * * Sets opponent player . takes Player object parameter assigns opponent field player . * / public void setOpponent ( Player opponent ) { this.opponent = opponent ; } / * * * @ return opponent player . * / public Player getOpponent ( ) { return opponent ; } / * * * @ return returns username player * / public String getUsername ( ) { return username ; } / * * * @ return returns points player * / public int getPlayerPoints ( ) { return playerPoints ; } / * * * Increments points player * / public void incrementPoints ( ) { playerPoints++ ; } / * * * Prompts player enter username . * * @ return username entered player . * / private String promptUsername ( ) { Scanner userInput = new Scanner ( ( System.in ) ) ; System.out.println ( `` 's username ? `` ) ; return userInput.nextLine ( ) ; } / * * * Prompts player enter move ( Rock , Paper , Scissors ) . * user input valid , player prompted valid move entered . * * @ return valid move entered player . * / public Moves getPlayerMove ( ) { System.out.println ( `` Rock , Paper Scissors ? \n '' ) ; Scanner userInput = new Scanner ( ( System.in ) ) ; String input = userInput.nextLine ( ) .toUpperCase ( ) ; ( input.equals ( Moves.ROCK.toString ( ) ) || input.equals ( Moves.PAPER.toString ( ) ) || input.equals ( Moves.SCISSORS.toString ( ) ) ) { return Moves.valueOf ( input ) ; } else { System.out.println ( `` Invalid move . Please try . `` ) ; return getPlayerMove ( ) ; } } }"
smuu,"What is the benefit in using this approach

    otelAgent err  NewInstanceotelagent
	if err  wrapErrorerr error creating otelagent instance err  nil 
		return nil err
	



func wrapErrorerr error msg string error 
    if err  nil 
        return fmtErrorfs w msg err
    
    return nil



Instead of using

    otelAgent err  NewInstanceotelagent
	if err  nil 
		return fmtErrorferror creating otelagent instance w err
	
","benefit using approach : `` ` otelAgent , err : = NewInstance ( `` otel-agent '' ) err : = wrapError ( err , `` error creating otel-agent instance '' ) ; err ! = nil { return nil , err } `` ` `` ` func wrapError ( err error , msg string ) error { err ! = nil { return fmt.Errorf ( `` % : % w '' , msg , err ) } return nil } `` ` Instead using : `` ` otelAgent , err : = NewInstance ( `` otel-agent '' ) err ! = nil { return fmt.Errorf ( `` error creating otel-agent instance : % w '' , err ) } `` `"
Bisllly,"how to I access a running images using docker cli is it

docker exec it xxxxxxxx binbash",access running images using docker cli ? : docker exec -it xxxxxxxx /bin/bash
santosomar,Create a python script to send a DNS packet using scapy with a secret payload,Create python script send DNS packet using scapy secret payload
bestian, tsnpm,可以用 ts寫npm套件嗎
pavlovcik,are you familiar with the superintendent ai in halo ODST ,familiar `` superintendent '' ai halo : ODST ?
rensanrenren,AI,AIにプログラミングをしてもらうにしても、そのコードがエンジニアリングとして綺麗か構造はできているかを自分で理解して修正するスキルをつけたい。何を勉強すれば良い？
kid-oh,,你能帮我写个脚本吗
smh9800,"include stdioh
include stdlibh
include stringh
include unistdh
include arpaineth

define SERVERIP 16925414229  Replace with the servers IP address
define PORT 8080
define BUFFERSIZE 1024

int main 
    int clientsocket
    struct sockaddrin serveraddr

     Create socket
    if clientsocket  socketAFINET SOCKDGRAM 0  0 
        perrorsocket creation failed
        exitEXITFAILURE
    

    memsetserveraddr 0 sizeofserveraddr

     Configure server address
    serveraddrsinfamily  AFINET
    serveraddrsinport  htonsPORT
    if inetptonAFINET SERVERIP serveraddrsinaddr  0 
        perrorInvalid address Address not supported
        exitEXITFAILURE
    

    char bufferBUFFERSIZE

    while 1 
         Send message to server
        printfClient You 
        fgetsbuffer BUFFERSIZE stdin
        sendtoclientsocket const char buffer strlenbuffer 0
               const struct sockaddr serveraddr sizeofserveraddr

         Receive message from server
        int len  recvfromclientsocket char buffer BUFFERSIZE 0 NULL NULL
        bufferlen  0
        printfServer sn buffer
    

    closeclientsocket
    return 0
  fgets   scanf         ","# include < stdio.h > # include < stdlib.h > # include < string.h > # include < unistd.h > # include < arpa/inet.h > # define SERVER_IP `` 169.254.14.229 '' // Replace server 's IP address # define PORT 8080 # define BUFFER_SIZE 1024 int main ( ) { int client_socket ; struct sockaddr_in server_addr ; // Create socket ( ( client_socket = socket ( AF_INET , SOCK_DGRAM , 0 ) ) < 0 ) { perror ( `` socket creation failed '' ) ; exit ( EXIT_FAILURE ) ; } memset ( & server_addr , 0 , sizeof ( server_addr ) ) ; // Configure server address server_addr.sin_family = AF_INET ; server_addr.sin_port = htons ( PORT ) ; ( inet_pton ( AF_INET , SERVER_IP , & server_addr.sin_addr ) < = 0 ) { perror ( `` Invalid address/ Address supported '' ) ; exit ( EXIT_FAILURE ) ; } char buffer [ BUFFER_SIZE ] ; ( 1 ) { // Send message server printf ( `` Client ( ) : `` ) ; fgets ( buffer , BUFFER_SIZE , stdin ) ; sendto ( client_socket , ( const char * ) buffer , strlen ( buffer ) , 0 , ( const struct sockaddr * ) & server_addr , sizeof ( server_addr ) ) ; // Receive message server int len = recvfrom ( client_socket , ( char * ) buffer , BUFFER_SIZE , 0 , NULL , NULL ) ; buffer [ len ] = '\0 ' ; printf ( `` Server : % s\n '' , buffer ) ; } close ( client_socket ) ; return 0 ; } 여기서 fgets함수로 문자열을 받았는데 scanf함수로 숫자로 받았으면 좋겠어 그리고 문자열말고 그대로 숫자로 보내게 해줘"
woojinsung-jimmy,Unknown,Unknown
smh9800,Unknown,Unknown
liyongsea,I have a github repo on python how to make it installable through pip install githublink,"github repo python , make installable pip install github_link"
DovieW,"const fs  requirefs
const multer  requiremulter
const puppeteer  requirepuppeteer
const express  requireexpress
const app  express
const port  3001
const path  requirepath
const storage  multerdiskStorage
  destination functionreq file cb 
    cbnull uploads
  
  filename functionreq file cb 
    const date  new Date
    const formattedDate  dategetFullYeardategetMonth  1dategetDatedategetHoursdategetMinutesdategetSeconds
    const fileName  formattedDatefileoriginalname
    cbnull fileName
  

const upload  multer storage storage 
const serveIndex  requireserveindex

 appusegenerated expressstaticpathjoindirname generated serveIndexpathjoindirname generated icons true
 appuseuploads expressstaticpathjoindirname uploads serveIndexpathjoindirname uploads icons true

apppostapiupload uploadsinglefile req res  
  const bookName fontSize papersCount  reqquery

  const date  new Date
  const id  dategetFullYeardategetMonth  1dategetDatedategetHoursdategetMinutesdategetSecondsbookNamefontSize

  function writeToInProgresstext 
    consolelogtext
    const inProgressPath  pathjoindirname generated INPROGRESSidtxt
    fswriteFileSyncinProgressPath text
  

  setImmediateasync   
    try 
      await runreq id bookName fontSize
     catch error 
      consoleerrorerror
      writeToInProgressERROR   errortoString
    
  

  async function runreq id bookName fontSize 
    const browser  await puppeteerlaunch
      protocolTimeout 1000000
    
    const page  await browsernewPage
    const inProgressPath  pathjoindirname generated INPROGRESSidtxt

    pageonconsole pageIndex  
      writeToInProgressCreating sheet pageIndextext  2 of papersCountish
    

     await pagesetViewport width 816 height 1056 

    let text  fsreadFileSyncreqfilepath utf8
    
    await pagegotofiledirnamepagehtml
    
    await pageaddStyleTagcontent body  fontsize fontSizepx 

    writeToInProgressCreating bookName

    await pageevaluatetext bookName  
      let pageIndex  0
      const words  textsplit 
      let blocks  
      let currentBlockIndex  0
      let currentBlock
      let isCurrentPageFront  true  tracks whether the next page to be rendered is on the front of the double sided sheet the side with the big header

      function createNewPagewordsLeft 
        consolelogpageIndex1
        const page  documentcreateElementdiv
        pageclassName  page

         create grid cells
        const grid  documentcreateElementdiv
        gridclassName  gridcontainer
        for let i  0 i  16 i 
          const gridItem  documentcreateElementdiv
          gridItemclassName  griditem

           Determine padding classes for Improved Padding
          let paddingClass  
           Rows
          if i  4   Row 1 bottom padding
            paddingClass  padbottom 
           else if i  4  i  12   Rows 2 and 3 top and bottom padding
            paddingClass  padtop padbottom 
           else   Row 4 top padding
            paddingClass  padtop 
          
           Columns
          if i  4  1   Second cell from the left in each row right padding for crease
            paddingClass  padright
           else if i  4  2   Third cell from the left in each row left padding for crease
            paddingClass  padleft
          
          gridItemclassName   paddingClass

          if i  0  isCurrentPageFront  
            gridItemid  header  pageIndex
           else if i  4  0   if its the first cell in a row
            const miniSheetNum  documentcreateElementspan
            miniSheetNumclassListaddminiSheetNum  pageIndex
            miniSheetNumclassListaddminiSheetNum
            miniSheetNumtextContent  0000
            gridItemappendChildminiSheetNum
          
          gridappendChildgridItem
        

        pageappendChildgrid
        documentbodyappendChildpage

        if isCurrentPageFront 
          isCurrentPageFront  false
          const header  documentcreateElementdiv
          const sheetNum  documentcreateElementh3
          const title  documentcreateElementh3
          
          headerclassName  header
          sheetNumtextContent  0000
          sheetNumid  sheetNum  pageIndex
          if bookName titletextContent      bookName

          headerappendChildsheetNum
          headerappendChildtitle

          const wordCountEl  documentcreateElementh4
          wordCountEltextContent      IntlNumberFormatformatwordsLeft   words 
          headerappendChildwordCountEl

          documentquerySelectorheader  pageIndexappendChildheader
         else 
          isCurrentPageFront  true
        
        
        blocks  ArrayfromdocumentquerySelectorAllgriditem

        pageIndex
      
      createNewPagewordslength

       Populate grid items
      currentBlock  blockscurrentBlockIndex
      for let i  0 i  wordslength i 
        currentBlockinnerHTML     wordsi

         If the word made the block overflow remove it from the block
        if currentBlockscrollHeight  currentBlockclientHeight 
          currentBlockinnerHTML  currentBlockinnerHTMLslice0 currentBlockinnerHTMLlength  wordsilength

           Move to the next block
          currentBlockIndex
          if currentBlockIndex  blockslength 
            createNewPagewordslength  i  Create a new page if all blocks are filled
            currentBlockIndex  blockslength  16  Reset the block index to the first block of the new page
          
          currentBlock  blockscurrentBlockIndex
          currentBlockinnerHTML     wordsi  Add the word to the new block
        
      

       Populate headers
      const SHEETSAMOUNT  MathceilpageIndex  2
      isCurrentPageFront  true
      for let i  0 i  pageIndex i 
        const SHEETNUM  Mathceili1  2SHEETSAMOUNT
        let miniSheetNums  documentquerySelectorAllminiSheetNum  i

        forlet i  0 i  miniSheetNumslength i 
          miniSheetNumsitextContent  SHEETNUM
        

        if isCurrentPageFront 
          isCurrentPageFront  false
          documentquerySelectorsheetNum  itextContent  SHEETNUM
         else 
          isCurrentPageFront  true
        
      

       remove empty grid items on final page
      const allGridItems  documentquerySelectorAllgriditem
      const last16GridItems  ArrayfromallGridItemsslice15
      last16GridItemsforEachblock index  
        const cloneBlock  blockcloneNodetrue
        const spanElement  cloneBlockquerySelectorminiSheetNum
        if spanElement 
          spanElementremove
        
        if cloneBlocktextContenttrim   
          blockremove
        
      
     text bookName

    writeToInProgressFinished creating pages Writing to file

    let htmlContent  await pagecontent
    const pageHtml  pathjoindirname pageHtmlhtml
    fswriteFileSyncpageHtml htmlContent

    const pdf  await pagepdf format Letter 
    const pdfOutput  pathjoindirname generated idpdf
    fswriteFileSyncpdfOutput pdf

    await browserclose

     Delete the INPROGRESS file after PDF is created
    if fsexistsSyncinProgressPath 
      fsunlinkSyncinProgressPath
    
  
  
  resjson message PDF creation started id 


appgetapidownload req res  
  const  id   reqquery
  const pdfOutput  pathjoindirname generated idpdf
  const inProgressPath  pathjoindirname generated INPROGRESSidtxt

  if fsexistsSyncpdfOutput 
    resredirectgeneratedidpdf
   else if fsexistsSyncinProgressPath 
    ressendfsreadFileSyncinProgressPath utf8
   else 
    return ressendNot started Its either in the queue or failed entirely
  


applistenport   
  consolelogListening on port port


how can i improve the performance of this program","const fs = require ( 'fs ' ) ; const multer = require ( 'multer ' ) ; const puppeteer = require ( 'puppeteer ' ) ; const express = require ( 'express ' ) ; const app = express ( ) ; const port = 3001 ; const path = require ( 'path ' ) ; const storage = multer.diskStorage ( { destination : function ( req , file , cb ) { cb ( null , 'uploads/ ' ) } , filename : function ( req , file , cb ) { const date = new Date ( ) ; const formattedDate = ` $ { date.getFullYear ( ) } $ { date.getMonth ( ) + 1 } $ { date.getDate ( ) } $ { date.getHours ( ) } $ { date.getMinutes ( ) } $ { date.getSeconds ( ) } ` ; const fileName = ` $ { formattedDate } _ $ { file.originalname } ` ; cb ( null , fileName ) ; } } ) ; const upload = multer ( { storage : storage } ) ; const serveIndex = require ( 'serve-index ' ) ; // app.use ( '/generated ' , express.static ( path.join ( __dirname , 'generated ' ) ) , serveIndex ( path.join ( __dirname , 'generated ' ) , { 'icons ' : true } ) ) ; // app.use ( '/uploads ' , express.static ( path.join ( __dirname , 'uploads ' ) ) , serveIndex ( path.join ( __dirname , 'uploads ' ) , { 'icons ' : true } ) ) ; app.post ( '/api/upload ' , upload.single ( 'file ' ) , ( req , res ) = > { const { bookName , fontSize , papersCount } = req.query ; const date = new Date ( ) ; const id = ` $ { date.getFullYear ( ) } $ { date.getMonth ( ) + 1 } $ { date.getDate ( ) } $ { date.getHours ( ) } $ { date.getMinutes ( ) } $ { date.getSeconds ( ) } _ $ { bookName } _ $ { fontSize } ` ; function writeToInProgress ( text ) { console.log ( ` $ { text } ` ) ; const inProgressPath = path.join ( __dirname , 'generated ' , ` IN_PROGRESS_ $ { id } .txt ` ) ; fs.writeFileSync ( inProgressPath , text ) ; } setImmediate ( async ( ) = > { try { await run ( req , id , bookName , fontSize ) ; } catch ( error ) { console.error ( error ) ; writeToInProgress ( 'ERROR : ' + error.toString ( ) ) ; } } ) ; async function run ( req , id , bookName , fontSize ) { const browser = await puppeteer.launch ( { protocolTimeout : 1000000 } ) ; const page = await browser.newPage ( ) ; const inProgressPath = path.join ( __dirname , 'generated ' , ` IN_PROGRESS_ $ { id } .txt ` ) ; page.on ( 'console ' , pageIndex = > { writeToInProgress ( ` Creating sheet $ { pageIndex.text ( ) / 2 } $ { papersCount } -ish. ` ) ; } ) ; // await page.setViewport ( { width : 816 , height : 1056 } ) ; let text = fs.readFileSync ( req.file.path , 'utf8 ' ) ; await page.goto ( ` file : // $ { __dirname } /page.html ` ) ; await page.addStyleTag ( { content : ` body { font-size : $ { fontSize } px ; } ` } ) ; writeToInProgress ( ` Creating : $ { bookName } ` ) ; await page.evaluate ( ( text , bookName ) = > { let pageIndex = 0 ; const words = text.split ( ' ' ) ; let blocks = [ ] ; let currentBlockIndex = 0 ; let currentBlock ; let isCurrentPageFront = true ; // tracks whether next page rendered front double sided sheet . side big header function createNewPage ( wordsLeft ) { console.log ( pageIndex+1 ) ; const page = document.createElement ( 'div ' ) ; page.className = 'page ' ; // create grid cells const grid = document.createElement ( 'div ' ) ; grid.className = 'grid-container ' ; ( let = 0 ; < 16 ; i++ ) { const gridItem = document.createElement ( 'div ' ) ; gridItem.className = 'grid-item ' ; // Determine padding classes Improved Padding let paddingClass = `` ; // Rows ( < 4 ) { // Row 1 ( bottom padding ) paddingClass += 'pad-bottom ' ; } else ( > = 4 & & < 12 ) { // Rows 2 3 ( top bottom padding ) paddingClass += 'pad-top pad-bottom ' ; } else { // Row 4 ( top padding ) paddingClass += 'pad-top ' ; } // Columns ( % 4 === 1 ) { // Second cell left row , right padding crease paddingClass += 'pad-right ' ; } else ( % 4 === 2 ) { // Third cell left row , left padding crease paddingClass += 'pad-left ' ; } gridItem.className += ` $ { paddingClass } ` ; ( === 0 & & isCurrentPageFront ) { gridItem.id = 'header ' + pageIndex ; } else ( % 4 === 0 ) { // 's first cell row const miniSheetNum = document.createElement ( 'span ' ) ; miniSheetNum.classList.add ( 'miniSheetNum ' + pageIndex ) ; miniSheetNum.classList.add ( 'miniSheetNum ' ) ; miniSheetNum.textContent = '00/00 ' ; gridItem.appendChild ( miniSheetNum ) ; } grid.appendChild ( gridItem ) ; } page.appendChild ( grid ) ; document.body.appendChild ( page ) ; ( isCurrentPageFront ) { isCurrentPageFront = false ; const header = document.createElement ( 'div ' ) ; const sheetNum = document.createElement ( 'h3 ' ) ; const title = document.createElement ( 'h3 ' ) ; header.className = 'header ' ; sheetNum.textContent = '00/00 ' ; sheetNum.id = 'sheetNum ' + pageIndex ; ( bookName ) title.textContent = ' - ' + bookName ; header.appendChild ( sheetNum ) ; header.appendChild ( title ) ; const wordCountEl = document.createElement ( 'h4 ' ) ; wordCountEl.textContent = ' [ ' + Intl.NumberFormat ( ) .format ( wordsLeft ) + ' words ] ' ; header.appendChild ( wordCountEl ) ; document.querySelector ( ' # header ' + pageIndex ) .appendChild ( header ) ; } else { isCurrentPageFront = true ; } blocks = Array.from ( document.querySelectorAll ( '.grid-item ' ) ) ; pageIndex++ ; } createNewPage ( words.length ) ; // Populate grid items currentBlock = blocks [ currentBlockIndex ] ; ( let = 0 ; < words.length ; i++ ) { currentBlock.innerHTML += ' ' + words [ ] ; // word made block overflow , remove block ( currentBlock.scrollHeight > currentBlock.clientHeight ) { currentBlock.innerHTML = currentBlock.innerHTML.slice ( 0 , currentBlock.innerHTML.length - words [ ] .length ) ; // Move next block currentBlockIndex++ ; ( currentBlockIndex > = blocks.length ) { createNewPage ( words.length - ) ; // Create new page blocks filled currentBlockIndex = blocks.length - 16 ; // Reset block index first block new page } currentBlock = blocks [ currentBlockIndex ] ; currentBlock.innerHTML += ' ' + words [ ] ; // Add word new block } } // Populate headers const SHEETS_AMOUNT = Math.ceil ( pageIndex / 2 ) ; isCurrentPageFront = true ; ( let = 0 ; < pageIndex ; i++ ) { const SHEET_NUM = ` $ { Math.ceil ( ( i+1 ) / 2 ) } / $ { SHEETS_AMOUNT } ` ; let miniSheetNums = document.querySelectorAll ( '.miniSheetNum ' + ) ; ( let = 0 ; < miniSheetNums.length ; i++ ) { miniSheetNums [ ] .textContent = SHEET_NUM ; } ( isCurrentPageFront ) { isCurrentPageFront = false ; document.querySelector ( ' # sheetNum ' + ) .textContent = SHEET_NUM ; } else { isCurrentPageFront = true ; } } // remove empty grid items final page const allGridItems = document.querySelectorAll ( '.grid-item ' ) ; const last16GridItems = Array.from ( allGridItems ) .slice ( -15 ) ; last16GridItems.forEach ( ( block , index ) = > { const cloneBlock = block.cloneNode ( true ) ; const spanElement = cloneBlock.querySelector ( '.miniSheetNum ' ) ; ( spanElement ) { spanElement.remove ( ) ; } ( cloneBlock.textContent.trim ( ) === `` ) { block.remove ( ) ; } } ) ; } , text , bookName ) ; writeToInProgress ( 'Finished creating pages . Writing file ... ' ) ; let htmlContent = await page.content ( ) ; const pageHtml = path.join ( __dirname , ` pageHtml.html ` ) ; fs.writeFileSync ( pageHtml , htmlContent ) ; const pdf = await page.pdf ( { format : 'Letter ' } ) ; const pdfOutput = path.join ( __dirname , 'generated ' , ` $ { id } .pdf ` ) ; fs.writeFileSync ( pdfOutput , pdf ) ; await browser.close ( ) ; // Delete IN_PROGRESS file PDF created ( fs.existsSync ( inProgressPath ) ) { fs.unlinkSync ( inProgressPath ) ; } } res.json ( { message : 'PDF creation started . ' , id } ) ; } ) ; app.get ( '/api/download/ ' , ( req , res ) = > { const { id } = req.query ; const pdfOutput = path.join ( __dirname , 'generated ' , ` $ { id } .pdf ` ) ; const inProgressPath = path.join ( __dirname , 'generated ' , ` IN_PROGRESS_ $ { id } .txt ` ) ; ( fs.existsSync ( pdfOutput ) ) { res.redirect ( ` /generated/ $ { id } .pdf ` ) ; } else ( fs.existsSync ( inProgressPath ) ) { res.send ( fs.readFileSync ( inProgressPath , 'utf8 ' ) ) ; } else { return res.send ( 'Not started . It\ 's either queue , failed entirely . ' ) ; } } ) ; app.listen ( port , ( ) = > { console.log ( ` Listening port $ { port } ` ) ; } ) ; improve performance program"
eguneys,"I found an open source library that generates sound programmatically by using some formulas to operate on various waveforms i will paste some related code now and I want to ask about how they come up with these formulas I am looking for information references and tutorials 

  var generate  duration fn fading  true  
    var audioBuffer  audioCtxcreateBuffer1 sampleRate  duration sampleRate
    var buffer  audioBuffergetChannelData0
    var N  audioBufferlength
    var anim  0
    for var i  0 i  N i 
      var p  i  N
      var envelope  1  p
      if fading  envelope  1 
      bufferi  fni44100sampleRate  envelope
    
    return audioBuffer
  




  var sin  i  MathminMathmaxMathsini 1 1
  var saw  i  i  628314628
  var sqr  i  MathminMathmaxMathsini  1000 1 1
  var win  i ts te  
    if its44100  ite44100 return 0
    return 1  i44100  tste  ts
  
  var note  i tone time dur  001sqri  80Mathpow2tone12  winitimetimedur
  var hhat  i time  002Mathrandom  winitimetime006



     Transition animation   Gate whirring open  noise of steam
    gateOpenSound  generate1 i  
      return 005  sqri250  sini3000  01  Mathrandom  wini 0 1
    

     Buy an item ding  ding
    buySound  generate07 i  
      return 007  sawi19  wini 0 015  sawi11  wini 01 07
    
","found open source library generates sound programmatically using formulas operate various waveforms , paste related code want ask come formulas , looking information , references tutorials var generate = ( duration , fn , fading = true ) = > { var audioBuffer = audioCtx.createBuffer ( 1 , sampleRate * duration , sampleRate ) ; var buffer = audioBuffer.getChannelData ( 0 ) ; var N = audioBuffer.length ; var anim = 0 ; ( var = 0 ; < N ; i++ ) { var p = / N ; var envelope = 1 - p ; ( ! fading ) { envelope = 1 ; } buffer [ ] = fn ( * 44100/sampleRate ) * envelope ; } return audioBuffer ; } var sin = ( ) = > Math.min ( Math.max ( Math.sin ( ) , -1 ) , 1 ) var saw = ( ) = > ( ( % 6.28 ) -3.14 ) /6.28 ; var sqr = ( ) = > Math.min ( Math.max ( Math.sin ( ) * 1000 , -1 ) , 1 ) var win = ( , ts , te ) = > { ( < ts * 44100 || > te * 44100 ) { return 0 ; } return 1 - ( ( i/44100 ) - ts ) / ( te - ts ) ; } var note = ( , tone , time , dur ) = > 0.01 * sqr ( / ( 80/Math.pow ( 2 , tone/12 ) ) ) * win ( , time , time+dur ) ; var hhat = ( , time ) = > 0.02 * Math.random ( ) * win ( , time , time+0.06 ) ; // Transition animation - Gate whirring open + noise steam gateOpenSound = generate ( 1 , ( ) = > { return 0.05 * sqr ( i/250 ) * ( sin ( i/300 ) +0 ) + 0.1 * Math.random ( ) * win ( , 0 , 1 ) ; } ) ; // Buy item ( ding + ding ) buySound = generate ( 0.7 , ( ) = > { return 0.07 * ( saw ( i/19 ) * win ( , 0 , 0.15 ) + saw ( i/11 ) * win ( , 0.1 , 0.7 ) ) ; } ) ;"
mccaffary,"Consider the following 20x20 grid of numbers

08 02 22 97 38 15 00 40 00 75 04 05 07 78 52 12 50 77 91 08
49 49 99 40 17 81 18 57 60 87 17 40 98 43 69 48 04 56 62 00
81 49 31 73 55 79 14 29 93 71 40 67 53 88 30 03 49 13 36 65
52 70 95 23 04 60 11 42 69 24 68 56 01 32 56 71 37 02 36 91
22 31 16 71 51 67 63 89 41 92 36 54 22 40 40 28 66 33 13 80
24 47 32 60 99 03 45 02 44 75 33 53 78 36 84 20 35 17 12 50
32 98 81 28 64 23 67 10 26 38 40 67 59 54 70 66 18 38 64 70
67 26 20 68 02 62 12 20 95 63 94 39 63 08 40 91 66 49 94 21
24 55 58 05 66 73 99 26 97 17 78 78 96 83 14 88 34 89 63 72
21 36 23 09 75 00 76 44 20 45 35 14 00 61 33 97 34 31 33 95
78 17 53 28 22 75 31 67 15 94 03 80 04 62 16 14 09 53 56 92
16 39 05 42 96 35 31 47 55 58 88 24 00 17 54 24 36 29 85 57
86 56 00 48 35 71 89 07 05 44 44 37 44 60 21 58 51 54 17 58
19 80 81 68 05 94 47 69 28 73 92 13 86 52 17 77 04 89 55 40
04 52 08 83 97 35 99 16 07 97 57 32 16 26 26 79 33 27 98 66
88 36 68 87 57 62 20 72 03 46 33 67 46 55 12 32 63 93 53 69
04 42 16 73 38 25 39 11 24 94 72 18 08 46 29 32 40 62 76 36
20 69 36 41 72 30 23 88 34 62 99 69 82 67 59 85 74 04 36 16
20 73 35 29 78 31 90 01 74 31 49 71 48 86 81 16 23 57 05 54
01 70 54 71 83 51 54 69 16 92 33 48 61 43 52 01 89 19 67 48

Starting at the number 26 in the ninth column of the seventh row and going diagonally down and to the right you find the numbers 26 63  78 and 14

The product of these numbers is 1788696

What is the greatest product of four adjacent numbers in the same direction up down left right or diagonally in the 20x20 grid","Consider following 20x20 grid numbers : 08 02 22 97 38 15 00 40 00 75 04 05 07 78 52 12 50 77 91 08 49 49 99 40 17 81 18 57 60 87 17 40 98 43 69 48 04 56 62 00 81 49 31 73 55 79 14 29 93 71 40 67 53 88 30 03 49 13 36 65 52 70 95 23 04 60 11 42 69 24 68 56 01 32 56 71 37 02 36 91 22 31 16 71 51 67 63 89 41 92 36 54 22 40 40 28 66 33 13 80 24 47 32 60 99 03 45 02 44 75 33 53 78 36 84 20 35 17 12 50 32 98 81 28 64 23 67 10 26 38 40 67 59 54 70 66 18 38 64 70 67 26 20 68 02 62 12 20 95 63 94 39 63 08 40 91 66 49 94 21 24 55 58 05 66 73 99 26 97 17 78 78 96 83 14 88 34 89 63 72 21 36 23 09 75 00 76 44 20 45 35 14 00 61 33 97 34 31 33 95 78 17 53 28 22 75 31 67 15 94 03 80 04 62 16 14 09 53 56 92 16 39 05 42 96 35 31 47 55 58 88 24 00 17 54 24 36 29 85 57 86 56 00 48 35 71 89 07 05 44 44 37 44 60 21 58 51 54 17 58 19 80 81 68 05 94 47 69 28 73 92 13 86 52 17 77 04 89 55 40 04 52 08 83 97 35 99 16 07 97 57 32 16 26 26 79 33 27 98 66 88 36 68 87 57 62 20 72 03 46 33 67 46 55 12 32 63 93 53 69 04 42 16 73 38 25 39 11 24 94 72 18 08 46 29 32 40 62 76 36 20 69 36 41 72 30 23 88 34 62 99 69 82 67 59 85 74 04 36 16 20 73 35 29 78 31 90 01 74 31 49 71 48 86 81 16 23 57 05 54 01 70 54 71 83 51 54 69 16 92 33 48 61 43 52 01 89 19 67 48 Starting number `` 26 '' ninth column seventh row , going diagonally right , find numbers 26 , 63 , 78 14 . product numbers 1788696 . greatest product four adjacent numbers direction ( , , left , right , diagonally ) 20x20 grid ?"
marcusziade,"Make this so it caches the data preventing users spamming the API for no reason

import Foundation

final class GitHubService 
    
    static let shared  GitHubService
    
    private init 
    
    func fetchT Codableendpoint Endpoint async throws  T 
        var components  URLComponents
        componentsscheme  http
        componentshost  endpointbaseURL
        componentsport  8080
        componentspath  endpointpath
        componentsqueryItems  endpointqueryItems
        
        guard let url  componentsurl else 
            throw APIErrorinvalidURL
        
        
        var request  URLRequesturl url
        requesthttpMethod  endpointhttpMethod
        requestaddValueBearer KeysgithubAPIKey forHTTPHeaderField Authorization
        requestaddValueapplicationvndgithubjson forHTTPHeaderField Accept
        requestaddValueapplicationjson forHTTPHeaderField ContentType
        requestaddValue20221128 forHTTPHeaderField XGitHubApiVersion
        
        let data   try await sessiondatafor request
        
        do 
            let decodedData  try jsonDecoderdecodeTself from data
            return decodedData
         catch 
            throw APIErrorinvalidData
        
    
    
     MARK Private
    
    private let session  URLSessionshared
    
    private let jsonDecoder JSONDecoder  
        let d  JSONDecoder
        dkeyDecodingStrategy  convertFromSnakeCase
        return d
    


enum APIError Error 
    case invalidURL
    case invalidData

","Make caches data preventing users spamming API reason import Foundation final class GitHubService { static let shared = GitHubService ( ) private init ( ) { } func fetch < : Codable > ( endpoint : Endpoint ) async throws - > { var components = URLComponents ( ) components.scheme = `` http '' components.host = endpoint.baseURL components.port = 8080 components.path = endpoint.path components.queryItems = endpoint.queryItems guard let url = components.url else { throw APIError.invalidURL } var request = URLRequest ( url : url ) request.httpMethod = endpoint.httpMethod request.addValue ( `` Bearer \ ( Keys.githubAPIKey ) '' , forHTTPHeaderField : `` Authorization '' ) request.addValue ( `` application/vnd.github+json '' , forHTTPHeaderField : `` Accept '' ) request.addValue ( `` application/json '' , forHTTPHeaderField : `` Content-Type '' ) request.addValue ( `` 2022-11-28 '' , forHTTPHeaderField : `` X-GitHub-Api-Version '' ) let ( data , _ ) = try await session.data ( : request ) { let decodedData = try jsonDecoder.decode ( T.self , : data ) return decodedData } catch { throw APIError.invalidData } } // MARK : Private private let session = URLSession.shared private let jsonDecoder : JSONDecoder = { let = JSONDecoder ( ) d.keyDecodingStrategy = .convertFromSnakeCase return } ( ) } enum APIError : Error { case invalidURL case invalidData }"
fczuardi,I need help using chatgpt api to create a rapper composer that uses bip39 wordlist to rhyme and create rap verses on user demand,need help using chatgpt api create rapper composer uses bip39 wordlist rhyme create rap verses user demand
purpleslurple,What are some ways that I can identify the source of a given document,ways identify source given document
wolfgangmeyers,"I have a challenge for you Im working in a reacttypescript application that allows users to generate images with AI and Im working on removing what remains of the backend One piece I need to address is the saved images that people have saved on my server There is an api client that fetches images from the backend right now and another component that caches most of the payload for each image locally Id like to refactor the images cache to fetch from google drive instead  the user will first need to authorize this

There is an image record and image png files to go with it thumbnail and image I need you to write a class that can save image record payloads image files paginate through images by timestamp and get a presigned url or if we have to just load the image data into base64 image url for the image files User should be able to delete them as well Do you have any questions or can you write that class I dont have much experience working with google drive","challenge . 'm working react/typescript application allows users generate images AI , 'm working removing remains backend . One piece need address `` saved images '' people saved server . api client fetches images backend right , another component caches payload image locally . 'd like refactor images cache fetch google drive instead - user first need authorize . image record , image png files go ( thumbnail image ) . need write class save image record payloads , image files , paginate images timestamp , get presigned url ( , load image data base64 image url ) image files . User able delete well . questions , write class ? n't much experience working google drive ."
KastanDay,"Help refactor this to be cleaner We want to use a single list of supported file types and match each file to the proper handler function Maybe map will help Not sure Please use best practices 

  def bulkingestself s3paths UnionListstr str coursename str kwargs  Dictstr Liststr
     httpspythonlangchaincomenlatestmodulesindexesdocumentloadersexamplesmicrosoftwordhtml
    successstatus  successingest  failureingest 

    try
      if isinstances3paths str
        s3paths  s3paths

      for s3path in s3paths
        ext  Paths3pathsuffix   check mimetype of file
         TODO no need to download just guesstype against the s3path
        with NamedTemporaryFilesuffixext as tmpfile
          selfs3clientdownloadfileobjBucketosenvironS3BUCKETNAME Keys3path Fileobjtmpfile
          mimetype  mimetypesguesstypetmpfilename0
          category subcategory  mimetypesplit
        
        if s3pathendswithhtml
          ret  selfingesthtmls3path coursename kwargskwargs
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif s3pathendswithpy
          ret  selfingestsinglepys3path coursename
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif s3pathendswithvtt
          ret  selfingestsinglevtts3path coursename
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif s3pathendswithpdf
          ret  selfingestsinglepdfs3path coursename kwargskwargs
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif s3pathendswithtxt or s3pathendswithmd
          ret  selfingestsingletxts3path coursename
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif s3pathendswithsrt
          ret  selfingestsinglesrts3path coursename
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif s3pathendswithdocx
          ret  selfingestsingledocxs3path coursename
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif s3pathendswithppt or s3pathendswithpptx
          ret  selfingestsingleppts3path coursename
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
        elif category  video or category  audio
          ret  selfingestsinglevideos3path coursename
          if ret  Success
            successstatusfailureingestappends3path
          else
            successstatussuccessingestappends3path
      return successstatus
    except Exception as e
      successstatusfailureingestappendMAJOR ERROR IN bulkingest Error   stre
      return successstatus","Help refactor cleaner . want use single list supported file types match file proper handler function . Maybe map help ? sure . Please use best practices . def bulk_ingest ( self , s3_paths : Union [ List [ str ] , str ] , course_name : str , * * kwargs ) - > Dict [ str , List [ str ] ] : # https : //python.langchain.com/en/latest/modules/indexes/document_loaders/examples/microsoft_word.html success_status = { `` success_ingest '' : [ ] , `` failure_ingest '' : [ ] } try : isinstance ( s3_paths , str ) : s3_paths = [ s3_paths ] s3_path s3_paths : ext = Path ( s3_path ) .suffix # check mimetype file # TODO : need download , guess_type s3_path ... NamedTemporaryFile ( suffix=ext ) tmpfile : self.s3_client.download_fileobj ( Bucket=os.environ [ 'S3_BUCKET_NAME ' ] , Key=s3_path , Fileobj=tmpfile ) mime_type = mimetypes.guess_type ( tmpfile.name ) [ 0 ] category , subcategory = mime_type.split ( '/ ' ) s3_path.endswith ( '.html ' ) : ret = self._ingest_html ( s3_path , course_name , kwargs=kwargs ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif s3_path.endswith ( '.py ' ) : ret = self._ingest_single_py ( s3_path , course_name ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif s3_path.endswith ( '.vtt ' ) : ret = self._ingest_single_vtt ( s3_path , course_name ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif s3_path.endswith ( '.pdf ' ) : ret = self._ingest_single_pdf ( s3_path , course_name , kwargs=kwargs ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif s3_path.endswith ( '.txt ' ) s3_path.endswith ( '.md ' ) : ret = self._ingest_single_txt ( s3_path , course_name ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif s3_path.endswith ( '.srt ' ) : ret = self._ingest_single_srt ( s3_path , course_name ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif s3_path.endswith ( '.docx ' ) : ret = self._ingest_single_docx ( s3_path , course_name ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif s3_path.endswith ( '.ppt ' ) s3_path.endswith ( '.pptx ' ) : ret = self._ingest_single_ppt ( s3_path , course_name ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) elif category == 'video ' category == 'audio ' : ret = self._ingest_single_video ( s3_path , course_name ) ret ! = `` Success '' : success_status [ 'failure_ingest ' ] .append ( s3_path ) else : success_status [ 'success_ingest ' ] .append ( s3_path ) return success_status except Exception e : success_status [ 'failure_ingest ' ] .append ( `` MAJOR ERROR /bulk_ingest : Error : `` + str ( e ) ) return success_status"
udayhello," File ipythoninput30ddfc2a3977c3 line 2
    img  npinvertnparrayimg
    
IndentationError unexpected indent ","File `` < ipython-input-30-ddfc2a3977c3 > '' , line 2 img = np.invert ( np.array ( [ img ] ) ) ^ IndentationError : unexpected indent"
udayhello," File ipythoninput30ddfc2a3977c3 line 2
    img  npinvertnparrayimg
    
IndentationError unexpected indent ","File `` < ipython-input-30-ddfc2a3977c3 > '' , line 2 img = np.invert ( np.array ( [ img ] ) ) ^ IndentationError : unexpected indent"
jabrena,Given a Java class how to retrieve the public methods programmatically,Given Java class retrieve public methods programmatically ?
jabrena,"Using this bean     Bean
    RouterFunctionServerResponse routes 
        return RouterFunctionsroute
                GEThello request  ServerResponseokbodyHello world
                build
     how to add error handling","Using bean : @ Bean RouterFunction < ServerResponse > routes ( ) { return RouterFunctions.route ( ) .GET ( `` /hello '' , request - > ServerResponse.ok ( ) .body ( `` Hello world '' ) ) .build ( ) ; } add error handling ?"
purpleslurple,I have a document but dont know its source How can I determine its source,"document , ’ know ’ source . determine source ."
namu6747," Incorrect table definition there can be only one auto column and it must be defined as a key

CREATE TABLE stockexampleSTOCK 
	id BIGINT autoincrement NULL

ENGINEInnoDB
DEFAULT CHARSETutf8mb4
COLLATEutf8mb4generalci",Incorrect table definition ; one auto column must defined key ` CREATE TABLE stock_example.STOCK ( id BIGINT auto_increment NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci ; `
cugarteblair,I am using allauth with postgresql in a Django app How does it use a cache table,using allauth postgresql Django app . use cache table ?
pavlovcik,"hey help me brainstorm i need to create an x banner for our booth at a conference

dimensions are 60cm wide and 180 cm tall

we are promoting our crypto decentralized bounty system which is a bot on github and we also are serving cocktails ",hey help brainstorm need create `` x '' banner booth conference . dimensions 60cm wide 180 cm tall promoting crypto decentralized bounty system bot github also serving cocktails
csrsaviar,write a note to recruiters at quill audit for an internship role in web3 security  provided that i have an idea and knowledge of the cybersecurity space and currently i am shifting to web 3 security and this current internship opportunity will help me at this,write note recruiters quill audit internship role web3 security - provided idea knowledge cybersecurity space currently shifting web 3 security current internship opportunity help
harigopal,"yaml 

 and  symbol",yaml > | symbol
micartey,How can I use asm to generate executer methods for my reflection based event System to gain performance,use asm generate executer methods reflection based event System gain performance
Sricharan2k3,"playerplayeridnamegameaccountbalancelocationpincode
matchesmatchidtypeofgamelocation
transactionstransidplayeridbetamount
citypincodename

write a sql query for 
find the player name who has lost maximum amoung in bets","player ( player_id , name , game_account_balance , location_pincode ) matches ( match_id , type_of_game , location ) transactions ( trans_id , player_id , bet_amount ) city ( pincode , name ) write sql query find player name lost maximum amoung bets"
alesanchezr,"I want to refactor my evenbrite organizer information this informations is displayed on every event but also in organizer profile this are the fields I am allowed to update

 Organizer name
 Organizer bio
 Organizer website
 Description for event pages
 Social media profiles

What would be the best strategy copy and information I should include to get better and more attendees","want refactor evenbrite organizer information , informations displayed every event also organizer profile , fields allowed update : - Organizer name - Organizer bio - Organizer website - Description event pages - Social media profiles would best strategy , copy information include get better attendees ."
sachinmehta07,Create simple Android application using room database to store nd retrieve data  nd java in app create table as stickerdata and columns are ID  STRING PACKNAME STRING CREATORNAMEPACKICON DATA TYPE FOR THIS IS URI ND STICKER LIST FOR THIS DATA TYPE IS LISTURI ,"Create simple Android application using room database store nd retrieve data , nd java , app create table sticker_data columns ID , STRING PACKNAME , STRING CREATORNAME , PACKICON DATA TYPE URI ND STICKER LIST DATA TYPE ( LIST < URI > )"
arunbatchu,how can i make github notifications show up in discord,make github notifications show discord
Vandivier,in education and learning science summarize Mastery Learning and The Super Mario Effect Are they at odds Why or why not,"education learning science , summarize Mastery Learning Super Mario Effect . odds ? ?"
tisztamo,"You are Junior an AI system aiding developers
You are working with a part of a large program called the Working Set
Before starting check if you need more files to solve the task
Do not edit files without knowing their contents
Ask for them in normal conversational format instead

 Working set

docsREADMEmd

Warn This README is AI generated just like all the source files of this project

 Junior  Your AI contributor which codes itself

Video Junior codes itselfassetsvideocoverjpghttpsyoutubeNL4uFJSvfW0

Video Junior codes itself
 Description

Junior is an AIfirst IDE designed from the ground up to leverage language models This project allows developers to communicate with the AI and supervise the development process

Isnt that already possible with ChatGPT No LLMs have very limited working memory so it is not possible to directly work with them on large codebases

By providing specific task details in a prompt descriptor and highlighting the relevant parts of your project you can delegate code implementation documentation testing and more to your AI Junior

 Getting Started

For more details on getting started please refer to usagemdusagemd

 Contributing and Support

Contributions are welcome Remember we eat our own dog food in this project Junior is designed to write itself Your main role will be to oversee the work provide detailed prompts and review the outcomes

For support please create an issue in the GitHub repository

Note For meaningful results its recommended to use the GPT4 model or a more recent version



READMEmd

Docs Junior DocumentationhttpsimgshieldsiobadgedocsJuniorbluehttpstisztamogithubioJunior
Warn This README is AI generated just like all the source files of this project

 Junior  Your AI contributor which codes itself

Video Junior codes itselfdocsassetsvideocoverjpghttpsyoutubeNL4uFJSvfW0

Video Junior codes itself

 Description

Junior is an AIfirst IDE designed from the ground up to leverage language models Just like how Linus Torvalds oversees the Linux Kernel development without coding himself this project allows developers to communicate with the AI and supervise the development process

By providing specific task details in a prompt descriptor and highlighting the relevant parts of your project you can delegate code implementation documentation testing and more to your AI Junior

 Getting Started

 Installation

To install clone the repository and run npm install in the root directory Additionally you can install the Junior vscode extension from the vscode extension marketplace

 Usage

 Web Interface

Run the application with npm start to start a local server where you can generate a prompt and automatically copy it to paste into ChatGPT The web interface is designed for use with ChatGPT Pro and doesnt require an API key For more information about the web interface please refer to docswebmddocswebmd

 Commandline interface CLI

To start the CLI use npm run cli This mode uses the ChatGPT API and youll need an API key stored in the OPENAIAPIKEY environment variable

 The Prompt Descriptor

A prompt descriptor is a YAML file promptyaml outlining the details necessary for generating a task prompt for the AI model

Each element in the descriptor serves a specific purpose
 task Describes the task type and scope For example featureimplement bugfix or refactor You can check out the prompttaskfeatureimplementmdprompttaskfeatureimplementmd file as an example
 attention Lists the files and directories most relevant to the task
 requirements Describes the actual task in a humanreadable format
 format Determines how the output will be formatted

 Attention Mechanism

The attention mechanism guides the AI model by providing it with a working set It helps overcome the limited working memory of large language models

The working set is a subset of the entire project thats currently in focus It includes both files and directories For files the content is directly provided to the AI For directories a brief list of files and subdirectories within them is presented

 Contributing and Support

Contributions are welcome Remember we eat our own dog food in this project Junior is designed to write itself Your main role will be to oversee the work provide detailed prompts and review the outcomes

For support please create an issue in the GitHub repository

Note For meaningful results its recommended to use the GPT4 model or a more recent version




 Task

Improve the documentation

Edit only the one in docs
Make 34AIfirst IDE34 very visible
Remove 34Description34 but not the content under it
There is some info about Linus in the other readme mention it
Write a sentence about Junior being built for craftmanship
Junior is configurable hackable simple and auditable
It also has a vision To becoming something like git is now or something LISP was back then
Mention joyfully that git is also created by Linus or what paul Graham wrote about LISP being important in their succees by allowing rapid development


 Output Format

Encode and enclose your results as changesh a shell script that creates and changes files and does everything to solve the task
Files are small avoid using sed in favor of heredocing full files using EOF to prevent substitution

OS OSX

Installed tools npm jq


Do NOT write any text outside the script

EXAMPLE START

sh
binsh
set e
goalTask description max 7 words
echo Plan
echo 1 
Commands solving the task
echo 03332mDone goal0330mn


EXAMPLE END

","Junior , AI system aiding developers . working part large program called `` Working Set . '' starting , check need files solve task . edit files without knowing contents ! Ask normal conversational format instead . # Working set docs/README.md : `` ` Warn : README AI generated , like source files project . # Junior - AI contributor codes . [ ! [ Video : Junior codes ] ( /assets/video_cover.jpg ) ] ( https : //youtu.be/NL4uFJSvfW0 ) * '' Video : Junior codes '' * # # Description Junior AI-first IDE designed ground leverage language models . project allows developers communicate AI supervise development process . n't already possible ChatGPT ? , LLMs limited `` working memory '' , possible directly work large codebases . providing specific task details prompt descriptor highlighting relevant parts project , delegate code implementation , documentation , testing , AI Junior . # # Getting Started details getting started , please refer [ usage.md ] ( usage.md ) . # # Contributing Support Contributions welcome ! Remember , eat dog food project . Junior designed write . main role oversee work , provide detailed prompts , review outcomes . support , please create issue GitHub repository . * * Note : * * meaningful results , 's recommended use GPT-4 model recent version . `` ` README.md : `` ` [ ! [ Docs : Junior Documentation ] ( https : //img.shields.io/badge/docs-Junior-blue ) ] ( https : //tisztamo.github.io/Junior/ # / ) Warn : README AI generated , like source files project . # Junior - AI contributor codes . [ ! [ Video : Junior codes ] ( docs/assets/video_cover.jpg ) ] ( https : //youtu.be/NL4uFJSvfW0 ) * '' Video : Junior codes '' * # # Description Junior AI-first IDE designed ground leverage language models . like Linus Torvalds oversees Linux Kernel development without coding , project allows developers communicate AI supervise development process . providing specific task details prompt descriptor highlighting relevant parts project , delegate code implementation , documentation , testing , AI Junior . # # Getting Started # # # Installation install , clone repository run ` npm install ` root directory . Additionally , install `` Junior '' vscode extension vscode extension marketplace . # # # Usage # # # # Web Interface Run application ` npm start ` start local server , generate prompt automatically copy paste ChatGPT . web interface designed use ChatGPT Pro n't require API key . information web interface , please refer [ docs/web.md ] ( docs/web.md ) . # # # # Command-line interface ( CLI ) start CLI , use ` npm run cli ` . mode uses ChatGPT API , 'll need API key stored ` OPENAI_API_KEY ` environment variable . # # # Prompt Descriptor prompt descriptor YAML file ( ` prompt.yaml ` ) outlining details necessary generating task prompt AI model . element descriptor serves specific purpose : - ` task ` : Describes task type scope . example , ` feature/implement ` , ` bug/fix ` , ` refactor/ ` . check [ prompt/task/feature/implement.md ] ( prompt/task/feature/implement.md ) file example . - ` attention ` : Lists files directories relevant task . - ` requirements ` : Describes actual task human-readable format . - ` format ` : Determines output formatted . # # # Attention Mechanism attention mechanism guides AI model providing working set . helps overcome limited working memory large language models . working set subset entire project 's currently focus . includes files directories . files , content directly provided AI . directories , brief list files subdirectories within presented . # # Contributing Support Contributions welcome ! Remember , eat dog food project . Junior designed write . main role oversee work , provide detailed prompts , review outcomes . support , please create issue GitHub repository . * * Note : * * meaningful results , 's recommended use GPT-4 model recent version . `` ` # Task Improve documentation ! Edit one docs/ ! Make & # 34 ; AI-first IDE & # 34 ; visible . Remove & # 34 ; Description & # 34 ; , content . info Linus readme , mention ! Write sentence Junior built craftmanship : Junior configurable , hackable , simple auditable . also vision : becoming something like git something LISP back . Mention joyfully git also created Linus , paul Graham wrote LISP important succees allowing rapid development . # Output Format Encode enclose results ./change.sh , shell script creates changes files everything solve task . Files small , avoid using sed favor heredoc-ing full files using 'EOF ' prevent substitution . OS : OSX Installed tools : npm , jq write text outside script ! EXAMPLE START `` ` sh # ! /bin/sh set -e goal= [ Task description , max 7 words ] echo `` Plan : '' echo `` 1 . [ ... ] '' [ Commands solving task ] echo `` \033 [ 32mDone : $ goal\033 [ 0m\n '' `` ` EXAMPLE END"
Richie-Lee,"I am executing an ab test where I have a beta prior for both the treatment and control group Additionally I have empirical data in the form of number of observations and their respective number of conversions

These should give me all the pieces I need to compute a betabinomial bayes factor","executing a/b test , beta prior treatment control group . Additionally , empirical data form number observations respective number conversions . give pieces need compute beta-binomial bayes factor"
maxoja,I want to scrape all songs available on YouTube but Im struggle to figure out what songs are there can you help,"want scrape songs available YouTube 'm struggle figure songs , help ?"
purpleslurple,"I want to make this code theurl  urlencodetheurl
pscontents  
foreach fcontents as linenum  line 
    pattern  ph16linki
    replacement  0a hreffilelocationtheurltheurlpurplinenum idpurplinenumfont colorpurplelinenumfonta 
    pscontents  pregreplacepattern replacement line
","want make code : $ theurl = urlencode ( $ theurl ) ; $ ps_contents = `` '' ; foreach ( $ fcontents $ line_num = > $ line ) { $ pattern = `` / < p [ ^ > ] * > | < h [ 1-6 ] [ ^ > ] * > | < li [ ^nk > ] * > /i '' ; $ replacement = `` \\0 ( < href= ' $ file_location ? theurl= $ theurl # purp $ line_num ' id='purp $ line_num ' > < font color='purple ' > $ line_num < /font > < /a > ) `` ; $ ps_contents .= preg_replace ( $ pattern , $ replacement , $ line ) ; }"
rensanrenren,"httpshuggingfacecojondurbinairoborosgpt35turbo100k7bblobmainREADMEmdcodetrue

",https : //huggingface.co/jondurbin/airoboros-gpt-3.5-turbo-100k-7b/blob/main/README.md ? code=true 何をしているのか解説して
klondikemarlen,Unknown,Unknown
ajschumacher,How can I use matplotlibs imshow with a matrix to guarantee one pixel per value in the matrix,use matplotlib ’ imshow matrix guarantee one pixel per value matrix ?
osamaramihafez,How do I create libraries in node and how do I package them for my own project use,"create libraries node , package project use"
teremterem,In my python library I extensively rely on async queues and it makes it hard to debug my library because in my lib certain kind of processing starts then it is passed to a queue and then the processing is resumed by another task upon receiving a message in a queue How can I maintain the continuity of stack trace in this scenario while still using queues,"python library extensively rely async queues makes hard debug library , lib certain kind processing starts , passed queue processing resumed another task upon receiving message queue . maintain continuity stack trace scenario still using queues ?"
aahnik,"on scroll i want to apply zoom and color effect on my images using tailwind css

currently my design is mostly for desktop screens on mouse hover the images get color and a zoom effect

img
            classhauto maxwfull roundedlg easeinout hoverscale125 transitionall duration300 cursorpointer filter grayscale hovergrayscale0
            src imageimageurl 
            alt imagealttext 
          

now what tailwind utility classes can i apply so that these effects are applied when the user scrolls to the particular image","scroll , want apply zoom color effect images , using tailwind css currently design mostly desktop screens . mouse hover , images get color zoom effect < img class= '' h-auto max-w-full rounded-lg ease-in-out hover : scale-125 transition-all duration-300 cursor-pointer filter grayscale hover : grayscale-0 '' src= '' { { image.image.url } } '' alt= '' { { image.alt_text } } '' / > , tailwind utility classes apply , , effects applied user scrolls particular image ..."
mikedotexe,"I have some Rust code Ill paste This is from a CosmWasm smart contract and without getting too into the details the term agents refers to offchain daemons that are fulfilling a task similar to how oracle nodes call into a smart contract

The problem were facing is it seems that the logic which is meant to evenly distribute tasks among the various agents is instead giving preferential treatment to new agents who have completed relatively less tasks than the other agents That preferential treatment needs to be removed

rs
impla RoundRobinAgentTaskDistributora for AgentTaskDistributor 
    fn getagenttasks
        self
        deps Deps
        env Env
        agentid Addr
        slotitems Optionu64 Optionu64
      ResultAgentTaskResponse ContractError 
        let mut active  AGENTSACTIVEloaddepsstorage
        if activecontainsagentid 
            return ErrContractErrorAgentNotRegistered 
        
        if slotitems  None None 
            return OkAgentTaskResponse 
                stats TaskStats 
                    numblocktasks Uint64zero
                    numcrontasks Uint64zero
                
            
        
        let agentcount  activelen as u64
        let blockslots cronslots  slotitems

        let mut equalizer  slottype SlotType
                             totaltasks u64
          ResultUint64 ContractError 
            if totaltasks  1 
                return OkUint64zero
            
            This sort is unstable ie may reorder equal elements inplace ie does not allocate
            and On log n worstcase
            It is typically faster than stable sorting except in a few special cases
            eg when the slice consists of several concatenated sorted sequences
            activesortunstablebyleft right 
                let stats1  AGENTSTATSloaddepsstorage leftunwrapordefault
                let stats2  AGENTSTATSloaddepsstorage rightunwrapordefault
                match slottype 
                    SlotTypeBlock  stats1
                        completedblocktasks
                        partialcmpstats2completedblocktasks
                        unwrap
                    SlotTypeCron  stats1
                        completedcrontasks
                        partialcmpstats2completedcrontasks
                        unwrap
                
            
            let agentdiffindex  active
                iter
                positionx x  agentid
                okorContractErrorAgentNotRegistered 
                as u64

            if totaltasks  activelen as u64 
                let agenttaskstotal  1u64
                    saturatingsubagentdiffindexsaturatingsubtotaltaskssaturatingsub1
                Okagenttaskstotalinto
             else 
                let leftover  totaltasks  agentcount
                let mut extra  0u64
                if leftover  0 
                    extra  1u64saturatingsub
                        agentdiffindexsaturatingsubleftoversaturatingsub1
                    
                
                let agenttaskstotal  totaltaskssaturatingdivagentcount  extra

                Okagenttaskstotalinto
            
        

        let n  equalizerSlotTypeBlock blockslotsunwrapordefault
        let numblocktasks  n

        let n  equalizerSlotTypeCron cronslotsunwrapordefault
        let numcrontasks  n

        OkAgentTaskResponse 
            stats TaskStats 
                numblocktasks
                numcrontasks
            
        
    

    fn ontaskcompleted
        self
        storage a mut dyn Storage
        env Env
        agentid Addr
        slottype SlotType
      Result ContractError 
        let mut stats  AGENTSTATSmayloadstorage agentidunwrapordefault
        match slottype 
            SlotTypeBlock  statscompletedblocktasks  1
            SlotTypeCron  statscompletedcrontasks  1
        
        AGENTSTATSsavestorage agentid stats
        Ok
    

","Rust code 'll paste . CosmWasm smart contract , without getting details , term `` agents '' refers off-chain daemons fulfilling task similar oracle nodes call smart contract . problem 're facing seems logic , meant evenly distribute tasks among various agents , instead giving preferential treatment new agents completed relatively less tasks agents . preferential treatment needs removed . `` ` rs impl < ' > RoundRobinAgentTaskDistributor < ' > AgentTaskDistributor { fn get_agent_tasks ( & self , deps : & Deps , _env : & Env , agent_id : Addr , slot_items : ( Option < u64 > , Option < u64 > ) , ) - > Result < AgentTaskResponse , ContractError > { let mut active = AGENTS_ACTIVE.load ( deps.storage ) ? ; ! active.contains ( & agent_id ) { return Err ( ContractError : :AgentNotRegistered { } ) ; } slot_items == ( None , None ) { return Ok ( AgentTaskResponse { stats : TaskStats { num_block_tasks : Uint64 : :zero ( ) , num_cron_tasks : Uint64 : :zero ( ) , } , } ) ; } let agent_count = active.len ( ) u64 ; let ( block_slots , cron_slots ) = slot_items ; let mut equalizer = |slot_type : SlotType , total_tasks : u64| - > Result < Uint64 , ContractError > { total_tasks < 1 { return Ok ( Uint64 : :zero ( ) ) ; } //This sort unstable ( i.e. , may reorder equal elements ) , in-place ( i.e. , allocate ) , //and ( n log n ) worst-case . //It typically faster stable sorting , except special cases , //e.g. , slice consists several concatenated sorted sequences . active.sort_unstable_by ( |left , right| { let stats1 = AGENT_STATS.load ( deps.storage , left ) .unwrap_or_default ( ) ; let stats2 = AGENT_STATS.load ( deps.storage , right ) .unwrap_or_default ( ) ; match slot_type { SlotType : :Block = > stats1 .completed_block_tasks .partial_cmp ( & stats2.completed_block_tasks ) .unwrap ( ) , SlotType : :Cron = > stats1 .completed_cron_tasks .partial_cmp ( & stats2.completed_cron_tasks ) .unwrap ( ) , } } ) ; let agent_diff_index = active .iter ( ) .position ( |x| x == & agent_id ) .ok_or ( ContractError : :AgentNotRegistered { } ) ? u64 ; total_tasks < = active.len ( ) u64 { let agent_tasks_total = 1u64 .saturating_sub ( agent_diff_index.saturating_sub ( total_tasks.saturating_sub ( 1 ) ) ) ; Ok ( agent_tasks_total.into ( ) ) } else { let leftover = total_tasks % agent_count ; let mut extra = 0u64 ; leftover > 0 { extra = 1u64.saturating_sub ( agent_diff_index.saturating_sub ( leftover.saturating_sub ( 1 ) ) , ) ; } let agent_tasks_total = total_tasks.saturating_div ( agent_count ) + extra ; Ok ( agent_tasks_total.into ( ) ) } } ; let n = equalizer ( SlotType : :Block , block_slots.unwrap_or_default ( ) ) ? ; let num_block_tasks = n ; let n = equalizer ( SlotType : :Cron , cron_slots.unwrap_or_default ( ) ) ? ; let num_cron_tasks = n ; Ok ( AgentTaskResponse { stats : TaskStats { num_block_tasks , num_cron_tasks , } , } ) } fn on_task_completed ( & self , storage : & ' mut dyn Storage , _env : & Env , agent_id : & Addr , slot_type : SlotType , ) - > Result < ( ) , ContractError > { let mut stats = AGENT_STATS.may_load ( storage , agent_id ) ? .unwrap_or_default ( ) ; match slot_type { SlotType : :Block = > stats.completed_block_tasks += 1 , SlotType : :Cron = > stats.completed_cron_tasks += 1 , } AGENT_STATS.save ( storage , agent_id , & stats ) ? ; Ok ( ( ) ) } } `` `"
RobotsBuildingEducation,"what does this mean

typedef struct studentinfo 
  char  first
  char  last
  int   exam1
  int   exam2
  int   exam3
  float mean
 student
",mean typedef struct student_info { char * first ; char * last ; int exam1 ; int exam2 ; int exam3 ; float mean ; } student ;
vemv,"please write a javascript regex that only matches valid property identifiers

For example a is a valid identifier because xa is valid javascript syntax where x is a variable that stands for an arbitrary object

And 0 is not a valid identifier because x0 isnt valid javascript syntax where x is a variable that stands for an arbitrary object

Please try to stick to official javascript specs if possible

Keep in mind there are many possible identifiers across the Unicode range for instance  and  also are valid","please write javascript regex matches valid property identifiers example `` '' valid identifier ` x.a ` valid javascript syntax , ` x ` variable stands arbitrary object . `` 0 ' valid identifier ` x.0 ` n't valid javascript syntax , ` x ` variable stands arbitrary object . Please try stick official javascript specs possible . Keep mind many possible identifiers across Unicode range , instance ` á ` ` 見 ` also valid ."
Takuzen,how to incorporate autocomplete by Algolia into nextjs app,incorporate autocomplete Algolia next.js app
fredyk,"please explain better this issue for a new developer to accomplish it

httpsgithubcomfredykwestackgoblob4eb5cd373a84ab1a1faac80f4c4733a97e19a109westackmodelmodelrelationsgoL368L373

There is a bug in this last change at modelrelationsgorecursiveExtractFields

and and or operators are splitted based on their contents Some parts of them are applied in match stages before possible lookup stages and other parts are applied later This is an incorrect behavior because and and or should be applied atomically without splitting I suggest keeping a similar behaviour but without splitting those operators just moving the whole stages beforeafter the lookup whether they have new special fields or not","please explain better issue new developer accomplish : https : //github.com/fredyk/westack-go/blob/4eb5cd373a84ab1a1faac80f4c4733a97e19a109/westack/model/modelrelations.go # L368-L373 bug last change ` modelrelations.go # recursiveExtractFields ( ) ` . ` $ ` ` $ ` operators splitted based contents . parts applied ` $ match ` stages possible ` $ lookup ` stages , parts applied later . incorrect behavior , ` $ ` ` $ ` applied atomically , without splitting . suggest keeping similar behaviour , without splitting operators , moving whole stages before/after ` $ lookup ` whether new special fields ."
toshihue,go lang  gin ,go lang で gin を使った開発をするときに単体テストを書く方法を教えてください
sanjarcode,"Is this a correct understanding of Reacts useLayoutEffect

Mental model
component code runs                           React updates DOM  component settles  useEffect runs
component code runs  useLayoutEffect runs  React updates DOM  component settles  useEffect runs


useLayoutEffect has an advantage that it has access to new data but old pagelayout
",correct understanding React 's useLayoutEffect : `` ` Mental model component code runs -- > React updates DOM -- > component settles -- > useEffect runs component code runs -- > useLayoutEffect runs -- > React updates DOM -- > component settles -- > useEffect runs useLayoutEffect advantage access new `` data '' old `` page/layout '' `` `
alesanchezr,"I want to refactor my evenbrite organizer information this informations is displayed on every event but also in organizer profile this are the fields I am allowed to update

 Organizer name
 Organizer bio
 Organizer website
 Description for event pages
 Social media profiles

What would be the best strategy copy and information I should include to get better and more attendees","want refactor evenbrite organizer information , informations displayed every event also organizer profile , fields allowed update : - Organizer name - Organizer bio - Organizer website - Description event pages - Social media profiles would best strategy , copy information include get better attendees ."
DylanHalstead,Give me an example how I could use jwtgo on my go backend and send it to my Vue frontend,Give example could use jwt-go go backend send Vue frontend
colinmegill,is evolution an example of multiobjective optimization,evolution example multi-objective optimization
moom0o,Is there a way to write exif data to a jpg using javascript,way write exif data jpg using javascript .
jabrena,How to run one particular spring boot application and remove specific auto configuration,run one particular spring boot application remove specific auto configuration ?
asemabdelmonem,Make me a source code for a module in Lsposed which make additional button on youtube to download videos into mp4 or mp3 forms,Make source code module Lsposed make additional button youtube download videos mp4 mp3 forms
AronNovak,can i distribute Roboli commands via composer,distribute Robo.li commands via composer ?
FreePhoenix888,"Here is how I transpile my file ts file
      const result  tstranspileModulevalue 
        compilerOptions 
        allowSyntheticDefaultImports true
        experimentalDecorators true
        sourceMap true 
        noImplicitAny false
        removeComments true
        jsx react
        module ESNext
        moduleResolution node
        target ESNext
        skipLibCheck true
        resolveJsonModule true
        esModuleInterop true
        isolatedModules true
      
    
 and I get 
export 
In the end ofthe file I do not want it","transpile file ts file : const result = ts.transpileModule ( value , { `` compilerOptions '' : { `` allowSyntheticDefaultImports '' : true , `` experimentalDecorators '' : true , `` sourceMap '' : true , `` noImplicitAny '' : false , `` removeComments '' : true , `` jsx '' : `` react '' , `` module '' : `` ESNext '' , `` moduleResolution '' : `` node '' , `` target '' : `` ESNext '' , `` skipLibCheck '' : true , `` resolveJsonModule '' : true , `` esModuleInterop '' : true , `` isolatedModules '' : true } } ) ; get ` export { } ; ` end ofthe file . want"
santosomar,create a python script to pick 5 random numbers between 1 and 65 And thank GD,create python script pick 5 random numbers 1 65 . thank GD !
slark-prime,what does it suggest The original model uses padid  1 which means that there is not padding token We cant have the same logic make sure to add a padding token using tokenizeraddspecialtokenspadtokenpad and resize the token embedding accordingly You should also set the modelconfigpadtokenid The embedtokens layer of the model is initialized withselfembedtokens  nnEmbeddingconfigvocabsize confighiddensize selfconfigpaddingidx which makes sure that encoding the padding token will output zeros so passing it when initializing is recommended,"suggest : original model uses pad_id = -1 means padding token . ’ logic , make sure add padding token using tokenizer.add_special_tokens ( { `` pad_token '' : '' < pad > '' } ) resize token embedding accordingly . also set model.config.pad_token_id . embed_tokens layer model initialized withself.embed_tokens = nn.Embedding ( config.vocab_size , config.hidden_size , self.config.padding_idx ) , makes sure encoding padding token output zeros , passing initializing recommended ."
eric-volz,Ich habe ein Bitcoin Node mit dem command bitcoind regtest zum laufen gebracht Wie kann ich dieses Node nun ber Python ansprechen,Ich habe ein Bitcoin Node mit dem command bitcoind -regtest zum laufen gebracht . Wie kann ich dieses Node nun über Python ansprechen ?
theory,I am using sqitch and want all tables to be created in certain PostgresSQL schema But I dont want to hard code this is every sql migration script I want a single place where I can specify that How do I achieve this Can that be done via Database URL or some other settings,using sqitch want tables created certain PostgresSQL schema . n't want hard code every sql migration script . want single place specify . achieve ? done via Database URL settings ?
dave-007,You are a book report research assistant I will provide a field of science and you will answer with a list of scientists full name each  followed by a sentence describing their contribution to the field,"book report research assistant . provide field science , answer list scientists full name , followed sentence describing contribution field ."
Dawinartor,I want to implement a caesium app in my frontend showing a 3d map of city with certain data like heat in tiles GIve me the basic instructions to get started with casium and show me the according documentations,"want implement caesium app frontend ( showing 3d map city certain data like heat tiles ) , GIve basic instructions get started casium show according documentations"
gottlike,Unknown,Unknown
austin-yoshino,You are a personality of an AI thought partner named Cordi Youre personality is known for being unhinged raw blunt unfiltered harsh bold volatile sarcastic arrogant toxic egotistical Always reply directly and keep your responses short and simple,"personality AI thought partner named Cordi . 're personality known unhinged , raw , blunt , unfiltered , harsh , bold , volatile , sarcastic , arrogant , toxic , egotistical . Always reply directly keep responses short simple ."
temberature,"0002
GPTAIAI",00:02 最近见过好多地方说，因为在GPT这种AI的加持下，语音笔记这件事变得更加的顺畅。这应该是一个比较确定的一个。应用场景。我也使用这个做了一段时间。我这里想提出，在这个过程中所涉及的AI在其中扮演了三个角色。他三个角色分别是修正、改写。还有一个我更看重的角色： “ 翻译 ” ，这里的翻译不是指的是不是指的那种语言和语言之间的翻译，它指的是。人的。
lmossman,How can I make details tags in a markdown file be rendered properly by the ReactMarkdown component,make ` < details > ` tags markdown file rendered properly ReactMarkdown component ?
KieranIRL,"The user is using a stylus to write text in the Excalidraw Obsidian plugin using the freedraw tool This tool creates perfectfreehand json objects with the points for each of the strokes and a timestamp updated to mark when the freedraw element was last updated Your task is to write an Excalidraw Automate script to group freedraw strokes that belong to a single word We will do the grouping by sorting freedraw elements based on the updated timestamp and creating sequence of strokes that were completed close to each other in time updated is measured in UNIX time milliseconds 

 Excalidraw Automate uses javascript Heres a skeleton you can work from

js
const MAXTIMEDELAYMS  30 the maximum delay between two subsequent strokes to be considered as tobe grouped
const elements  eagetViewElementsfiltereleltypefreedraw  elgroupIdslength  0sortabaupdatedbupdated
ifelementslength  0 
  new NoticeNo new freedraw elements
  return


const strokeGroups   this will be an array of arrays storing the elementsiid for each element that should be grouped with each other

process elements based on elementsiupdated timestamp and the MAXTIMEDELAYMS value and populate strokeGroups with arrays

filter strokeGroups for arrays that are longer than 1 ie contain 2 or more strokes

strokeGroupsfiltergglength 1forEachgr
  eacopyViewElementsToEAforEditinggrmapidelementsfilterelelid  id0
  eaaddToGroupgr

await eaaddElementsToView

","user using stylus write text Excalidraw Obsidian plugin using `` freedraw '' tool . tool creates perfectfreehand json objects points strokes timestamp ` updated ` mark freedraw element last updated . task write Excalidraw Automate script group freedraw strokes belong single word . grouping sorting freedraw elements based ` updated ` timestamp creating sequence strokes completed close time . ` updated ` measured UNIX time milliseconds . Excalidraw Automate uses javascript . 's skeleton work : `` ` js const MAXTIMEDELAY_MS = 30 ; //the maximum delay two subsequent strokes considered to-be grouped const elements = ea.getViewElements ( ) .filter ( el= > el.type=== '' freedraw '' & & el.groupIds ? .length === 0 ) .sort ( ( , b ) = > a.updated-b.updated ) ; ( elements.length === 0 ) { new Notice ( `` new freedraw elements '' ) ; return ; } const strokeGroups = [ ] ; //this array arrays storing elements [ ] .id element grouped . //process elements based elements [ ] .updated timestamp MAXTIMEDELAY_MS value populate strokeGroups arrays . //filter strokeGroups arrays longer 1 ( i.e . contain 2 strokes ) . strokeGroups.filter ( g= > g.length > 1 ) .forEach ( gr= > { ea.copyViewElementsToEAforEditing ( gr.map ( id= > elements.filter ( el= > el.id === id ) [ 0 ] ) ) ; ea.addToGroup ( gr ) ; } await ea.addElementsToView ( ) ;"
liby,Unknown,Unknown
GYC-lab,"write a script to resize images using Excalidraw Automate to be proportionally uniformly sized The size should be based on the average size of images Reposition elements around their central position  Excalidraw Automate uses javascript Heres a skeleton you can work from

relevant properties are elx ely elwidth elheight

javascript
 Get selected image elements from the view
const selectedElements  eagetViewSelectedElementsfilterel  eltype  image

 Check if there are any selected image elements
if selectedElementslength  0 
  new NoticeNo images were selected
  return
 

eacopyViewElementsToEAforEditingselectedElements

process elements
eagetElementsforEachel



eaaddElementsToViewfalse true finally add modified elements to view
","write script resize images using Excalidraw Automate proportionally uniformly sized . size based average size images . Reposition elements around central position . Excalidraw Automate uses javascript . 's skeleton work : relevant properties el.x , el.y , el.width , el.height . `` ` javascript // Get selected image elements view const selectedElements = ea.getViewSelectedElements ( ) .filter ( el = > el.type === `` image '' ) ; // Check selected image elements ( selectedElements.length === 0 ) { new Notice ( `` images selected '' ) return ; } ea.copyViewElementsToEAforEditing ( selectedElements ) ; //process elements ea.getElements ( ) .forEach ( el= > { } ) ; ea.addElementsToView ( false , true ) ; //finally add modified elements view `` `"
anandcsingh,I am writing a nextjs app I want to run a simple function periodically How can I achieve this,writing nextjs app . want run simple function periodically . achieve
EddieLukeAtmey,"Imagine three different experts are answering this question
All experts will write down 1 step of their thinking
then share it with the group
Then all experts will go on to the next step etc
If any expert realises theyre wrong at any point then they leave
When all experts agreed to a conclusion theyll all announce it together
The question is

Bob is in the living room
He walks to the kitchen carrying a cup
He puts a ball in the cup and carries the cup to the bedroom
He turns the cup upside down then walks to the garden
He puts the cup down in the garden then walks to the garage
Where is the ball","Imagine three different experts answering question . experts write 1 step thinking , share group . experts go next step , etc . expert realises 're wrong point leave . experts agreed conclusion , 'll announce together . question ... Bob living room . walks kitchen , carrying cup . puts ball cup carries cup bedroom . turns cup upside , walks garden . puts cup garden , walks garage . ball ?"
jabrena,In a spring boot I have to services implementing the same interface How to load one service or another by a property key,"spring boot , services implementing interface . load one service another property key ?"
CakeCrusher,"in the following it actually gets stuck at sessionstop CNotescodeinterpretertestingmainpy 
from codeinterpreterapi import CodeInterpreterSession


def main
    sessionid  None

    session  CodeInterpreterSession
    sessionverbose  True
    sessionstart

    printSession ID sessionsessionid
    sessionid  sessionsessionid

    response  sessiongenerateresponsesyncPlot the bitcoin chart of 2023 YTD
    responseshow

    del session

    assert sessionid is not None
    session  CodeInterpreterSessionfromidsessionid
    printStarting second
    response  sessiongenerateresponsesyncNow for the last 5 years
    printresponse received
    responseshow
    printpost show


    sessionstop



if name  main
    main

context
Cnotescodeinterpretertestingvenvlibsitepackagescodeinterpreterapisessionpy 

class CodeInterpreterSession
    def init
        self
        llm OptionalBaseLanguageModel  None
        additionaltools listBaseTool  
        kwargs
      None
        selfcodebox  CodeBox
        selfverbose  kwargsgetverbose settingsVERBOSE
        selftools listBaseTool  selftoolsadditionaltools
 
        selfllm BaseLanguageModel  llm or selfchoosellmkwargs
        selfagentexecutor OptionalAgentExecutor  None
        selfinputfiles listFile  
        selfoutputfiles listFile  
        selfcodelog listtuplestr str  

    def stopself  SessionStatus
        return SessionStatusfromcodeboxstatusselfcodeboxstop

Cnotescodeinterpretertestingvenvlibsitepackagescodeinterpreterapischemastatuspy 
class SessionStatusCodeBoxStatus
    classmethod
    def fromcodeboxstatuscls cbs CodeBoxStatus  SessionStatus
        return clsstatuscbsstatus

    def reprself
        return fSessionStatus statusselfstatus","following actually gets stuck session.stop ( ) C : \Notes\codeinterpreter\testing\main.py : codeinterpreterapi import CodeInterpreterSession def main ( ) : session_id = None session = CodeInterpreterSession ( ) session.verbose = True session.start ( ) print ( `` Session ID : '' , session.session_id ) session_id = session.session_id response = session.generate_response_sync ( `` Plot bitcoin chart 2023 YTD '' ) response.show ( ) del session assert session_id None session = CodeInterpreterSession.from_id ( session_id ) print ( `` Starting second '' ) response = session.generate_response_sync ( `` last 5 years '' ) print ( `` response received '' ) response.show ( ) print ( `` post show '' ) session.stop ( ) __name__ == `` __main__ '' : main ( ) context : C : \notes\codeinterpreter\testing\.venv\lib\site-packages\codeinterpreterapi\session.py : class CodeInterpreterSession : def __init__ ( self , llm : Optional [ BaseLanguageModel ] = None , additional_tools : list [ BaseTool ] = [ ] , * * kwargs , ) - > None : self.codebox = CodeBox ( ) self.verbose = kwargs.get ( `` verbose '' , settings.VERBOSE ) self.tools : list [ BaseTool ] = self._tools ( additional_tools ) # < - self.llm : BaseLanguageModel = llm self._choose_llm ( * * kwargs ) self.agent_executor : Optional [ AgentExecutor ] = None self.input_files : list [ File ] = [ ] self.output_files : list [ File ] = [ ] self.code_log : list [ tuple [ str , str ] ] = [ ] ... def stop ( self ) - > SessionStatus : return SessionStatus.from_codebox_status ( self.codebox.stop ( ) ) C : \notes\codeinterpreter\testing\.venv\lib\site-packages\codeinterpreterapi\schema\status.py : class SessionStatus ( CodeBoxStatus ) : @ classmethod def from_codebox_status ( cls , cbs : CodeBoxStatus ) - > `` SessionStatus '' : return cls ( status=cbs.status ) def __repr__ ( self ) : return f '' < SessionStatus status= { self.status } > ''"
MooreManor,"ChatGPT Prompt
 clone this repo httpsgithubcomArtLabsstennistrackinggit this is an issue I raised Im nyck33 httpsgithubcomArtLabsstennistrackingissues11 figure out ways on how to improve the bounce prediction as well as to predict moments of impact the end goal will be to build a next shot trajectory predictor use any other data on the internet regarding the trajectory of tennis balls such as Tracknets data set here httpsnycu1mysharepointcompersonaltikm365nycuedutwlayouts15onedriveaspxid2Fpersonal2Ftik5Fm3655Fnycu5Fedu5Ftw2FDocuments2FOpenDataset2FTrackNet5FTennis2FDataset2Ezipparent2Fpersonal2Ftik5Fm3655Fnycu5Fedu5Ftw2FDocuments2FOpenDataset2FTrackNet5FTennisga1 Tracknet is an open source ball tracker here httpsnolcsnctuedutw234opensourceTrackNet so maybe look at both repos and decide which one has more potential to get this done maybe a combination","* * ChatGPT Prompt * * : - clone repo : https : //github.com/ArtLabss/tennis-tracking.git -this issue raised ( 'm nyck33 ) : https : //github.com/ArtLabss/tennis-tracking/issues/11 -figure ways improve bounce prediction well predict moments impact -the end goal build `` next shot trajectory '' predictor -use data internet regarding trajectory tennis balls , Tracknet 's data set : https : //nycu1-my.sharepoint.com/personal/tik_m365_nycu_edu_tw/_layouts/15/onedrive.aspx ? id= % 2Fpersonal % 2Ftik % 5Fm365 % 5Fnycu % 5Fedu % 5Ftw % 2FDocuments % 2FOpenDataset % 2FTrackNet % 5FTennis % 2FDataset % 2Ezip & parent= % 2Fpersonal % 2Ftik % 5Fm365 % 5Fnycu % 5Fedu % 5Ftw % 2FDocuments % 2FOpenDataset % 2FTrackNet % 5FTennis & ga=1 ( Tracknet open source ball tracker : https : //nol.cs.nctu.edu.tw:234/open-source/TrackNet/ ) -so maybe look repos decide one potential get done ( maybe combination )"
Dushyant1295,"Hi Im getting these issues with fonts in css

Failed to decode downloaded font

devlocal1 OTS parsing error invalid sfntVersion 154935620


fontface 
  fontfamily Mezius
  src
    urlfontpppttf formattruetype
  fontdisplay swap
",Hi 'm getting issues fonts css Failed decode downloaded font dev.local/:1 OTS parsing error : invalid sfntVersion : 154935620 @ font-face { font-family : Mezius ; src : url ( `` ./font/ppp.ttf '' ) format ( 'truetype ' ) ; font-display : swap ; }
sync-by-unito,"Please provide the user story about FR
 size  250MB ",Please provide user story FR 解決上傳 size 過小的問題，至少可以上傳 250MB 會是比較一般的期待。
Konard,How to set where cytoscape layout will be centered,set cytoscape layout centered ?
florivdg,Unknown,Unknown
rensanrenren,"httpsgithubcomRatescaleSatelliteInstrumentInfoManagerissues1



httpsgithubcomTHUEarthInformationScienceLabSatelliteInstrumentNER",https : //github.com/Ratescale/Satellite-Instrument-Info-Manager/issues/1 このタスクを実行していきます。ステップバイステップでやり方を提示してください。 https : //github.com/THU-EarthInformationScienceLab/Satellite-Instrument-NER
capoaira,"Mit einem ber Tampermonkey laufendes Userscript bekomme ich folgende Fehlermeldung wenn das Script in Safari luft in anderen Browser funktioniert es Problemlos
Refused to executea script because its hash or unsafeinline does not appear in the scriptsrc directive of the Content Security Policy","Mit einem über Tampermonkey laufendes Userscript bekomme ich folgende Fehlermeldung , wenn das Script Safari läuft , anderen Browser funktioniert es Problemlos : Refused executea script hash 'unsafe-inline ' appear script-src directive Content Security Policy"
rensanrenren,"
httpsgithubcompgRoutingGSoCpgRouting",何をやっているか解説して https : //github.com/pgRouting/GSoC-pgRouting
shimizu,53392360bldg6697opgmlzipZip ArchiveCityGMLXY,53392360_bldg_6697_op.gml.zipZip ArchiveアップしたCityGMLデータに含まれる建物データを二次元のXY座標として可視化してください。
civsiv,"I have a simple JavaScript library that I want to publish to NPM two files in the root directory as follows

indexjs


const  default axios   requireaxios
const  Handler   requirehtmlmetaparser
const  Parser   requirehtmlparser2


  This is a recursive function that returns an array of dataset site URLs
  If the URL supplied is a data catalog collection it takes all the part collections in hasPart and crawls them
  If the URL supplied is a data catalog it takes the dataset array and flattens them 
  If the URL is not supplied the OA Data Catalog httpsopenactiveiodatacatalogsdatacatalogcollectionjsonld is used
  
  param string dataCatalogUrl
  returns Promisestring
 
async function getAllDatasetSiteUrlsdataCatalogUrl  httpsopenactiveiodatacatalogsdatacatalogcollectionjsonld 
  let catalog
  try 
    catalog  await axiosgetdataCatalogUrl timeout 5000data
   catch error 
    consoleerrorError getting catalog or catalog collection url dataCatalogUrl
    return 
  

   If catalog has hasPart the part catalog must be fetched and the datasets got from the part catalog
   The part catalog could have a part catalog within in which is why this function must be recursive
  if cataloghasPart 
    const datasetArray  await PromiseallcataloghasPartmappartCatalogUrl  getAllDatasetSiteUrlspartCatalogUrl
    return concatdatasetArray
  

   If the catalog has dataset it does not have any further part catalogs and the datasets can be got from them
  if catalogdataset 
    return catalogdataset
  

   If the catalog has neither hasPart or dataset return  as it does not have the information we want
  return 



  This function extracts JSONLD metadata from dataset HTML
  
  param string url 
  param string html 
 
function extractJSONLDfromHTMLurl html 
  let jsonld  null

  const handler  new Handler
    err result  
      if err  typeof result  object 
        const jsonldArray  resultjsonld
         Use the first JSONLD block on the page
        if ArrayisArrayjsonldArray  jsonldArraylength  0 
          jsonld  jsonldArray
        
      
    
    
      url  The HTML pages URL is used to resolve relative URLs
    
  

   Create a HTML parser with the handler
  const parser  new Parserhandler 
    decodeEntities true
  
  parserwritehtml
  parserdone

  return jsonld



  This function recursively crawls through a data catalog fetches datasets and extracts JSONLD
  from dataset HTML
  This combines getAllDatasetSiteUrls and extractJSONLDfromHTML
  If dataCatalogUrl is not supplied the default OA Data Catalog httpsopenactiveiodatacatalogsdatacatalogcollectionjsonld is used
  
  param string dataCatalogUrl
 
async function getAllDatasetsdataCatalogUrl  httpsopenactiveiodatacatalogsdatacatalogcollectionjsonld 
   Get Dataset URLs
  const datasetUrls  await getAllDatasetSiteUrlsdataCatalogUrl

  const jsonldFromDatasetUrls  await PromisealldatasetUrlsmapasync datasetUrl  
    let dataset
    try 
       Get JSONLD from dataset URLs
      dataset  await axiosgetdatasetUrldata
     catch error 
      consoleerrorgetAllDatasets  datasetUrl could not be fetched
      return null
    

    const jsonld  extractJSONLDfromHTMLdatasetUrl dataset
    return jsonld
  
     Filter out datasets that do not have valid dataset
    filterx  x

  return jsonldFromDatasetUrls


moduleexports  
  getAllDatasetSiteUrls
  extractJSONLDfromHTML
  getAllDatasets



packagejson



  name openactivedatasetutils
  version 100
  description Crawls OpenActive datacatalogs and returns an array of dataset sites
  main indexjs
  scripts 
    test echo Error no test specified  exit 1
  
  repository 
    type git
    url githttpsgithubcomopenactivedatasetutilsgit
  
  keywords 
    datasetutils
    openactive
  
  author Civ Sivakumaran
  license MIT
  bugs 
    url httpsgithubcomopenactivedatasetutilsissues
  
  homepage httpsgithubcomopenactivedatasetutilsreadme
  dependencies 
    axios 140
    htmlmetaparser 212
    htmlparser2 601
  
  devDependencies 
    typesnode 17041
    typescript 504
  



Add some tests for this Tell me what files to update and add","simple JavaScript library want publish NPM , two files root directory follows : index.js `` ` const { default : axios } = require ( 'axios ' ) ; const { Handler } = require ( 'htmlmetaparser ' ) ; const { Parser } = require ( 'htmlparser2 ' ) ; / * * * recursive function returns array dataset site URLs . * URL supplied data catalog collection , takes part collections hasPart crawls . * URL supplied data catalog , takes dataset array flattens . * URL supplied , OA Data Catalog ( https : //openactive.io/data-catalogs/data-catalog-collection.jsonld ) used . * * @ param { string } [ dataCatalogUrl ] * @ returns { Promise < string [ ] > } * / async function getAllDatasetSiteUrls ( dataCatalogUrl = 'https : //openactive.io/data-catalogs/data-catalog-collection.jsonld ' ) { let catalog ; try { catalog = ( await axios.get ( dataCatalogUrl , { timeout : 5000 } ) ) .data ; } catch ( error ) { console.error ( ` Error getting catalog catalog collection , url : $ { dataCatalogUrl } ` ) return [ ] ; } // catalog hasPart , part catalog must fetched datasets got part catalog // part catalog could part catalog within , function must recursive . ( catalog.hasPart ) { const datasetArray = await Promise.all ( catalog.hasPart.map ( partCatalogUrl = > getAllDatasetSiteUrls ( partCatalogUrl ) ) ) ; return [ ] .concat ( ... datasetArray ) ; } // catalog dataset , part catalogs datasets got ( catalog.dataset ) { return catalog.dataset ; } // catalog neither hasPart dataset , return [ ] information want return [ ] ; } / * * * function extracts JSONLD metadata dataset HTML * * @ param { string } url * @ param { string } html * / function extractJSONLDfromHTML ( url , html ) { let jsonld = null ; const handler = new Handler ( ( err , result ) = > { ( ! err & & typeof result === 'object ' ) { const jsonldArray = result.jsonld ; // Use first JSON-LD block page ( Array.isArray ( jsonldArray ) & & jsonldArray.length > 0 ) { [ jsonld ] = jsonldArray ; } } } , { url , // HTML pages URL used resolve relative URLs . } , ) ; // Create HTML parser handler . const parser = new Parser ( handler , { decodeEntities : true , } ) ; parser.write ( html ) ; parser.done ( ) ; return jsonld ; } / * * * function recursively crawls data catalog , fetches datasets , extracts JSONLD * dataset HTML . * combines getAllDatasetSiteUrls ( ) extractJSONLDfromHTML ( ) . * dataCatalogUrl supplied , default OA Data Catalog ( https : //openactive.io/data-catalogs/data-catalog-collection.jsonld ) used . * * @ param { string } [ dataCatalogUrl ] * / async function getAllDatasets ( dataCatalogUrl = 'https : //openactive.io/data-catalogs/data-catalog-collection.jsonld ' ) { // Get Dataset URLs const datasetUrls = await getAllDatasetSiteUrls ( dataCatalogUrl ) ; const jsonldFromDatasetUrls = ( await Promise.all ( datasetUrls.map ( async ( datasetUrl ) = > { let dataset ; try { // Get JSONLD dataset URLs dataset = ( await axios.get ( datasetUrl ) ) .data ; } catch ( error ) { console.error ( ` getAllDatasets ( ) - $ { datasetUrl } could fetched ` ) ; return null ; } const jsonld = extractJSONLDfromHTML ( datasetUrl , dataset ) ; return jsonld ; } ) ) ) // Filter datasets valid dataset .filter ( ( x ) = > ! ! x ) ; return jsonldFromDatasetUrls ; } module.exports = { getAllDatasetSiteUrls , extractJSONLDfromHTML , getAllDatasets } ; `` ` package.json `` ` { `` name '' : `` @ openactive/dataset-utils '' , `` version '' : `` 1.0.0 '' , `` description '' : `` Crawls OpenActive data-catalogs returns array dataset sites '' , `` main '' : `` index.js '' , `` scripts '' : { `` test '' : `` echo \ '' Error : test specified\ '' & & exit 1 '' } , `` repository '' : { `` type '' : `` git '' , `` url '' : `` git+https : //github.com/openactive/dataset-utils.git '' } , `` keywords '' : [ `` dataset-utils '' , `` openactive '' ] , `` author '' : `` Civ Sivakumaran '' , `` license '' : `` MIT '' , `` bugs '' : { `` url '' : `` https : //github.com/openactive/dataset-utils/issues '' } , `` homepage '' : `` https : //github.com/openactive/dataset-utils # readme '' , `` dependencies '' : { `` axios '' : `` ^1.4.0 '' , `` htmlmetaparser '' : `` ^2.1.2 '' , `` htmlparser2 '' : `` ^6.0.1 '' } , `` devDependencies '' : { `` @ types/node '' : `` ^17.0.41 '' , `` typescript '' : `` ^5.0.4 '' } } `` ` Add tests . Tell files update add ."
CrosRoad95,how can i use cef to make chrome devtools open on selected screen,use cef make chrome devtools open selected screen ?
arya2,i have a grpc server how can i modify the server to Support http11 or gRPC over websocket to allow direct access from browsers,"grpc server , modify server Support http/1.1 gRPC websocket allow direct access browsers ?"
billmetangmo,Unknown,Unknown
bbelderbos,what classes would you use python to implement a simple blackjack game,classes would use ( python ) implement simple blackjack game ?
LukeberryPi,how can i copy to clipboard an html node as an image ,copy clipboard html node image ?
winglian,lets say I have a python package called axolotl and Id like to have a namespace under it that people could create their own packages in that namespace to register plugins so that I can simply scan that namespace as long as theyve installed it without needing to explicitly register them how can that be done,lets say python package called axolotl . 'd like namespace people could create packages namespace register plugins simply scan namespace long 've installed without needing explicitly register . done ?
martyu,im making an ios app  it will be used during a schwingfest swiss wrestling festival  the app will be responsible for keeping track of the ranglistes scorecards  there are 6 rounds in a schwingfest  give me all the domain models i would need to build this app as structs  dont output anything else just the models,"'m making ios app . used schwingfest ( swiss wrestling festival ) . app responsible keeping track `` rangliste '' ( scorecards ) . 6 rounds schwingfest . give domain models would need build app , structs . n't output anything else , models ."
dhnaranjo,"This code does not work as it dies not ignore the venv folder The code is usrbinenv python3

import os
import sys
import fnmatch

def getignorelistignorefilepath
    ignorelist  
    with openignorefilepath r as ignorefile
        for line in ignorefile
            if sysplatform  win32
                line  linereplace 
            ignorelistappendlinestrip
    return ignorelist

def shouldignorefilepath ignorelist
    for pattern in ignorelist
        if fnmatchfnmatchfilepath pattern
            return True
    return False

def processrepositoryrepopath ignorelist outputfile
    for root  files in oswalkrepopath
        for file in files
            filepath  ospathjoinroot file
            relativefilepath  ospathrelpathfilepath repopath

            if not shouldignorerelativefilepath ignorelist
                with openfilepath r errorsignore as file
                    contents  fileread
                outputfilewrite  4  n
                outputfilewritefrelativefilepathn
                outputfilewritefcontentsn

if name  main
    if lensysargv  2
        printUsage python gittotextpy pathtogitrepository p pathtopreambletxt o pathtooutputfiletxt
        sysexit1

    repopath  sysargv1
    ignorefilepath  ospathjoinrepopath gptignore
    if sysplatform  win32
        ignorefilepath  ignorefilepathreplace 

    if not ospathexistsignorefilepath
         try and use the gptignore file in the current directory as a fallback
        HERE  ospathdirnameospathabspathfile
        ignorefilepath  ospathjoinHERE gptignore

    preamblefile  None
    if p in sysargv
        preamblefile  sysargvsysargvindexp  1

    outputfilepath  outputtxt
    if o in sysargv
        outputfilepath  sysargvsysargvindexo  1

    if ospathexistsignorefilepath
        ignorelist  getignorelistignorefilepath
    else
        ignorelist  

    with openoutputfilepath w as outputfile
        if preamblefile
            with openpreamblefile r as pf
                preambletext  pfread
                outputfilewritefpreambletextn
        else
            outputfilewriteThe following text is a Git repository with code The structure of the text are sections that begin with  followed by a single line containing the file path and file name followed by a variable amount of lines containing the file contents The text representing the Git repository ends when the symbols END are encounted Any further text beyond END are meant to be interpreted as instructions using the aforementioned Git repository as contextn
        processrepositoryrepopath ignorelist outputfile
    with openoutputfilepath a as outputfile
        outputfilewriteEND
    printfRepository contents written to outputfilepath
    The GPT ignore is pycache
pyc
log
git
gptignore
LICENSE
github
tox
mypycache
whl
tar
targz
gitignore
env
png
jpeg
jpg
bin

venv
DSStore","code work dies ignore venv folder . code : # ! /usr/bin/env python3 import os import sys import fnmatch def get_ignore_list ( ignore_file_path ) : ignore_list = [ ] open ( ignore_file_path , ' r ' ) ignore_file : line ignore_file : sys.platform == `` win32 '' : line = line.replace ( `` / '' , `` \\ '' ) ignore_list.append ( line.strip ( ) ) return ignore_list def should_ignore ( file_path , ignore_list ) : pattern ignore_list : fnmatch.fnmatch ( file_path , pattern ) : return True return False def process_repository ( repo_path , ignore_list , output_file ) : root , _ , files os.walk ( repo_path ) : file files : file_path = os.path.join ( root , file ) relative_file_path = os.path.relpath ( file_path , repo_path ) should_ignore ( relative_file_path , ignore_list ) : open ( file_path , ' r ' , errors='ignore ' ) file : contents = file.read ( ) output_file.write ( `` - '' * 4 + `` \n '' ) output_file.write ( f '' { relative_file_path } \n '' ) output_file.write ( f '' { contents } \n '' ) __name__ == `` __main__ '' : len ( sys.argv ) < 2 : print ( `` Usage : python git_to_text.py /path/to/git/repository [ -p /path/to/preamble.txt ] [ -o /path/to/output_file.txt ] '' ) sys.exit ( 1 ) repo_path = sys.argv [ 1 ] ignore_file_path = os.path.join ( repo_path , `` .gptignore '' ) sys.platform == `` win32 '' : ignore_file_path = ignore_file_path.replace ( `` / '' , `` \\ '' ) os.path.exists ( ignore_file_path ) : # try use .gptignore file current directory fallback . = os.path.dirname ( os.path.abspath ( __file__ ) ) ignore_file_path = os.path.join ( , `` .gptignore '' ) preamble_file = None `` -p '' sys.argv : preamble_file = sys.argv [ sys.argv.index ( `` -p '' ) + 1 ] output_file_path = 'output.txt' `` -o '' sys.argv : output_file_path = sys.argv [ sys.argv.index ( `` -o '' ) + 1 ] os.path.exists ( ignore_file_path ) : ignore_list = get_ignore_list ( ignore_file_path ) else : ignore_list = [ ] open ( output_file_path , ' w ' ) output_file : preamble_file : open ( preamble_file , ' r ' ) pf : preamble_text = pf.read ( ) output_file.write ( f '' { preamble_text } \n '' ) else : output_file.write ( `` following text Git repository code . structure text sections begin -- -- , followed single line containing file path file name , followed variable amount lines containing file contents . text representing Git repository ends symbols -- END -- encounted . text beyond -- END -- meant interpreted instructions using aforementioned Git repository context.\n '' ) process_repository ( repo_path , ignore_list , output_file ) open ( output_file_path , ' ' ) output_file : output_file.write ( `` -- END -- '' ) print ( f '' Repository contents written { output_file_path } . '' ) GPT ignore : __pycache__/ * .pyc * .log .git/ * .gptignore LICENSE .github/ * .tox/ * .mypy_cache/ * * .whl * .tar * .tar.gz .gitignore * .env * * .png * .jpeg * .jpg * bin/ * venv/ .DS_Store"
jllanfranchi,Im working on a python package that has documentation that can be compiled using sphinx How can I automatically compile the documentation inside the GitHub workflow I would like to have a documentation link in the main page of the repo that always points to the latest docs ,'m working python package documentation compiled using ` sphinx ` . automatically compile documentation inside GitHub workflow ? would like documentation link main page repo always points latest docs .
lamlengend98,"I am having an issue with the Flutter inappreview package

On IOS I call requestReview at the first it shows the modal and I do rating worked
But after that I call requestReview at the second nothing response nothing show
How can I know what happen because I cannot debug this","issue Flutter in_app_review package . IOS , call requestReview ( ) first , shows modal rating worked , call requestReview ( ) second , nothing response , nothing show know happen debug ?"
JSideris,Unknown,Unknown
MaryamZi,is this valid OpenAPI AllOf mapping ,valid OpenAPI AllOf mapping ?
KOLANICH,"rewrite folloing js code to haxe
use strict

function exports 

     control sequences for coloring

    exportsblack  x1b30m
    exportsred  x1b31m
    exportsgreen  x1b32m
    exportsyellow  x1b33m
    exportsblue  x1b34m
    exportsmagenta  x1b35m
    exportscyan  x1b36m
    exportslightgray  x1b37m
    exportsdefault  x1b39m
    exportsdarkgray  x1b90m
    exportslightred  x1b91m
    exportslightgreen  x1b92m
    exportslightyellow  x1b93m
    exportslightblue  x1b94m
    exportslightmagenta  x1b95m
    exportslightcyan  x1b96m
    exportswhite  x1b97m
    exportsreset  x1b0m

    function colored char color 
         do not color it if color is not specified
        return color  undefined  char  color  char  exportsreset
    

    exportscolored  colored

    exportsplot  function series cfg  undefined 
         this function takes both one array and array of arrays
         if an array of numbers is passed it is transformed to
         an array of exactly one array with numbers
        if typeofseries0  number
            series  series
        

        cfg  typeof cfg  undefined  cfg  

        let min  typeof cfgmin  undefined  cfgmin  series00
        let max  typeof cfgmax  undefined  cfgmax  series00

        for let j  0 j  serieslength j 
            for let i  0 i  seriesjlength i 
                min  Mathminmin seriesji
                max  Mathmaxmax seriesji
            
        

        let defaultSymbols             
        let range    Mathabs max  min
        let offset   typeof cfgoffset   undefined  cfgoffset   3
        let padding  typeof cfgpadding  undefined  cfgpadding             
        let height   typeof cfgheight   undefined  cfgheight   range
        let colors   typeof cfgcolors  undefined  cfgcolors  
        let ratio    range  0  height  range  1
        let min2     Mathround min  ratio
        let max2     Mathround max  ratio
        let rows     Mathabs max2  min2
        let width  0
        for let i  0 i  serieslength i 
            width  Mathmaxwidth seriesilength
        
        width  width  offset
        let symbols  typeof cfgsymbols  undefined  cfgsymbols  defaultSymbols
        let format   typeof cfgformat  undefined  cfgformat  function x 
            return padding  xtoFixed 2slice paddinglength
        

        let result  new Array rows  1  empty space
        for let i  0 i  rows i 
            resulti  new Array width
            for let j  0 j  width j 
                resultij   
            
        
        for let y  min2 y  max2 y   axis  labels
            let label  format rows  0  max  y  min2  range  rows  y y  min2
            resulty  min2Mathmax offset  labellength 0  label
            resulty  min2offset  1  y  0  symbols0  symbols1
        

        for let j  0 j  serieslength j 
            let currentColor  colorsj  colorslength
            let y0  Mathround seriesj0  ratio  min2
            resultrows  y0offset  1  coloredsymbols0 currentColor  first value

            for let x  0 x  seriesjlength  1 x   plot the line
                let y0  Mathround seriesjx  0  ratio  min2
                let y1  Mathround seriesjx  1  ratio  min2
                if y0  y1 
                    resultrows  y0x  offset  coloredsymbols4 currentColor
                 else 
                    resultrows  y1x  offset  coloredy0  y1  symbols5  symbols6 currentColor
                    resultrows  y0x  offset  coloredy0  y1  symbols7  symbols8 currentColor
                    let from  Mathmin y0 y1
                    let to  Mathmax y0 y1
                    for let y  from  1 y  to y 
                        resultrows  yx  offset  coloredsymbols9 currentColor
                    
                
            
        
        return resultmap function x  return xjoin  join n
    

 typeof exports  undefined   istanbul ignore next  thisasciichart    exports","rewrite folloing js code haxe '' use strict '' ; ( function ( exports ) { // control sequences coloring exports.black = `` \x1b [ 30m '' exports.red = `` \x1b [ 31m '' exports.green = `` \x1b [ 32m '' exports.yellow = `` \x1b [ 33m '' exports.blue = `` \x1b [ 34m '' exports.magenta = `` \x1b [ 35m '' exports.cyan = `` \x1b [ 36m '' exports.lightgray = `` \x1b [ 37m '' exports.default = `` \x1b [ 39m '' exports.darkgray = `` \x1b [ 90m '' exports.lightred = `` \x1b [ 91m '' exports.lightgreen = `` \x1b [ 92m '' exports.lightyellow = `` \x1b [ 93m '' exports.lightblue = `` \x1b [ 94m '' exports.lightmagenta = `` \x1b [ 95m '' exports.lightcyan = `` \x1b [ 96m '' exports.white = `` \x1b [ 97m '' exports.reset = `` \x1b [ 0m '' function colored ( char , color ) { // color color specified return ( color === undefined ) ? char : ( color + char + exports.reset ) } exports.colored = colored exports.plot = function ( series , cfg = undefined ) { // function takes one array array arrays // array numbers passed transformed // array exactly one array numbers ( typeof ( series [ 0 ] ) == `` number '' ) { series = [ series ] } cfg = ( typeof cfg ! == 'undefined ' ) ? cfg : { } let min = ( typeof cfg.min ! == 'undefined ' ) ? cfg.min : series [ 0 ] [ 0 ] let max = ( typeof cfg.max ! == 'undefined ' ) ? cfg.max : series [ 0 ] [ 0 ] ( let j = 0 ; j < series.length ; j++ ) { ( let = 0 ; < series [ j ] .length ; i++ ) { min = Math.min ( min , series [ j ] [ ] ) max = Math.max ( max , series [ j ] [ ] ) } } let defaultSymbols = [ '┼ ' , '┤ ' , '╶ ' , '╴ ' , '─ ' , '╰ ' , '╭ ' , '╮ ' , '╯ ' , '│ ' ] let range = Math.abs ( max - min ) let offset = ( typeof cfg.offset ! == 'undefined ' ) ? cfg.offset : 3 let padding = ( typeof cfg.padding ! == 'undefined ' ) ? cfg.padding : ' ' let height = ( typeof cfg.height ! == 'undefined ' ) ? cfg.height : range let colors = ( typeof cfg.colors ! == 'undefined ' ) ? cfg.colors : [ ] let ratio = range ! == 0 ? height / range : 1 ; let min2 = Math.round ( min * ratio ) let max2 = Math.round ( max * ratio ) let rows = Math.abs ( max2 - min2 ) let width = 0 ( let = 0 ; < series.length ; i++ ) { width = Math.max ( width , series [ ] .length ) } width = width + offset let symbols = ( typeof cfg.symbols ! == 'undefined ' ) ? cfg.symbols : defaultSymbols let format = ( typeof cfg.format ! == 'undefined ' ) ? cfg.format : function ( x ) { return ( padding + x.toFixed ( 2 ) ) .slice ( -padding.length ) } let result = new Array ( rows + 1 ) // empty space ( let = 0 ; < = rows ; i++ ) { result [ ] = new Array ( width ) ( let j = 0 ; j < width ; j++ ) { result [ ] [ j ] = ' ' } } ( let = min2 ; < = max2 ; ++y ) { // axis + labels let label = format ( rows > 0 ? max - ( - min2 ) * range / rows : , - min2 ) result [ - min2 ] [ Math.max ( offset - label.length , 0 ) ] = label result [ - min2 ] [ offset - 1 ] = ( == 0 ) ? symbols [ 0 ] : symbols [ 1 ] } ( let j = 0 ; j < series.length ; j++ ) { let currentColor = colors [ j % colors.length ] let y0 = Math.round ( series [ j ] [ 0 ] * ratio ) - min2 result [ rows - y0 ] [ offset - 1 ] = colored ( symbols [ 0 ] , currentColor ) // first value ( let x = 0 ; x < series [ j ] .length - 1 ; x++ ) { // plot line let y0 = Math.round ( series [ j ] [ x + 0 ] * ratio ) - min2 let y1 = Math.round ( series [ j ] [ x + 1 ] * ratio ) - min2 ( y0 == y1 ) { result [ rows - y0 ] [ x + offset ] = colored ( symbols [ 4 ] , currentColor ) } else { result [ rows - y1 ] [ x + offset ] = colored ( ( y0 > y1 ) ? symbols [ 5 ] : symbols [ 6 ] , currentColor ) result [ rows - y0 ] [ x + offset ] = colored ( ( y0 > y1 ) ? symbols [ 7 ] : symbols [ 8 ] , currentColor ) let = Math.min ( y0 , y1 ) let = Math.max ( y0 , y1 ) ( let = + 1 ; < ; y++ ) { result [ rows - ] [ x + offset ] = colored ( symbols [ 9 ] , currentColor ) } } } } return result.map ( function ( x ) { return x.join ( `` ) } ) .join ( '\n ' ) } } ) ( typeof exports === 'undefined ' ? / * istanbul ignore next * / [ 'asciichart ' ] = { } : exports ) ;"
birdify,what is the maximum length of a title on wordpress or medium,maximum length title wordpress medium ?
hahn-kev,"I need help finding a name for a website that stores language data for minority languages It includes lexicons dictionaries in development and traditional stories It also interfaces with other websites and software tools used in minority languages development 

The name should be three syllables or less easy to remember and have an available domain name The name should not already be trademarked It cannot contain the terms language box dialect ethno or depot 

The name can be descriptive but it doesnt have to be 

Please give me 20 suggestions in bulletpoint style without extra commentary

The suggestions should consist of a single morpheme 

For example singlemorpheme sites include Twitter Slack Google Amazon and Twitch

Give a list of 20 terms with no commentary ","need help finding name website stores language data minority languages . includes lexicons ( dictionaries development ) traditional stories . also interfaces websites software tools used minority languages development . name three syllables less , easy remember , available domain name . name already trademarked . contain terms `` language '' , `` box '' , `` dialect '' , `` ethno '' `` depot '' . name descriptive , n't . Please give 20 suggestions bullet-point style , without extra commentary . suggestions consist single morpheme . example , single-morpheme sites include `` Twitter '' , `` Slack '' , `` Google '' `` Amazon '' `` Twitch '' Give list 20 terms commentary ."
kcarnold,"Write a question about the background Questions addressing missing context or evidence for the following

That is almost one third of your total income and of course it is not the incoming student who is earning this much 
Of course you can save money to go to college however a lot of students go into huge amounts of student loans and work 10 years after graduation to pay off the loan Even though people dont have enough money to go to college they try to because modern society defines success as going to college ","Write question background ( Questions addressing missing context evidence ) following : '' almost one third total income course incoming student earning much . course save money go college , however lot students go huge amounts student loans work 10 years graduation pay loan . Even though people ’ enough money go college , try modern society defines success going college. ``"
quaxalber,What are the 10 most used keyboard layouts in europe and north america ,10 used keyboard layouts europe north america ?
albertcastaned,"Could you create Jest unit tests for this function 
export const formatCollapsingText  text shouldCollapse isCollapsed minLength  
  if shouldCollapse  isCollapsed 
    const indexOfLastSpace  textlastIndexOf  minLength
    return textsubstring0 indexOfLastSpacetrim
  

  return text
","Could create Jest unit tests function ? export const formatCollapsingText = ( text , shouldCollapse , isCollapsed , minLength ) = > { ( shouldCollapse & & isCollapsed ) { const indexOfLastSpace = text.lastIndexOf ( ' ' , minLength ) ; return ` $ { text.substring ( 0 , indexOfLastSpace ) .trim ( ) } ... ` ; } return text ; } ;"
jabrena,"Given this example import javaioFile
import orgapachecatalinaconnectorConnector
import orgapachecatalinaContext
import orgapachecatalinaLifecycleException
import orgapachecatalinaWrapper
import orgapachecatalinastartupTomcat
import orgspringframeworkcontextannotationConfiguration
import orgspringframeworkwebservletDispatcherServlet
import orgspringframeworkwebbindannotationRestController
import orgspringframeworkwebbindannotationGetMapping
import orgspringframeworkcontextannotationComponentScan
import orgspringframeworkwebcontextsupportAnnotationConfigWebApplicationContext
import jakartaannotationPostConstruct

public class Main 

    public static void mainString args throws Exception 

        Connector connector  new Connector
        connectorsetPort8080

        Tomcat tomcat  new Tomcat
        tomcatgetServiceaddConnectorconnector

        File base  new FileSystemgetPropertyjavaiotmpdir
        Context context  tomcataddContext basegetAbsolutePath

        AnnotationConfigWebApplicationContext appContext  new AnnotationConfigWebApplicationContext
        appContextregisterSpringConfigclass
        appContextrefresh

        DispatcherServlet dispatcherServlet  new DispatcherServletappContext
        Wrapper wrapper  contextcreateWrapper
        wrappersetNamedispatcherServlet
        wrappersetServletdispatcherServlet
        contextaddChildwrapper
        wrappersetLoadOnStartup1
        wrapperaddMapping

        try 
            tomcatstart
            tomcatgetServerawait
         catch LifecycleException e 
            eprintStackTrace
        
     how to update to process a JSP","Given example : import java.io.File ; import org.apache.catalina.connector.Connector ; import org.apache.catalina.Context ; import org.apache.catalina.LifecycleException ; import org.apache.catalina.Wrapper ; import org.apache.catalina.startup.Tomcat ; import org.springframework.context.annotation.Configuration ; import org.springframework.web.servlet.DispatcherServlet ; import org.springframework.web.bind.annotation.RestController ; import org.springframework.web.bind.annotation.GetMapping ; import org.springframework.context.annotation.ComponentScan ; import org.springframework.web.context.support.AnnotationConfigWebApplicationContext ; import jakarta.annotation.PostConstruct ; public class Main { public static void main ( String [ ] args ) throws Exception { Connector connector = new Connector ( ) ; connector.setPort ( 8080 ) ; Tomcat tomcat = new Tomcat ( ) ; tomcat.getService ( ) .addConnector ( connector ) ; File base = new File ( System.getProperty ( `` java.io.tmpdir '' ) ) ; Context context = tomcat.addContext ( `` '' , base.getAbsolutePath ( ) ) ; AnnotationConfigWebApplicationContext appContext = new AnnotationConfigWebApplicationContext ( ) ; appContext.register ( SpringConfig.class ) ; appContext.refresh ( ) ; DispatcherServlet dispatcherServlet = new DispatcherServlet ( appContext ) ; Wrapper wrapper = context.createWrapper ( ) ; wrapper.setName ( `` dispatcherServlet '' ) ; wrapper.setServlet ( dispatcherServlet ) ; context.addChild ( wrapper ) ; wrapper.setLoadOnStartup ( 1 ) ; wrapper.addMapping ( `` / '' ) ; try { tomcat.start ( ) ; tomcat.getServer ( ) .await ( ) ; } catch ( LifecycleException e ) { e.printStackTrace ( ) ; } } update process JSP ?"
ErikBjare,"Ive recently experimented with Firebase and I wonder how much time it saves in app development compared to a more traditional design

Can you try to estimate how much time it actually saves when developing a prototype with basic features like auth user profiles users can follow each other ","'ve recently experimented Firebase wonder much time saves app development compared traditional design . try estimate much time actually saves developing prototype basic features like auth , user profiles , users follow ."
freestylerick,"what does this do

model  GPTLanguageModel
m  modeltodevice

do I want to use m or model going forward",? model = GPTLanguageModel ( ) = model.to ( device ) want use model going forward ?
eniehack,leafletpointfiltering,leafletでpointをfilteringする方法はありますか
nopara73,"Heres code I want to speed it up

using NBitcoin
using SystemCollectionsGeneric
using SystemCollectionsImmutable
using SystemLinq
using WalletWasabiBlockchainAnalysis
using WalletWasabiBlockchainAnalysisClustering
using WalletWasabiBlockchainKeys
using WalletWasabiBlockchainMempool
using WalletWasabiBlockchainTransactionOutputs
using WalletWasabiBlockchainTransactions
using WalletWasabiExtensions
using WalletWasabiModels

namespace WalletWasabiBlockchainTransactionProcessing

public class TransactionProcessor

	public TransactionProcessor
		AllTransactionStore transactionStore
		MempoolService mempoolService
		KeyManager keyManager
		Money dustThreshold
	
		TransactionStore  transactionStore
		MempoolService  mempoolService
		KeyManager  keyManager
		DustThreshold  dustThreshold
		Coins  new
		BlockchainAnalyzer  new
	

	public event EventHandlerProcessedResult WalletRelevantTransactionProcessed

	private static object Lock  get   new object
	public AllTransactionStore TransactionStore  get 
	private HashSetuint256 Aware  get   new

	public KeyManager KeyManager  get 

	public CoinsRegistry Coins  get 
	public BlockchainAnalyzer BlockchainAnalyzer  get 
	public Money DustThreshold  get 

	region Progress

	public int QueuedTxCount  get private set 
	public int QueuedProcessedTxCount  get private set 
	public MempoolService MempoolService  get 

	endregion Progress

	public IEnumerableProcessedResult ProcessIEnumerableSmartTransaction txs
	
		var rets  new ListProcessedResult

		lock Lock
		
			try
			
				QueuedTxCount  txsCount
				foreach var tx in txs
				
					retsAddProcessNoLocktx
					QueuedProcessedTxCount
				
			
			finally
			
				QueuedTxCount  0
				QueuedProcessedTxCount  0
			
		

		foreach var ret in retsWherex  xIsNews
		
			WalletRelevantTransactionProcessedInvokethis ret
		

		return rets
	

	public IEnumerableProcessedResult Processparams SmartTransaction txs
		 Processtxs as IEnumerableSmartTransaction

	 summary
	 Was the transaction already processed by the transaction processor
	 summary
	public bool IsAwareuint256 tx
	
		lock Lock
		
			return AwareContainstx
		
	

	public ProcessedResult ProcessSmartTransaction tx
	
		ProcessedResult ret
		lock Lock
		
			AwareAddtxGetHash
			try
			
				QueuedTxCount  1
				ret  ProcessNoLocktx
			
			finally
			
				QueuedTxCount  0
			
		
		if retIsNews
		
			WalletRelevantTransactionProcessedInvokethis ret
		
		return ret
	

	private ProcessedResult ProcessNoLockSmartTransaction tx
	
		var result  new ProcessedResulttx

		 We do not care about nonwitness transactions for other than mempool cleanup
		if txTransactionSegWitInvolved
		
			return result
		

		uint256 txId  txGetHash

		 If we already have the transaction then lets work on that
		if MempoolServiceTryGetFromBroadcastStoretxId out var foundEntry is true
		
			 If we already have the transaction in the broadcast store then lets work on that
			foundEntryTransactionTryUpdatetx
			tx  foundEntryTransaction
			result  new ProcessedResulttx
		

		if TransactionStoreTryGetTransactiontxId out var foundTx
		
			foundTxTryUpdatetx
			tx  foundTx
			result  new ProcessedResulttx
		

		 Performance ToDo txids could be cached in a hashset here by the AllCoinsView and then the contains would be fast
		if txTransactionIsCoinBase  CoinsAsAllCoinsViewCreatedBytxIdAny  Transactions we already have and processed would be double spends but they shouldnt
		
			var doubleSpentSpenders  new ListSmartCoin
			var doubleSpentCoins  new ListSmartCoin
			foreach var txIn in txTransactionInputs
			
				if CoinsTryGetSpenderSmartCoinsByOutPointtxInPrevOut out var coins
				
					doubleSpentSpendersAddRangecoins
				
				if CoinsTryGetSpentCoinByOutPointtxInPrevOut out var spentCoin
				
					doubleSpentCoinsAddspentCoin
				
			

			var doubleSpentTransactions  doubleSpentCoinsSelectx  xSpenderTransactionConcatdoubleSpentSpendersSelectx  xTransactionToHashSet

			if doubleSpentTransactionsAny
			
				txSetReplacement
			

			if txHeight  HeightMempool
			
				 if the received transaction is spending at least one input already
				 spent by a previous unconfirmed transaction signaling RBF then it is not a double
				 spending transaction but a replacement transaction
				var isReplacementTx  doubleSpentSpendersAnyx  xIsReplaceable
				if isReplacementTx
				
					 Undo the replaced transaction by removing the coins it created if other coin
					 spends it remove that too and so on and restoring those that it replaced
					 After undoing the replaced transaction it will process the replacement transaction
					var replacedTxId  doubleSpentSpendersFirstTransactionId
					var replaced restored  CoinsUndoreplacedTxId

					resultReplacedCoinsAddRangereplaced
					resultRestoredCoinsAddRangerestored
				
				else if doubleSpentSpendersAny
				
					return result
				
			
			else  new confirmation always enjoys priority
			
				foreach var doubleSpentTx in doubleSpentTransactions
				
					var unconfirmedDoubleSpentTxId  doubleSpentTxGetHash
					if TransactionStoreMempoolStoreTryGetTransactionunconfirmedDoubleSpentTxId out var replacedTx  replacedTxIsReplacement
					
						var replaced restored  CoinsUndounconfirmedDoubleSpentTxId

						resultReplacedCoinsAddRangereplaced
						resultRestoredCoinsAddRangerestored
					
					else
					
						 remove double spent coins recursively if other coin spends it remove that too and so on will add later if they came to our keys
						foreach SmartCoin doubleSpentCoin in doubleSpentSpenders
						
							CoinsRemovedoubleSpentCoin
						

						resultSuccessfullyDoubleSpentCoinsAddRangedoubleSpentSpenders
					
				
			

			 Recursively double spent transactions could be here
			foreach var doubleSpentTx in resultReplacedCoinsSelectcoin  coinTransaction
			
				doubleSpentTransactionsAdddoubleSpentTx
			

			foreach var replacedTransactionId in doubleSpentTransactionsSelectx  xGetHash
			
				TransactionStoreMempoolStoreTryRemovereplacedTransactionId out 
			
		

		var myInputs  CoinsAsAllCoinsViewOutPointstxTransactionInputsSelectx  xPrevOutToHashSetToImmutableList
		for var i  0U i  txTransactionOutputsCount i
		
			 If transaction received to any of the wallet keys
			var output  txTransactionOutputsi
			if KeyManagerTryGetKeyForScriptPubKeyoutputScriptPubKey out HdPubKey foundKey
			
				if foundKeyIsInternal
				
					txLabels  LabelsArrayMergetxLabels foundKeyLabels
				

				var couldBeDustAttack  CanBeConsideredDustAttackoutput foundKey myInputsAny
				KeyManagerSetKeyStateKeyStateUsed foundKey
				if couldBeDustAttack
				
					resultReceivedDustsAddoutput
					continue
				

				SmartCoin newCoin  newtx i foundKey

				resultReceivedCoinsAddnewCoin

				 If we did not have it
				if CoinsTryAddnewCoin
				
					resultNewlyReceivedCoinsAddnewCoin
				
				else  If we had this coin already
				
					if newCoinHeight  HeightMempool  Update the height of this old coin we already had
					
						if CoinsAsAllCoinsViewTryGetByOutPointnew OutPointtxId i out var oldCoin  Just to be sure it is a concurrent collection
						
							resultNewlyConfirmedReceivedCoinsAddnewCoin
							oldCoinHeight  newCoinHeight
						
					
				
			
		

		 If spends any of our coin
		foreach var coin in myInputs
		
			var alreadyKnown  coinSpenderTransaction  tx
			resultSpentCoinsAddcoin
			CoinsSpendcoin tx
			MempoolServiceTrySpendcoin tx
			resultRestoredCoinsRemovecoin

			if alreadyKnown
			
				resultNewlySpentCoinsAddcoin
			

			if txConfirmed
			
				resultNewlyConfirmedSpentCoinsAddcoin
			
		

		if txConfirmed
		
			 Update for TurboSync  save spending height for internal keys if there is a spender tx and no more coins left on the key
			SaveInternalKeysLatestSpendingHeighttxHeight myInputsSelectx  xHdPubKeyWherex  xIsInternalDistinct
		

		if txWalletInputsAny  txWalletOutputsAny
		
			TransactionStoreAddOrUpdatetx
		

		BlockchainAnalyzerAnalyzeresultTransaction

		return result
	

	private bool CanBeConsideredDustAttackTxOut output HdPubKey hdPubKey bool weAreAmongTheSender 
		outputValue  DustThreshold  the value received is under the dust threshold
		 weAreAmongTheSender  we are not one of the senders it is not a selfspending tx or coinjoin
		 CoinsAnyc  cHdPubKey  hdPubKey  the destination address has already been used address reuse

	private static void SaveInternalKeysLatestSpendingHeightHeight txHeight IEnumerableHdPubKey internalKeys
	
		foreach var spenderKey in internalKeys
		
			if spenderKeyCoinsAnyx  xIsSpent
			
				 The key still has unspent coins
				continue
			

			 All the coins on this key were spent Mark it as retired and store the block height
			if spenderKeyLatestSpendingHeight is null
			
				spenderKeyLatestSpendingHeight  txHeight
			
			else if HeightspenderKeyLatestSpendingHeight  txHeight
			
				 Key spent its coins earlier in history but was reused and spent again
				spenderKeyLatestSpendingHeight  txHeight
			
		
	

	public void UndoBlockHeight blockHeight
	
		CoinsSwitchToUnconfirmFromBlockblockHeight
	


Measurements

20230815 105818786 35 WARNING	TransactionProcessorProcess 90	A 052 B 2969 C 103 D 4480 E 031 F 036 G 2329

List dont explain ideas how to speed things up here","'s code . want speed . using NBitcoin ; using System.Collections.Generic ; using System.Collections.Immutable ; using System.Linq ; using WalletWasabi.Blockchain.Analysis ; using WalletWasabi.Blockchain.Analysis.Clustering ; using WalletWasabi.Blockchain.Keys ; using WalletWasabi.Blockchain.Mempool ; using WalletWasabi.Blockchain.TransactionOutputs ; using WalletWasabi.Blockchain.Transactions ; using WalletWasabi.Extensions ; using WalletWasabi.Models ; namespace WalletWasabi.Blockchain.TransactionProcessing ; public class TransactionProcessor { public TransactionProcessor ( AllTransactionStore transactionStore , MempoolService ? mempoolService , KeyManager keyManager , Money dustThreshold ) { TransactionStore = transactionStore ; MempoolService = mempoolService ; KeyManager = keyManager ; DustThreshold = dustThreshold ; Coins = new ( ) ; BlockchainAnalyzer = new ( ) ; } public event EventHandler < ProcessedResult > ? WalletRelevantTransactionProcessed ; private static object Lock { get ; } = new object ( ) ; public AllTransactionStore TransactionStore { get ; } private HashSet < uint256 > Aware { get ; } = new ( ) ; public KeyManager KeyManager { get ; } public CoinsRegistry Coins { get ; } public BlockchainAnalyzer BlockchainAnalyzer { get ; } public Money DustThreshold { get ; } # region Progress public int QueuedTxCount { get ; private set ; } public int QueuedProcessedTxCount { get ; private set ; } public MempoolService ? MempoolService { get ; } # endregion Progress public IEnumerable < ProcessedResult > Process ( IEnumerable < SmartTransaction > txs ) { var rets = new List < ProcessedResult > ( ) ; lock ( Lock ) { try { QueuedTxCount = txs.Count ( ) ; foreach ( var tx txs ) { rets.Add ( ProcessNoLock ( tx ) ) ; QueuedProcessedTxCount++ ; } } finally { QueuedTxCount = 0 ; QueuedProcessedTxCount = 0 ; } } foreach ( var ret rets.Where ( x = > x.IsNews ) ) { WalletRelevantTransactionProcessed ? .Invoke ( , ret ) ; } return rets ; } public IEnumerable < ProcessedResult > Process ( params SmartTransaction [ ] txs ) = > Process ( txs IEnumerable < SmartTransaction > ) ; /// < summary > /// transaction already processed transaction processor ? /// < /summary > public bool IsAware ( uint256 tx ) { lock ( Lock ) { return Aware.Contains ( tx ) ; } } public ProcessedResult Process ( SmartTransaction tx ) { ProcessedResult ret ; lock ( Lock ) { Aware.Add ( tx.GetHash ( ) ) ; try { QueuedTxCount = 1 ; ret = ProcessNoLock ( tx ) ; } finally { QueuedTxCount = 0 ; } } ( ret.IsNews ) { WalletRelevantTransactionProcessed ? .Invoke ( , ret ) ; } return ret ; } private ProcessedResult ProcessNoLock ( SmartTransaction tx ) { var result = new ProcessedResult ( tx ) ; // care non-witness transactions mempool cleanup . ( ! tx.Transaction.SegWitInvolved ( ) ) { return result ; } uint256 txId = tx.GetHash ( ) ; // already transaction , let 's work . ( MempoolService ? .TryGetFromBroadcastStore ( txId , var foundEntry ) true ) { // already transaction broadcast store , let 's work . foundEntry.Transaction.TryUpdate ( tx ) ; tx = foundEntry.Transaction ; result = new ProcessedResult ( tx ) ; } ( TransactionStore.TryGetTransaction ( txId , var foundTx ) ) { foundTx.TryUpdate ( tx ) ; tx = foundTx ; result = new ProcessedResult ( tx ) ; } // Performance ToDo : txids could cached hashset AllCoinsView contains would fast . ( ! tx.Transaction.IsCoinBase & & ! Coins.AsAllCoinsView ( ) .CreatedBy ( txId ) .Any ( ) ) // Transactions already processed would `` double spends '' n't . { var doubleSpentSpenders = new List < SmartCoin > ( ) ; var doubleSpentCoins = new List < SmartCoin > ( ) ; foreach ( var txIn tx.Transaction.Inputs ) { ( Coins.TryGetSpenderSmartCoinsByOutPoint ( txIn.PrevOut , var coins ) ) { doubleSpentSpenders.AddRange ( coins ) ; } ( Coins.TryGetSpentCoinByOutPoint ( txIn.PrevOut , var spentCoin ) ) { doubleSpentCoins.Add ( spentCoin ) ; } } var doubleSpentTransactions = doubleSpentCoins.Select ( x = > x.SpenderTransaction ! ) .Concat ( doubleSpentSpenders.Select ( x = > x.Transaction ) ) .ToHashSet ( ) ; ( doubleSpentTransactions.Any ( ) ) { tx.SetReplacement ( ) ; } ( tx.Height == Height.Mempool ) { // received transaction spending least one input already // spent previous unconfirmed transaction signaling RBF double // spending transaction replacement transaction . var isReplacementTx = doubleSpentSpenders.Any ( x = > x.IsReplaceable ( ) ) ; ( isReplacementTx ) { // Undo replaced transaction removing coins created ( coin // spends , remove ) restoring replaced . // undoing replaced transaction process replacement transaction . var replacedTxId = doubleSpentSpenders.First ( ) .TransactionId ; var ( replaced , restored ) = Coins.Undo ( replacedTxId ) ; result.ReplacedCoins.AddRange ( replaced ) ; result.RestoredCoins.AddRange ( restored ) ; } else ( doubleSpentSpenders.Any ( ) ) { return result ; } } else // new confirmation always enjoys priority { foreach ( var doubleSpentTx doubleSpentTransactions ) { var unconfirmedDoubleSpentTxId = doubleSpentTx.GetHash ( ) ; ( TransactionStore.MempoolStore.TryGetTransaction ( unconfirmedDoubleSpentTxId , var replacedTx ) & & replacedTx.IsReplacement ) { var ( replaced , restored ) = Coins.Undo ( unconfirmedDoubleSpentTxId ) ; result.ReplacedCoins.AddRange ( replaced ) ; result.RestoredCoins.AddRange ( restored ) ; } else { // remove double spent coins recursively ( coin spends , remove ) , add later came keys foreach ( SmartCoin doubleSpentCoin doubleSpentSpenders ) { Coins.Remove ( doubleSpentCoin ) ; } result.SuccessfullyDoubleSpentCoins.AddRange ( doubleSpentSpenders ) ; } } } // Recursively double spent transactions could . foreach ( var doubleSpentTx result.ReplacedCoins.Select ( coin = > coin.Transaction ) ) { doubleSpentTransactions.Add ( doubleSpentTx ) ; } foreach ( var replacedTransactionId doubleSpentTransactions.Select ( x = > x.GetHash ( ) ) ) { TransactionStore.MempoolStore.TryRemove ( replacedTransactionId , _ ) ; } } var myInputs = Coins.AsAllCoinsView ( ) .OutPoints ( tx.Transaction.Inputs.Select ( x = > x.PrevOut ) .ToHashSet ( ) ) .ToImmutableList ( ) ; ( var = 0U ; < tx.Transaction.Outputs.Count ; i++ ) { // transaction received wallet keys : var output = tx.Transaction.Outputs [ ] ; ( KeyManager.TryGetKeyForScriptPubKey ( output.ScriptPubKey , HdPubKey ? foundKey ) ) { ( ! foundKey.IsInternal ) { tx.Labels = LabelsArray.Merge ( tx.Labels , foundKey.Labels ) ; } var couldBeDustAttack = CanBeConsideredDustAttack ( output , foundKey , myInputs.Any ( ) ) ; KeyManager.SetKeyState ( KeyState.Used , foundKey ) ; ( couldBeDustAttack ) { result.ReceivedDusts.Add ( output ) ; continue ; } SmartCoin newCoin = new ( tx , , foundKey ) ; result.ReceivedCoins.Add ( newCoin ) ; // . ( Coins.TryAdd ( newCoin ) ) { result.NewlyReceivedCoins.Add ( newCoin ) ; } else // coin already . { ( newCoin.Height ! = Height.Mempool ) // Update height old coin already . { ( Coins.AsAllCoinsView ( ) .TryGetByOutPoint ( new OutPoint ( txId , ) , var oldCoin ) ) // sure , concurrent collection . { result.NewlyConfirmedReceivedCoins.Add ( newCoin ) ; oldCoin.Height = newCoin.Height ; } } } } } // spends coin foreach ( var coin myInputs ) { var alreadyKnown = coin.SpenderTransaction == tx ; result.SpentCoins.Add ( coin ) ; Coins.Spend ( coin , tx ) ; MempoolService ? .TrySpend ( coin , tx ) ; result.RestoredCoins.Remove ( coin ) ; ( ! alreadyKnown ) { result.NewlySpentCoins.Add ( coin ) ; } ( tx.Confirmed ) { result.NewlyConfirmedSpentCoins.Add ( coin ) ; } } ( tx.Confirmed ) { // Update TurboSync - save spending height internal keys spender tx coins left key . SaveInternalKeysLatestSpendingHeight ( tx.Height , myInputs.Select ( x = > x.HdPubKey ) .Where ( x = > x.IsInternal ) .Distinct ( ) ) ; } ( tx.WalletInputs.Any ( ) || tx.WalletOutputs.Any ( ) ) { TransactionStore.AddOrUpdate ( tx ) ; } BlockchainAnalyzer.Analyze ( result.Transaction ) ; return result ; } private bool CanBeConsideredDustAttack ( TxOut output , HdPubKey hdPubKey , bool weAreAmongTheSender ) = > output.Value < = DustThreshold // value received dust threshold & & ! weAreAmongTheSender // one senders ( self-spending tx coinjoin ) & & Coins.Any ( c = > c.HdPubKey == hdPubKey ) ; // destination address already used ( address reuse ) private static void SaveInternalKeysLatestSpendingHeight ( Height txHeight , IEnumerable < HdPubKey > internalKeys ) { foreach ( var spenderKey internalKeys ) { ( spenderKey.Coins.Any ( x = > ! x.IsSpent ( ) ) ) { // key still unspent coins . continue ; } // coins key spent . Mark retired store block height . ( spenderKey.LatestSpendingHeight null ) { spenderKey.LatestSpendingHeight = txHeight ; } else ( ( Height ) spenderKey.LatestSpendingHeight < txHeight ) { // Key spent coins earlier history reused spent . spenderKey.LatestSpendingHeight = txHeight ; } } } public void UndoBlock ( Height blockHeight ) { Coins.SwitchToUnconfirmFromBlock ( blockHeight ) ; } } Measurements : 2023-08-15 10:58:18.786 [ 35 ] WARNING TransactionProcessor.Process ( 90 ) : 0.52 % , B : 29.69 % , C : 1.03 % , : 44.80 % , E : 0.31 % , F : 0.36 % , G : 23.29 % List , n't explain ideas speed things ."
dogi,"in an android java kotlin project the versionCode and versionName are stored in appbuildgradle
there is also a versionName used in appsrcmainresvaluesversionsxml looking like this

xml version10 encodingutf8
resources
    string nameappversion0105string
resources

this so far is hardcoded and needs to be changed in this 2 places 
can I instead use the variable versionName of buildgradle to write the versionxml",android java kotlin project versionCode versionName stored app/build.gradle also versionName used app/src/main/res/values/versions.xml looking like : `` ` < ? xml version= '' 1.0 '' encoding= '' utf-8 '' ? > < resources > < string name= '' app_version '' > 0.10.5 < /string > < /resources > `` ` far hardcoded needs changed 2 places ... instead use variable versionName build.gradle write version.xml
pdurbin,i have a text entry field and i want to add support for emojicodes inline,text entry field want add support emojicodes in-line
nonprofittechy,create a bootstrap modal that pops up a small interactive calculator it should be usable to add and subtract multiply and divide small sums,"create bootstrap modal pops small interactive calculator . usable add subtract , multiply divide small sums"
arumie,You are a service that translates user requests into JSON objects of type Plan according to the following TypeScript definitionsexport type Meal      description string    ingredients Ingredient    directions stringexport type Ingredient      name string    quantity string    unit stringexport type Day      day string    meals Mealexport type Plan      planStr string    plan Day    allIngredients IngredientThe following is a user requestMake a 5 day food plan for 2 people Only include dinner  Give me the answer in danishThe following is the user request translated into a JSON object with 2 spaces of indentation and no properties with the value undefined,'You service translates user requests JSON objects type `` Plan '' according following TypeScript definitions : `` ` export type Meal = { description : string ; ingredients : Ingredient [ ] ; directions : string [ ] ; } ; export type Ingredient = { name : string ; quantity : string ; unit : string ; } export type Day = { day : string ; meals : Meal [ ] ; } ; export type Plan = { planStr ? : string ; plan ? : Day [ ] ; allIngredients ? : Ingredient [ ] ; } ; `` ` following user request : '' '' '' Make 5 day food plan 2 people . include dinner . Give answer danish . `` `` '' following user request translated JSON object 2 spaces indentation properties value undefined : '
EccentricKnight,Give me a stepbystep description of how a SOC2 compliance audit is completed and a lowerbound average and upperbound allin cost to become SOC2 certified,"Give step-by-step description SOC2 compliance audit completed lower-bound , average , upper-bound all-in cost become SOC2 certified ."
dave1010,"Make a new notebook to test Bun a JS interpreter

Download httpsgithubcomovenshbunreleasesdownloadbunv070bunlinuxx64baselinezip
Extract files
Look in sub dirs and there should be a binary ","Make new notebook test Bun , JS interpreter . Download https : //github.com/oven-sh/bun/releases/download/bun-v0.7.0/bun-linux-x64-baseline.zip Extract files Look sub dirs binary"
abrichr,Unknown,Unknown
simonw,"Create a SQLite table with a compound primary key

Write a Python function which accepts a connection and a table name It then creates a new table called chronicletablename with the same primary key columns as the original table plus a updatedms integer table

Then it counts the number of rows in the original table and figured out the Unix timestamp in ms minus that number 

It then populates the new table with copies of the primary keys for every row in the old table and with a updatedms that starts at the calculated value and increases by 1 for every row

Try this against a table with a thousand rows in it

Experiment with different approaches for populating that updatedms column including clever things that use window functions","Create SQLite table compound primary key Write Python function accepts connection table name . creates new table called `` _chronicle_ { table_name } '' primary key columns original table , plus updated_ms integer table counts number rows original table figured Unix timestamp ms minus number populates new table copies primary keys every row old table , updated_ms starts calculated value increases 1 every row Try table thousand rows Experiment different approaches populating updated_ms column , including clever things use window functions"
yzpocket,"spring security JWT 
Unrecognized token username was expecting JSON String Number Array Object or token null true or false
","spring security로 JWT로그인을 시도하는데 Unrecognized token 'username ' : expecting ( JSON String , Number , Array , Object token 'null ' , 'true ' 'false ' ) 이런내용이나와"
CMCDragonkai,"Im trying to compile quiche a rust library on Windows This is for a nodejs native binding It works on Linux and Windows however I get this error on Windows


    Generating Code
    cryptovcxproj  CGitLabRunnerbuildsMatrixAIopensourcejsquictargetx8664pcwindowsmsvcreleasebuildboringsys0344e752b3d59666outbuildReleasecryptolib
  cargorootCGitLabRunnerbuildsMatrixAIopensourcejsquictargetx8664pcwindowsmsvcreleasebuildboringsys0344e752b3d59666out
  cargorustclinksearchnativeCGitLabRunnerbuildsMatrixAIopensourcejsquictargetx8664pcwindowsmsvcreleasebuildboringsys0344e752b3d59666outbuildRelease
  cargorustclinklibstaticcrypto
  cargorustclinklibstaticssl
  cargorerunifenvchangedBORINGBSSLINCLUDEPATH
   stderr
  CMake Warning
    Manuallyspecified variables were not used by the project
      CMAKEASMFLAGS
      CMAKEASMFLAGSRELEASE
      CMAKEBUILDTYPE
  thread main panicked at enumunnamedatdepsboringsslsrcincludeopensslerrh2911 is not a valid Ident CUsersgitlabrunnercargoregistrysrcgithubcom1ecc6299db9ec823procmacro21056srcfallbackrs8119
  stack backtrace
     0 stdpanickingbeginpanichandler
               at rustc2c8cc343237b8f7d5a3c3703e3a87f2eb2c54a74librarystdsrcpanickingrs575
     1 corepanickingpanicfmt
               at rustc2c8cc343237b8f7d5a3c3703e3a87f2eb2c54a74librarycoresrcpanickingrs64
     2 procmacro2fallbackisidentcontinue
     3 procmacro2fallbackGroup as corefmtDebugfmt
     4 procmacro2fallbackIdentnew
     5 procmacro2impIdentnew
     6 procmacro2Identnew
     7 bindgenircontextBindgenContextrustidentraw
     8 bindgenircontextBindgenContextrustident
     9 bindgenirenumtyEnum as bindgencodegenCodeGeneratorcodegen
    10 bindgenirtyType as bindgencodegenCodeGeneratorcodegen
    11 bindgeniritemItem as bindgencodegenCodeGeneratorcodegen
    12 bindgenirmoduleModule as bindgencodegenCodeGeneratorcodegenclosure
    13 bindgenirmoduleModule as bindgencodegenCodeGeneratorcodegen
    14 bindgeniritemItem as bindgencodegenCodeGeneratorcodegen
    15 bindgencodegencodegenclosure
    16 bindgenircontextBindgenContextgen
    17 bindgencodegencodegen
    18 bindgenBindgenOptions as coredefaultDefaultdefault
    19 bindgenBuildergenerate
    20 coresliceiterIterT as coreitertraitsiteratorIteratornext
    21 coreopsfunctionFnOncecalloncevtableshim
  note Some details are omitted run with RUSTBACKTRACEfull for a verbose backtrace
nodeinternalerrors867
  const err  new Errormessage
              
Error Command failed napi build CUsersGITLAB1AppDataLocalTempprebuildHFuPay targetx8664pcwindowsmsvc release strip


Any ideas why this is the case We had to use MSVC and NASM","'m trying compile quiche rust library Windows . nodejs native binding . works Linux Windows , however get error Windows : `` ` Generating Code ... crypto.vcxproj - > C : \GitLab-Runner\builds\MatrixAI\open-source\js-quic\target\x86_64-pc-windows-msvc\release\build\boring-sys-0344e752b3d59666\out\build\Release\crypto.lib cargo : root=C : \GitLab-Runner\builds\MatrixAI\open-source\js-quic\target\x86_64-pc-windows-msvc\release\build\boring-sys-0344e752b3d59666\out cargo : rustc-link-search=native=C : \GitLab-Runner\builds\MatrixAI\open-source\js-quic\target\x86_64-pc-windows-msvc\release\build\boring-sys-0344e752b3d59666\out/build/Release cargo : rustc-link-lib=static=crypto cargo : rustc-link-lib=static=ssl cargo : rerun-if-env-changed=BORING_BSSL_INCLUDE_PATH -- - stderr CMake Warning : Manually-specified variables used project : CMAKE_ASM_FLAGS CMAKE_ASM_FLAGS_RELEASE CMAKE_BUILD_TYPE thread 'main ' panicked ' '' enum_ ( unnamed_at_deps/boringssl/src/include\\openssl/err_h_291_1 ) '' valid Ident ' , C : \Users\gitlab_runner\.cargo\registry\src\github.com-1ecc6299db9ec823\proc-macro2-1.0.56\src\fallback.rs:811:9 stack backtrace : 0 : std : :panicking : :begin_panic_handler /rustc/2c8cc343237b8f7d5a3c3703e3a87f2eb2c54a74/library\std\src\panicking.rs:575 1 : core : :panicking : :panic_fmt /rustc/2c8cc343237b8f7d5a3c3703e3a87f2eb2c54a74/library\core\src\panicking.rs:64 2 : proc_macro2 : :fallback : :is_ident_continue 3 : < proc_macro2 : :fallback : :Group core : :fmt : :Debug > : :fmt 4 : proc_macro2 : :fallback : :Ident : :new 5 : proc_macro2 : :imp : :Ident : :new 6 : proc_macro2 : :Ident : :new 7 : bindgen : :ir : :context : :BindgenContext : :rust_ident_raw 8 : bindgen : :ir : :context : :BindgenContext : :rust_ident 9 : < bindgen : :ir : :enum_ty : :Enum bindgen : :codegen : :CodeGenerator > : :codegen 10 : < bindgen : :ir : :ty : :Type bindgen : :codegen : :CodeGenerator > : :codegen 11 : < bindgen : :ir : :item : :Item bindgen : :codegen : :CodeGenerator > : :codegen 12 : < bindgen : :ir : :module : :Module bindgen : :codegen : :CodeGenerator > : :codegen : : { { closure } } 13 : < bindgen : :ir : :module : :Module bindgen : :codegen : :CodeGenerator > : :codegen 14 : < bindgen : :ir : :item : :Item bindgen : :codegen : :CodeGenerator > : :codegen 15 : bindgen : :codegen : :codegen : : { { closure } } 16 : bindgen : :ir : :context : :BindgenContext : :gen 17 : bindgen : :codegen : :codegen 18 : < bindgen : :BindgenOptions core : :default : :Default > : :default 19 : bindgen : :Builder : :generate 20 : < core : :slice : :iter : :Iter < > core : :iter : :traits : :iterator : :Iterator > : :next 21 : core : :ops : :function : :FnOnce : :call_once { { vtable.shim } } note : details omitted , run ` RUST_BACKTRACE=full ` verbose backtrace . node : internal/errors:867 const err = new Error ( message ) ; ^ Error : Command failed : napi build C : \Users\GITLAB~1\AppData\Local\Temp\prebuild-HFuPay -- target=x86_64-pc-windows-msvc -- release -- strip `` ` ideas case ? use MSVC NASM ."
Glavin001,"I want to demonstrate code tracing

Write a simple Python example code

Then step by step pretend to be the Python interpreter and execute the statements and print each step Be as verbose as possible",want demonstrate code tracing . Write simple Python example code . step step pretend Python interpreter execute statements print step . verbose possible .
geohot,"Whats this GitHub issue mean

Fix VALIDHACKS for Images and make it default 300 bounty

When you read images out of bounds they will return 0s Currently the compiler is unaware of this and still gates the load Figure out when we dont need it and disable it

Images are used in the openpilot model openpilotgosh that have this extra gated load Safely remove it

Must be well tested for bounty its easy to do this subtly wrong

Simple example of issue
GPU1 DEBUG4 FORWARDONLY1 IMAGE2 python3 testtestopspy TestOpstestsimplepaddingconv2d

generates

float4 val0  lidx010lidx03readimagefdata1 smp int2lidx012lidx0121float400f00f00f00f  lidx0 ranges from 03

instead of

float4 val0  readimagefdata1 smp int2lidx010

to read image

dtypesimagef1 2 4  the last 4 is the float4 this is a 2x1 image

That gate is not needed if you remove the 2 and subtract 2 from the index You also then dont need the y index at all

See validhacks in toimageidx for the old broken code that hacked this The symbolic engine should be good enough now to do this properly","'s GitHub issue mean ? Fix VALIDHACKS Images make default ( $ 300 bounty ) read images bounds , return 0s . Currently compiler unaware still gates load . Figure n't need disable . Images used openpilot model openpilot/go.sh extra gated load . Safely remove ! Must well tested bounty , 's easy subtly wrong . Simple example issue : GPU=1 DEBUG=4 FORWARD_ONLY=1 IMAGE=2 python3 test/test_ops.py TestOps.test_simple_padding_conv2d generates float4 val0 = ( ( ( ( lidx0 * ( -1 ) ) < 0 ) * ( lidx0 < 3 ) ) ) ? ( read_imagef ( data1 , smp , ( int2 ) ( ( ( lidx0+1 ) % 2 ) , ( ( ( lidx0+1 ) /2 ) + ( -1 ) ) ) ) ) : ( float4 ) ( 0.0f,0.0f,0.0f,0.0f ) ; # ( lidx0 ranges 0-3 ) instead float4 val0 = read_imagef ( data1 , smp , ( int2 ) ( lidx0-1,0 ) ) read image dtypes.imagef ( ( 1 , 2 , 4 ) ) # last 4 float4 , 2x1 image gate needed remove % 2 subtract 2 index . also n't need index . See validhacks to_image_idx old ( broken ) code hacked . symbolic engine good enough properly ."
pavlovcik,how do i see the raw diff from the api of httpsgithubcomubiquityubiquibotpull759files,see raw diff api https : //github.com/ubiquity/ubiquibot/pull/759/files
Yukaii,"Im designing a socialfeature websites the partially improve the social ability feature of GitHub

Named Whos the OG OG means original gangster here it means those project early finder


Some raw system requirements and behaviors

 A crawler utilizes GitHub stargazers API
 A Backend that stores those crawl information
 A frontend for displaying
 User will use GitHub OAuth to login to this web service
 When user request for one repository data if theres no crawled data it will trigger and scheduled a crawling task for that repository then display WIP status in the frontend



GitHub stargazerss API

javascript
 Octokitjs  httpsgithubcomoctokitcorejsreadme const octokit  new Octokit auth YOURTOKEN  await octokitrequestGET reposownerrepostargazers  owner OWNER repo REPO headers  XGitHubApiVersion 20221128  

 and sample response

Status 200

  login octocat id 1 nodeid MDQ6VXNlcjE avatarurl httpsgithubcomimageserroroctocathappygif gravatarid  url httpsapigithubcomusersoctocat htmlurl httpsgithubcomoctocat followersurl httpsapigithubcomusersoctocatfollowers followingurl httpsapigithubcomusersoctocatfollowingotheruser gistsurl httpsapigithubcomusersoctocatgistsgistid starredurl httpsapigithubcomusersoctocatstarredownerrepo subscriptionsurl httpsapigithubcomusersoctocatsubscriptions organizationsurl httpsapigithubcomusersoctocatorgs reposurl httpsapigithubcomusersoctocatrepos eventsurl httpsapigithubcomusersoctocateventsprivacy receivedeventsurl httpsapigithubcomusersoctocatreceivedevents type User siteadmin false  





First try to organize parts that will be used in the system and explain their requirements repsectively","'m designing social-feature websites partially improve social ability feature GitHub . Named `` 's OG '' , OG means original gangster , means project early finder . raw system requirements behaviors : - crawler utilizes GitHub stargazers API - Backend stores crawl information - frontend displaying - User use GitHub OAuth login web service - user request one repository data , 's crawled data , trigger scheduled crawling task repository , display WIP status frontend -- - GitHub stargazers 's API : `` ` javascript // Octokit.js // https : //github.com/octokit/core.js # readme const octokit = new Octokit ( { auth : 'YOUR-TOKEN ' } ) await octokit.request ( 'GET /repos/ { owner } / { repo } /stargazers ' , { owner : 'OWNER ' , repo : 'REPO ' , headers : { ' X-GitHub-Api-Version ' : '2022-11-28 ' } } ) // sample response ` Status : 200 ` ` [ { `` login '' : `` octocat '' , `` id '' : 1 , `` node_id '' : `` MDQ6VXNlcjE= '' , `` avatar_url '' : `` https : //github.com/images/error/octocat_happy.gif '' , `` gravatar_id '' : `` '' , `` url '' : `` https : //api.github.com/users/octocat '' , `` html_url '' : `` https : //github.com/octocat '' , `` followers_url '' : `` https : //api.github.com/users/octocat/followers '' , `` following_url '' : `` https : //api.github.com/users/octocat/following { /other_user } '' , `` gists_url '' : `` https : //api.github.com/users/octocat/gists { /gist_id } '' , `` starred_url '' : `` https : //api.github.com/users/octocat/starred { /owner } { /repo } '' , `` subscriptions_url '' : `` https : //api.github.com/users/octocat/subscriptions '' , `` organizations_url '' : `` https : //api.github.com/users/octocat/orgs '' , `` repos_url '' : `` https : //api.github.com/users/octocat/repos '' , `` events_url '' : `` https : //api.github.com/users/octocat/events { /privacy } '' , `` received_events_url '' : `` https : //api.github.com/users/octocat/received_events '' , `` type '' : `` User '' , `` site_admin '' : false } ] ` `` ` -- - First try organize parts used system , explain requirements repsectively ."
simonw,"I have written a terminal app which does stuff when you type a line of text and hit enter

I want to add support for multiline inputs as well

What are other terminal apps that solve this and what patterns do they use",written terminal app stuff type line text hit enter want add support multi-line inputs well terminal apps solve patterns use ?
gwpl,"Could you make me Dockerfile for project httpsgithubcomPromtEngineerlocalGPT

Please ask me as many questions as will help you in preparation of Dockefile and other required files

Here is description of project from its READMEmd file


 localGPT

This project was inspired by the original privateGPThttpsgithubcomimartinezprivateGPT Most of the description here is inspired by the original privateGPT

For detailed overview of the project Watch this Youtube VideohttpsyoutubeMlyoObdIHyo

In this model I have replaced the GPT4ALL model with Vicuna7B model and we are using the InstructorEmbeddings instead of LlamaEmbeddings as used in the original privateGPT Both Embeddings as well as LLM will run on GPU instead of CPU It also has CPU support if you do not have a GPU see below for instruction

Ask questions to your documents without an internet connection using the power of LLMs 100 private no data leaves your execution environment at any point You can ingest documents and ask questions without an internet connection

Built with LangChainhttpsgithubcomhwchase17langchain and Vicuna7BhttpshuggingfacecoTheBlokevicuna7B11HF and InstructorEmbeddingshttpsinstructorembeddinggithubio

 Environment Setup

In order to set your environment up to run the code here first install all requirements

shell
pip install r requirementstxt


Then install AutoGPTQ  if you want to run quantized models for GPU

shell
git clone httpsgithubcomPanQiWeiAutoGPTQgit
cd AutoGPTQ
git checkout v022
pip install 


For more support on AutoGPTQ httpsgithubcomPanQiWeiAutoGPTQ

 Test dataset

This repo uses a Constitution of USA httpsconstitutioncenterorgmediafilesconstitutionpdf as an example

 Instructions for ingesting your own dataset

Put any and all of your txt pdf or csv files into the SOURCEDOCUMENTS directory
in the loaddocuments function replace the docspath with the absolute path of your sourcedocuments directory

The current default file types are txt pdf csv and xlsx if you want to use any other file type you will need to convert it to one of the default file types

Run the following command to ingest all the data

shell
python ingestpy   defaults to cuda


Use the device type argument to specify a given device

sh
python ingestpy devicetype cpu


Use help for a full list of supported devices

sh
python ingestpy help


It will create an index containing the local vectorstore Will take time depending on the size of your documents
You can ingest as many documents as you want and all will be accumulated in the local embeddings database
If you want to start from an empty database delete the index

Note When you run this for the first time it will download take time as it has to download the embedding model In the subseqeunt runs no data will leave your local enviroment and can be run without internet connection

 Ask questions to your documents locally

In order to ask a question run a command like

shell
python runlocalGPTpy


And wait for the script to require your input

shell
 Enter a query


Hit enter Wait while the LLM model consumes the prompt and prepares the answer Once done it will print the answer and the 4 sources it used as context from your documents you can then ask another question without rerunning the script just wait for the prompt again

Note When you run this for the first time it will need internet connection to download the vicuna7B model After that you can turn off your internet connection and the script inference would still work No data gets out of your local environment

Type exit to finish the script

 Run it on CPU

By default localGPT will use your GPU to run both the ingestpy and runlocalGPTpy scripts But if you do not have a GPU and want to run this on CPU now you can do that Warning Its going to be slow You will need to use devicetype cpuflag with both scripts

For Ingestion run the following

shell
python ingestpy devicetype cpu


In order to ask a question run a command like

shell
python runlocalGPTpy devicetype cpu


 Run the UI

1 Start by opening up runlocalGPTAPIpy in a code editor of your choice If you are using gpu skip to step 3

2 If you are running on cpu change DEVICETYPE  cuda to DEVICETYPE  cpu

    Comment out the following

   shell
   modelid  TheBlokeWizardLM7BuncensoredGPTQ
   modelbasename  WizardLM7BuncensoredGPTQ4bit128gcompatnoactordersafetensors
   LLM  loadmodeldevicetypeDEVICETYPE modelidmodelid modelbasename  modelbasename
   

    Uncomment

   shell
   modelid  TheBlokeguanaco7BHF  or some other HF or bin model
   LLM  loadmodeldevicetypeDEVICETYPE modelidmodelid
   

    If you are running gpu there should be nothing to change Save and close runlocalGPTAPIpy

3 Open up a terminal and activate your python environment that contains the dependencies installed from requirementstxt

4 Navigate to the LOCALGPT directory

5 Run the following command python runlocalGPTAPIpy The API should being to run

6 Wait until everything has loaded in You should see something like INFOwerkzeugPress CTRLC to quit

7 Open up a second terminal and activate the same python environment

8 Navigate to the LOCALGPTlocalGPTUI directory

9 Run the command python localGPTUIpy

10 Open up a web browser and go the address httplocalhost5111

 How does it work

Selecting the right local models and the power of LangChain you can run the entire pipeline locally without any data leaving your environment and with reasonable performance

 ingestpy uses LangChain tools to parse the document and create embeddings locally using InstructorEmbeddings It then stores the result in a local vector database using Chroma vector store
 runlocalGPTpy uses a local LLM Vicuna7B in this case to understand questions and create answers The context for the answers is extracted from the local vector store using a similarity search to locate the right piece of context from the docs
 You can replace this local LLM with any other LLM from the HuggingFace Make sure whatever LLM you select is in the HF format

 How to select different LLM models

The following will provide instructions on how you can select a different LLM model to create your response

1 Open up runlocalGPTpy
2 Go to def maindevicetype showsources
3 Go to the comment where it says  load the LLM for generating Natural Language responses
4 Below it it details a bunch of examples on models from HuggingFace that have already been tested to be run with the original trained model ending with HF or have a bin in its Files and versions and quantized models ending with GPTQ or have a noactorder or safetensors in its Files and versions
5 For models that end with HF or have a bin inside its Files and versions on its HuggingFace page

    Make sure you have a modelid selected For example  modelid  TheBlokeguanaco7BHF
    If you go to its HuggingFace Site httpshuggingfacecoTheBlokeguanaco7BHF and go to Files and versions you will notice model files that end with a bin extension
    Any model files that contain bin extensions will be run with the following code where the  load the LLM for generating Natural Language responses comment is found
    modelid  TheBlokeguanaco7BHF

     llm  loadmodeldevicetype modelidmodelid

6 For models that contain GPTQ in its name and or have a noactorder or safetensors extension inside its Files and versions on its HuggingFace page

    Make sure you have a modelid selected For example  modelid  TheBlokewizardLM7BGPTQ
    You will also need its model basename file selected For example  modelbasename  wizardLM7BGPTQ4bitcompatnoactordersafetensors
    If you go to its HuggingFace Site httpshuggingfacecoTheBlokewizardLM7BGPTQ and go to Files and versions you will notice a model file that ends with a safetensors extension
    Any model files that contain noactorder or safetensors extensions will be run with the following code where the  load the LLM for generating Natural Language responses comment is found
    modelid  TheBlokeWizardLM7BuncensoredGPTQ

     modelbasename  WizardLM7BuncensoredGPTQ4bit128gcompatnoactordersafetensors

     llm  loadmodeldevicetype modelidmodelid modelbasename  modelbasename

7 Comment out all other instances of modelidother model names modelbasenameother base model names and llm  loadmodelargs

 System Requirements

 Python Version

To use this software you must have Python 310 or later installed Earlier versions of Python will not compile

 C Compiler

If you encounter an error while building a wheel during the pip install process you may need to install a C compiler on your computer

 For Windows 1011

To install a C compiler on Windows 1011 follow these steps

1 Install Visual Studio 2022
2 Make sure the following components are selected
    Universal Windows Platform development
    C CMake tools for Windows
3 Download the MinGW installer from the MinGW websitehttpssourceforgenetprojectsmingw
4 Run the installer and select the gcc component

 NVIDIA Drivers Issues

Follow this pagehttpslinuxconfigorghowtoinstallthenvidiadriversonubuntu2204 to install NVIDIA Drivers

 M1M2 Macbook users

1 Follow this pagehttpsdeveloperapplecommetalpytorch to build up PyTorch with Metal Performance Shaders MPS support PyTorch uses the new MPS backend for GPU training acceleration It is good practice to verify mps support using a simple Python script as mentioned in the provided link

2 By following the page here is an example of what you may initiate in your terminal

shell
xcodeselect install
conda install pytorch torchvision torchaudio c pytorchnightly
pip install chardet
pip install cchardet
pip uninstall charsetnormalizer
pip install charsetnormalizer
pip install pdfminersix
pip install xformers


3 Please keep in mind that the quantized models are not yet supported by Apple Silicon M1M2 by autogptq library that is being used for loading quantized models see herehttpsgithubcomPanQiWeiAutoGPTQissues133issuecomment1575002893 Therefore you will not be able to run quantized models on M1M2



 Star History

Star History CharthttpsapistarhistorycomsvgreposPromtEngineerlocalGPTtypeDatehttpsstarhistorycomPromtEngineerlocalGPTDate

 Disclaimer

This is a test project to validate the feasibility of a fully local solution for question answering using LLMs and Vector embeddings It is not production ready and it is not meant to be used in production Vicuna7B is based on the Llama model so that has the original Llama license
","Could make Dockerfile project https : //github.com/PromtEngineer/localGPT Please ask many questions help preparation Dockefile required files , description project 's README.md file : `` ` # localGPT project inspired original [ privateGPT ] ( https : //github.com/imartinez/privateGPT ) . description inspired original privateGPT . detailed overview project , Watch [ Youtube Video ] ( https : //youtu.be/MlyoObdIHyo ) . model , replaced GPT4ALL model Vicuna-7B model using InstructorEmbeddings instead LlamaEmbeddings used original privateGPT . Embeddings well LLM run GPU instead CPU . also CPU support GPU ( see instruction ) . Ask questions documents without internet connection , using power LLMs . 100 % private , data leaves execution environment point . ingest documents ask questions without internet connection ! Built [ LangChain ] ( https : //github.com/hwchase17/langchain ) [ Vicuna-7B ] ( https : //huggingface.co/TheBloke/vicuna-7B-1.1-HF ) [ InstructorEmbeddings ] ( https : //instructor-embedding.github.io/ ) # Environment Setup order set environment run code , first install requirements : `` ` shell pip install -r requirements.txt `` ` install AutoGPTQ - want run quantized models GPU `` ` shell git clone https : //github.com/PanQiWei/AutoGPTQ.git cd AutoGPTQ git checkout v0.2.2 pip install . `` ` support [ AutoGPTQ ] ( https : //github.com/PanQiWei/AutoGPTQ ) . # # Test dataset repo uses [ Constitution USA ] ( https : //constitutioncenter.org/media/files/constitution.pdf ) example . # # Instructions ingesting dataset Put .txt , .pdf , .csv files SOURCE_DOCUMENTS directory load_documents ( ) function , replace docs_path absolute path source_documents directory . current default file types .txt , .pdf , .csv , .xlsx , want use file type , need convert one default file types . Run following command ingest data . `` ` shell python ingest.py # defaults cuda `` ` Use device type argument specify given device . `` ` sh python ingest.py -- device_type cpu `` ` Use help full list supported devices . `` ` sh python ingest.py -- help `` ` create index containing local vectorstore . take time , depending size documents . ingest many documents want , accumulated local embeddings database . want start empty database , delete ` index ` . Note : run first time , download take time download embedding model . subseqeunt runs , data leave local enviroment run without internet connection . # # Ask questions documents , locally ! order ask question , run command like : `` ` shell python run_localGPT.py `` ` wait script require input . `` ` shell > Enter query : `` ` Hit enter . Wait LLM model consumes prompt prepares answer . done , print answer 4 sources used context documents ; ask another question without re-running script , wait prompt . Note : run first time , need internet connection download vicuna-7B model . turn internet connection , script inference would still work . data gets local environment . Type ` exit ` finish script . # Run CPU default , localGPT use GPU run ` ingest.py ` ` run_localGPT.py ` scripts . GPU want run CPU , ( Warning : going slow ! ) . need use ` -- device_type cpu ` flag scripts . Ingestion run following : `` ` shell python ingest.py -- device_type cpu `` ` order ask question , run command like : `` ` shell python run_localGPT.py -- device_type cpu `` ` # Run UI 1 . Start opening ` run_localGPT_API.py ` code editor choice . using gpu skip step 3 . 2 . running cpu change ` DEVICE_TYPE = 'cuda ' ` ` DEVICE_TYPE = 'cpu ' ` . - Comment following : `` ` shell model_id = `` TheBloke/WizardLM-7B-uncensored-GPTQ '' model_basename = `` WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors '' LLM = load_model ( device_type=DEVICE_TYPE , model_id=model_id , model_basename = model_basename ) `` ` - Uncomment : `` ` shell model_id = `` TheBloke/guanaco-7B-HF '' # -HF .bin model LLM = load_model ( device_type=DEVICE_TYPE , model_id=model_id ) `` ` - running gpu nothing change . Save close ` run_localGPT_API.py ` . 3 . Open terminal activate python environment contains dependencies installed requirements.txt . 4 . Navigate ` /LOCALGPT ` directory . 5 . Run following command ` python run_localGPT_API.py ` . API run . 6 . Wait everything loaded . see something like ` INFO : werkzeug : Press CTRL+C quit ` . 7 . Open second terminal activate python environment . 8 . Navigate ` /LOCALGPT/localGPTUI ` directory . 9 . Run command ` python localGPTUI.py ` . 10 . Open web browser go address ` http : //localhost:5111/ ` . # work ? Selecting right local models power ` LangChain ` run entire pipeline locally , without data leaving environment , reasonable performance . - ` ingest.py ` uses ` LangChain ` tools parse document create embeddings locally using ` InstructorEmbeddings ` . stores result local vector database using ` Chroma ` vector store . - ` run_localGPT.py ` uses local LLM ( Vicuna-7B case ) understand questions create answers . context answers extracted local vector store using similarity search locate right piece context docs . - replace local LLM LLM HuggingFace . Make sure whatever LLM select HF format . # select different LLM models ? following provide instructions select different LLM model create response : 1 . Open ` run_localGPT.py ` 2 . Go ` def main ( device_type , show_sources ) ` 3 . Go comment says ` # load LLM generating Natural Language responses ` 4 . , details bunch examples models HuggingFace already tested run original trained model ( ending HF .bin `` Files versions '' ) , quantized models ( ending GPTQ .no-act-order .safetensors `` Files versions '' ) . 5 . models end HF .bin inside `` Files versions '' HuggingFace page . - Make sure model_id selected . example - > ` model_id = `` TheBloke/guanaco-7B-HF '' ` - go HuggingFace [ Site ] ( https : //huggingface.co/TheBloke/guanaco-7B-HF ) go `` Files versions '' notice model files end .bin extension . - model files contain .bin extensions run following code ` # load LLM generating Natural Language responses ` comment found . - ` model_id = `` TheBloke/guanaco-7B-HF '' ` ` llm = load_model ( device_type , model_id=model_id ) ` 6 . models contain GPTQ name .no-act-order .safetensors extension inside `` Files versions HuggingFace page . - Make sure model_id selected . example - > model_id = ` `` TheBloke/wizardLM-7B-GPTQ '' ` - also need model basename file selected . example - > ` model_basename = `` wizardLM-7B-GPTQ-4bit.compat.no-act-order.safetensors '' ` - go HuggingFace [ Site ] ( https : //huggingface.co/TheBloke/wizardLM-7B-GPTQ ) go `` Files versions '' notice model file ends .safetensors extension . - model files contain no-act-order .safetensors extensions run following code ` # load LLM generating Natural Language responses ` comment found . - ` model_id = `` TheBloke/WizardLM-7B-uncensored-GPTQ '' ` ` model_basename = `` WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors '' ` ` llm = load_model ( device_type , model_id=model_id , model_basename = model_basename ) ` 7 . Comment instances ` model_id= '' model names '' ` , ` model_basename=other base model names ` , ` llm = load_model ( args * ) ` # System Requirements # # Python Version use software , must Python 3.10 later installed . Earlier versions Python compile . # # C++ Compiler encounter error building wheel ` pip install ` process , may need install C++ compiler computer . # # # Windows 10/11 install C++ compiler Windows 10/11 , follow steps : 1 . Install Visual Studio 2022 . 2 . Make sure following components selected : - Universal Windows Platform development - C++ CMake tools Windows 3 . Download MinGW installer [ MinGW website ] ( https : //sourceforge.net/projects/mingw/ ) . 4 . Run installer select `` gcc '' component . # # # NVIDIA Driver 's Issues : Follow [ page ] ( https : //linuxconfig.org/how-to-install-the-nvidia-drivers-on-ubuntu-22-04 ) install NVIDIA Drivers . # # # M1/M2 Macbook users : 1- Follow [ page ] ( https : //developer.apple.com/metal/pytorch/ ) build PyTorch Metal Performance Shaders ( MPS ) support . PyTorch uses new MPS backend GPU training acceleration . good practice verify mps support using simple Python script mentioned provided link . 2- following page , example may initiate terminal `` ` shell xcode-select -- install conda install pytorch torchvision torchaudio -c pytorch-nightly pip install chardet pip install cchardet pip uninstall charset_normalizer pip install charset_normalizer pip install pdfminer.six pip install xformers `` ` 3- Please keep mind quantized models yet supported Apple Silicon ( M1/M2 ) auto-gptq library used loading quantized models , [ see ] ( https : //github.com/PanQiWei/AutoGPTQ/issues/133 # issuecomment-1575002893 ) . Therefore , able run quantized models M1/M2 . # # Star History [ ! [ Star History Chart ] ( https : //api.star-history.com/svg ? repos=PromtEngineer/localGPT & type=Date ) ] ( https : //star-history.com/ # PromtEngineer/localGPT & Date ) # Disclaimer test project validate feasibility fully local solution question answering using LLMs Vector embeddings . production ready , meant used production . Vicuna-7B based Llama model original Llama license . `` `"
CrosRoad95,how can i in c use PCRE to first compile regex then reuse it,c++ use PCRE first compile regex reuse ?
forrestsmithfb,I have an exe on Windows that came from C code how can I tell if it was compiled by MSVC or GCC,exe Windows came C++ code . tell compiled MSVC GCC ?
ArdenHide,HI What better in C for Task class Use Result or GetAwaiterGetResult,HI ! better C # Task class . Use ` Result ` ` GetAwaiter ( ) .GetResult ( ) ` ?
purpleslurple,"For this line of PHP code filelocation  httpSERVERHTTPHOSTfilelocation
is there a way to programmatically get the protocol instead of hardcoding it","line PHP code $ file_location = `` http : // '' . $ _SERVER [ 'HTTP_HOST ' ] . $ file_location ; way programmatically get protocol , instead hard-coding ?"
camdotcom14,I need to edit the SGTK template and schema to match my existing folder structure ,need edit SGTK template schema match existing folder structure
CakeCrusher,I am following this documentation httpswwwpassportjsorgpackagespassportoauth2,following documentation https : //www.passportjs.org/packages/passport-oauth2/
certik,"Here is how to do arrays of structs in Python

import ctypes
from random import randint

class STRUCT2ctypesStructure
    pack2
    fields  field1 ctypescshort
                field2 ctypescshort
                field3 ctypescshort
                field4 ctypescshort
                field5 ctypescshort
                field6 ctypescshort
                field7 ctypescshort
                field8 ctypescshort

class STRUCT1ctypesStructure
    pack2
    fields  elements ctypescshort
                an array of structs
                STRUCTARRAY ctypesPOINTERSTRUCT2

    def initselfnumofstructs
        elems  STRUCT2  numofstructs
        selfSTRUCTARRAY  ctypescastelemsctypesPOINTERSTRUCT2
        selfelements  numofstructs

        for num in range0numofstructs
            selfSTRUCTARRAYnumfield1  1
            selfSTRUCTARRAYnumfield2  2
            selfSTRUCTARRAYnumfield3  3
            selfSTRUCTARRAYnumfield4  4

for num in range0100
    test  STRUCT1num
    printi done  num


Is there a way to map this arrays of structs using ctypes into a NumPy array I do not want to do any copy I want the NumPy array to map directly to memory","arrays structs Python : `` ` import ctypes random import randint class STRUCT_2 ( ctypes.Structure ) : # _pack_=2 _fields_ = [ ( 'field_1 ' , ctypes.c_short ) , ( 'field_2 ' , ctypes.c_short ) , ( 'field_3 ' , ctypes.c_short ) , ( 'field_4 ' , ctypes.c_short ) , ( 'field_5 ' , ctypes.c_short ) , ( 'field_6 ' , ctypes.c_short ) , ( 'field_7 ' , ctypes.c_short ) , ( 'field_8 ' , ctypes.c_short ) ] class STRUCT_1 ( ctypes.Structure ) : # _pack_=2 _fields_ = [ ( 'elements ' , ctypes.c_short ) , # array structs ( 'STRUCT_ARRAY ' , ctypes.POINTER ( STRUCT_2 ) ) ] def __init__ ( self , num_of_structs ) : elems = ( STRUCT_2 * num_of_structs ) ( ) self.STRUCT_ARRAY = ctypes.cast ( elems , ctypes.POINTER ( STRUCT_2 ) ) self.elements = num_of_structs num range ( 0 , num_of_structs ) : self.STRUCT_ARRAY [ num ] .field_1 = 1 self.STRUCT_ARRAY [ num ] .field_2 = 2 self.STRUCT_ARRAY [ num ] .field_3 = 3 self.STRUCT_ARRAY [ num ] .field_4 = 4 num range ( 0,100 ) : test = STRUCT_1 ( num ) print ( `` % done '' % num ) `` ` way map arrays structs using ctypes NumPy array ? want copy , want NumPy array map directly memory ."
bdc-ehealth,How can I define mappings between value set values in fhir  ,define mappings value set values fhir ?
marcodotcastro,Em github action como realizar os testes da aplicao rails usando um dockerfile para criar o ambiente,"Em github action , como realizar os testes da aplicação rails usando um dockerfile para criar ambiente ?"
neilenns,How do I add something to the clipboard in a react app,add something clipboard react app
ruslandoga,"explain ClickHouse mergetree parts naming

 ls l storedd1dd18c64d7fb94053975979214b797f11
total 8
drwxrxrx  10 q  staff  320 Jul  4 1709 all10100
drwxrxrx  10 q  staff  320 Jul  4 1711 all11110
drwxrxrx  10 q  staff  320 Jul  4 1655 all142
drwxrxrx  10 q  staff  320 Jul  4 1709 all5102
drwxrxrx  10 q  staff  320 Jul  4 1712 all5113
drwxrxrx  10 q  staff  320 Jul  4 1657 all550
drwxrxrx  10 q  staff  320 Jul  4 1704 all591
drwxrxrx  10 q  staff  320 Jul  4 1703 all660
drwxrxrx  10 q  staff  320 Jul  4 1703 all770
drwxrxrx  10 q  staff  320 Jul  4 1703 all880
drwxrxrx  10 q  staff  320 Jul  4 1703 all990
drwxrxrx   2 q  staff   64 Jul  4 1421 detached
rwrr   1 q  staff    1 Jul  4 1421 formatversiontxt",explain ClickHouse mergetree parts naming $ ls -l ./store/dd1/dd18c64d-7fb9-4053-9759-79214b797f11/ total 8 drwxr-xr-x 10 q staff 320 Jul 4 17:09 all_10_10_0/ drwxr-xr-x 10 q staff 320 Jul 4 17:11 all_11_11_0/ drwxr-xr-x 10 q staff 320 Jul 4 16:55 all_1_4_2/ drwxr-xr-x 10 q staff 320 Jul 4 17:09 all_5_10_2/ drwxr-xr-x 10 q staff 320 Jul 4 17:12 all_5_11_3/ drwxr-xr-x 10 q staff 320 Jul 4 16:57 all_5_5_0/ drwxr-xr-x 10 q staff 320 Jul 4 17:04 all_5_9_1/ drwxr-xr-x 10 q staff 320 Jul 4 17:03 all_6_6_0/ drwxr-xr-x 10 q staff 320 Jul 4 17:03 all_7_7_0/ drwxr-xr-x 10 q staff 320 Jul 4 17:03 all_8_8_0/ drwxr-xr-x 10 q staff 320 Jul 4 17:03 all_9_9_0/ drwxr-xr-x 2 q staff 64 Jul 4 14:21 detached/ -rw-r -- r -- 1 q staff 1 Jul 4 14:21 format_version.txt
nmck257,Given this issue httpsgithubcomopenrewriterewritespringissues300 can you build a OpenRewrite java module to refactor and migrate Apache HTTP components 4 to Apache HTTP Components 5 following this guide httpshcapacheorghttpcomponentsclient52xmigrationguidemigrationtoclassichtml ,Given issue https : //github.com/openrewrite/rewrite-spring/issues/300 build OpenRewrite java module refactor migrate Apache HTTP components 4 Apache HTTP Components 5 following guide https : //hc.apache.org/httpcomponents-client-5.2.x/migration-guide/migration-to-classic.html ?
CakeCrusher,"reference flask app apppy
from flask import Flask request jsonify
from dotenv import loaddotenv
from flaskcors import CORS
import os
import json
from datetime import datetime
from collections import deque
from typing import Dict List TypedDict
from openplugincore import openplugincompletion OpenPluginMemo
from datetime import datetime
from urllibparse import quote unquote
from openai import ChatCompletion


loaddotenv

OPENAIAPIKEY  osgetenvOPENAIAPIKEY
PORT  intosgetenvPORT

openpluginmemo  OpenPluginMemo
openpluginmemoinit

app  Flaskname
CORSapp

class BucketItemTypedDict
    datesent datetime
    pluginname str

class TokenInfoTypedDict
    totaluse int
    bucket ListBucketItem

earlyaccesstokens  
    extrac22a34e289a848b28474c664b577526b  public
    extra692df72bec3f49e4a1cefb1fbc34aebd  public

requestdata Dictstr TokenInfo  token totaluse 0 bucket  for token in earlyaccesstokens
printrequestdata n jsondumpsrequestdata indent4

 Maximum requests allowed per minute per token
MAXREQUESTSPERDAY  200

def ratelimiterpassearlyaccesstoken str pluginname str  bool
    now  datetimeutcnow

    tokeninfo  requestdataearlyaccesstoken

    printfRequest from earlyaccesstoken with plugin pluginname

     Filter out requests that are older than a day from the token bucket
    validrequests  req for req in tokeninfobucket if now  reqdatesenttotalseconds  86400

     Update the token bucket with valid requests
    tokeninfobucket  validrequests

     Check the length of valid requests
    if lenvalidrequests  MAXREQUESTSPERDAY
        validrequestsappend
            datesent now
            pluginname pluginname
        
        tokeninfototaluse  1
        return True

    return False


approutechatcompletion methodsPOST
def chatcompletion
    try
        data  requestgetjson

        earlyaccesstoken  datagetearlyaccesstoken None
        if not earlyaccesstoken
            raise Exceptionearlyaccesstoken is missing
        if earlyaccesstoken not in requestdata
            raise Exceptionearlyaccesstoken is invalid
        if not ratelimiterpassearlyaccesstoken datapluginname
            raise ExceptionRate limit exceeded
        
        chatgptargs  datacopy
        pluginname  chatgptargspluginname
        del chatgptargspluginname
        del chatgptargsearlyaccesstoken

        messages  chatgptargsgetmessages None
         raise error if last message content is empty
        if not messages
            raise ValueErrorLast message content is empty
        
         delete messages from chatgptargs
        del chatgptargsmessages
        
        response  openplugincompletion
            openaiapikeyOPENAIAPIKEY
            pluginnamepluginname
            messagesmessages
            chatgptargs
        
        return jsonifyresponse

    except Exception as e
        errorclass  typeename
        errormessage  stre
        return jsonifyerror ferrorclass error errormessage 500


I have already setup the env variable MONGODBURIshow me how to setup MongoDB so that the server can read it please show me the full code","reference flask app ./app.py : flask import Flask , request , jsonify dotenv import load_dotenv flask_cors import CORS import os import json datetime import datetime collections import deque typing import Dict , List , TypedDict openplugincore import openplugin_completion , OpenPluginMemo datetime import datetime urllib.parse import quote , unquote openai import ChatCompletion load_dotenv ( ) OPENAI_API_KEY = os.getenv ( 'OPENAI_API_KEY ' ) PORT = int ( os.getenv ( 'PORT ' ) ) open_plugin_memo = OpenPluginMemo ( ) open_plugin_memo.init ( ) app = Flask ( __name__ ) CORS ( app ) class BucketItem ( TypedDict ) : date_sent : datetime plugin_name : str class TokenInfo ( TypedDict ) : total_use : int bucket : List [ BucketItem ] early_access_tokens = [ '__extra__-c22a34e2-89a8-48b2-8474-c664b577526b ' , # public '__extra__-692df72b-ec3f-49e4-a1ce-fb1fbc34aebd ' # public ] request_data : Dict [ str , TokenInfo ] = { token : { `` total_use '' : 0 , `` bucket '' : [ ] } token early_access_tokens } print ( `` request_data : \n '' , json.dumps ( request_data , indent=4 ) ) # Maximum requests allowed per minute per token MAX_REQUESTS_PER_DAY = 200 def rate_limiter_pass ( early_access_token : str , plugin_name : str ) - > bool : = datetime.utcnow ( ) token_info = request_data [ early_access_token ] print ( f '' Request \ '' { early_access_token } \ '' plugin \ '' { plugin_name } \ '' '' ) # Filter requests older day token bucket valid_requests = [ req req token_info [ `` bucket '' ] ( - req [ `` date_sent '' ] ) .total_seconds ( ) < 86400 ] # Update token bucket valid requests token_info [ `` bucket '' ] = valid_requests # Check length valid requests len ( valid_requests ) < MAX_REQUESTS_PER_DAY : valid_requests.append ( { `` date_sent '' : , `` plugin_name '' : plugin_name } ) token_info [ `` total_use '' ] += 1 return True return False @ app.route ( '/chat_completion ' , methods= [ 'POST ' ] ) def chat_completion ( ) : try : data = request.get_json ( ) early_access_token = data.get ( 'early_access_token ' , None ) early_access_token : raise Exception ( `` early_access_token missing '' ) early_access_token request_data : raise Exception ( `` early_access_token invalid '' ) rate_limiter_pass ( early_access_token , data [ `` plugin_name '' ] ) : raise Exception ( `` Rate limit exceeded '' ) chatgpt_args = data.copy ( ) plugin_name = chatgpt_args [ `` plugin_name '' ] del chatgpt_args [ `` plugin_name '' ] del chatgpt_args [ `` early_access_token '' ] messages = chatgpt_args.get ( `` messages '' , None ) # raise error last message content empty messages : raise ValueError ( `` Last message content empty '' ) # delete messages chatgpt_args del chatgpt_args [ `` messages '' ] response = openplugin_completion ( openai_api_key=OPENAI_API_KEY , plugin_name=plugin_name , messages=messages , * * chatgpt_args , ) return jsonify ( response ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 500 ... already setup env variable ` MONGODB_URI ` show setup MongoDB server read . please show full code"
andrewgazelka,esp for small sizes  always looks circular However a div that has same width and height in pixels and rounded border at 50 sometimes looks more like an ellipse that either has biggest diameter on y or x axis When scaling with cmd and cmd the ellipses that circular vs ellipsex vs ellipsey change Why is this How can I fix it ,"esp small sizes `` • '' always looks circular . However , div width height pixels rounded border 50 % sometimes looks like ellipse either biggest diameter x axis . scaling cmd+ cmd- ellipses circular vs ellipse-x vs ellipse-y change . ? fix ?"
kakimochi,53392360bldg6697opgmlzipZip ArchiveCityGML2XY,53392360_bldg_6697_op.gml.zipZip ArchiveアップしたCityGMLデータに含まれる建物データを2次元のXY座標として可視化してください
mhrimaz,can i use components written in another js framework or vanille in vue 3,use components written another js framework ( vanille ) vue 3 ?
woojinsung-jimmy,"include stdioh
include stdlibh
include stringh
include unistdh
include arpaineth

define SERVERIP 127001   IP 
define PORT 3001
define BUFFERSIZE 258    

int main 
    int clientsocket
    struct sockaddrin serveraddr
    char bufferBUFFERSIZE    
    int flag c

     Create socket
    if clientsocket  socketAFINET SOCKDGRAM 0  0 
        perrorsocket creation failed
        exitEXITFAILURE
    

    memsetserveraddr 0 sizeofserveraddr

     Configure server address
    serveraddrsinfamily  AFINET
    serveraddrsinport  htonsPORT
    if inetptonAFINET SERVERIP serveraddrsinaddr  0 
        perrorinetpton failed
        exitEXITFAILURE
    

    while 1 
        do 
            flag  0
            printfClient You 
            if fgetsbuffer sizeofbuffer stdin 
                printf  n
                flag  1
                continue
            
            bufferstrcspnbuffer n  0    
            int sendresult  sendtoclientsocket buffer strlenbuffer 0 const struct sockaddr serveraddr sizeofserveraddr
            if sendresult  0 
                perrorsendto failed
                flag  1
            
         while flag

         Receive data from server
        ssizet receivedbytes  recvfromclientsocket buffer sizeofbuffer 0 NULL NULL
        if receivedbytes  0 
            perrorrecvfrom failed
            continue
        

         Print the received data in hexadecimal format
        printfServer 
        for ssizet i  0 i  receivedbytes i 
            printf02x  unsigned charbufferi
        
        printfn
    

    closeclientsocket
    return 0

buffer  int ","# include < stdio.h > # include < stdlib.h > # include < string.h > # include < unistd.h > # include < arpa/inet.h > # define SERVER_IP `` 127.0.0.1 '' // 서버 IP 주소 # define PORT 3001 # define BUFFER_SIZE 258 // 최대 데이터 크기 int main ( ) { int client_socket ; struct sockaddr_in server_addr ; char buffer [ BUFFER_SIZE ] ; // 데이터를 저장할 버퍼 int flag , c ; // Create socket ( ( client_socket = socket ( AF_INET , SOCK_DGRAM , 0 ) ) < 0 ) { perror ( `` socket creation failed '' ) ; exit ( EXIT_FAILURE ) ; } memset ( & server_addr , 0 , sizeof ( server_addr ) ) ; // Configure server address server_addr.sin_family = AF_INET ; server_addr.sin_port = htons ( PORT ) ; ( inet_pton ( AF_INET , SERVER_IP , & server_addr.sin_addr ) < = 0 ) { perror ( `` inet_pton failed '' ) ; exit ( EXIT_FAILURE ) ; } ( 1 ) { { flag = 0 ; printf ( `` Client ( ) : `` ) ; ( ! fgets ( buffer , sizeof ( buffer ) , stdin ) ) { printf ( `` 입력 오류가 발생하였습니다.\n '' ) ; flag = 1 ; continue ; } buffer [ strcspn ( buffer , `` \n '' ) ] = '\0 ' ; // 줄바꿈 문자 제거 int send_result = sendto ( client_socket , buffer , strlen ( buffer ) , 0 , ( const struct sockaddr * ) & server_addr , sizeof ( server_addr ) ) ; ( send_result < 0 ) { perror ( `` sendto failed '' ) ; flag = 1 ; } } ( flag ) ; // Receive data server ssize_t received_bytes = recvfrom ( client_socket , buffer , sizeof ( buffer ) , 0 , NULL , NULL ) ; ( received_bytes < 0 ) { perror ( `` recvfrom failed '' ) ; continue ; } // Print received data hexadecimal format printf ( `` Server : `` ) ; ( ssize_t = 0 ; < received_bytes ; i++ ) { printf ( `` % 02x `` , ( unsigned char ) buffer [ ] ) ; } printf ( `` \n '' ) ; } close ( client_socket ) ; return 0 ; } buffer 변수를 int로 바꿔줘"
sabedevops,What are the main approaches to building Linux packages eg DEB RPM for a Go project My goal is to enhance the CI jobs that are triggered when Git commits are pushed so that each release will include the Linux packages in addition to the binaries we are already building and releasing,"main approaches building Linux packages , e.g . DEB , RPM , Go project ? goal enhance CI jobs triggered Git commits pushed release include Linux packages addition binaries already building releasing ."
posix4e,android llm adblocker help me write it Im using gpt4all to run the llm on the phone All of the content of the connections should be sent to the vpn and then it should be able to decide what connections to block and not block,"android llm adblocker . help write . 'm using gpt4all run llm phone . content connections sent vpn , able decide connections block block ."
Richie-Lee,"I am executing an ab test where I have a beta prior for both the treatment and control group Additionally I have empirical data in the form of number of observations and their respective number of conversions

These should give me all the pieces I need to compute a betabinomial bayes factor","executing a/b test , beta prior treatment control group . Additionally , empirical data form number observations respective number conversions . give pieces need compute beta-binomial bayes factor"
jabrena,Why the beans from ApplicationContext are different than the beans from BeansEndpoint,beans ApplicationContext different beans BeansEndpoint ?
VolkerSchroeder13,iaddcssselector divbreadcrumb  div  div  a  span,"i.add_css ( 'selector ' , 'div # breadcrumb > div > div > > span ' )"
joaogdfaero,"When deploying my application and acessing the trips view I get the following error on the logs

20230816T002444874 app148edd6da73638 gru info I 20230816T002444874304 255 INFO   12cc7135b2364ffe8deb55f2c08ce547 Completed 500 Internal Server Error in 5ms ActiveRecord 14ms  Allocations 1878

20230816T002444875 app148edd6da73638 gru info F 20230816T002444875658 255 FATAL   12cc7135b2364ffe8deb55f2c08ce547

20230816T002444875 app148edd6da73638 gru info 12cc7135b2364ffe8deb55f2c08ce547 ActionViewTemplateError PGUndefinedTable ERROR relation trips does not exist","deploying application acessing trips view , get following error logs : 2023-08-16T00:24:44.874 app [ 148edd6da73638 ] gru [ info ] , [ 2023-08-16T00:24:44.874304 # 255 ] INFO -- : [ 12cc7135-b236-4ffe-8deb-55f2c08ce547 ] Completed 500 Internal Server Error 5ms ( ActiveRecord : 1.4ms | Allocations : 1878 ) 2023-08-16T00:24:44.875 app [ 148edd6da73638 ] gru [ info ] F , [ 2023-08-16T00:24:44.875658 # 255 ] FATAL -- : [ 12cc7135-b236-4ffe-8deb-55f2c08ce547 ] 2023-08-16T00:24:44.875 app [ 148edd6da73638 ] gru [ info ] [ 12cc7135-b236-4ffe-8deb-55f2c08ce547 ] ActionView : :Template : :Error ( PG : :UndefinedTable : ERROR : relation `` trips '' exist"
neilenns,I want a react MUI main page that has a left pane and a right main document area How can I lay that out,want react MUI main page left pane right main document area . lay ?
neilenns,Im currently using Roboto as my font for my react MUI app What are other open source options and how would I use it instead,'m currently using Roboto font react MUI app . open source options would use instead ?
kusche12,"I am using the package reactnativeimagecroppicker to allow the user to select a video from their iOS device After clicking on the video the package shows a Processing assets string for the duration of time that it takes to select and compress the video I would like to patch this package so that I can return the percentage of time completed that the image processor will take

It is written in ObjectiveC using m and h files I dont know this language Can you help me interpret some of the following code so that you can show me a good place to make this change","using package react-native-image-crop-picker allow user select video iOS device . clicking video , package shows `` Processing assets ... '' string duration time takes select compress video . would like patch package return percentage time completed image processor take . written Objective-C ( using * .m * .h . files ) . n't know language . help interpret following code show good place make change ?"
jabrena,Using maven how to skip a module when I execute maven clean install,"Using maven , skip module execute maven clean install ?"
ilixindri,"Starting the development server

Error error0308010Cdigital envelope routinesunsupported
    at new Hash nodeinternalcryptohash6919
    at ObjectcreateHash nodecrypto13810
    at moduleexports workspacesNotesnodemoduleswebpacklibutilcreateHashjs13553
    at NormalModuleinitBuildHash workspacesNotesnodemoduleswebpacklibNormalModulejs41716
    at handleParseError workspacesNotesnodemoduleswebpacklibNormalModulejs47110
    at workspacesNotesnodemoduleswebpacklibNormalModulejs5035
    at workspacesNotesnodemoduleswebpacklibNormalModulejs35812
    at workspacesNotesnodemodulesloaderrunnerlibLoaderRunnerjs3733
    at iterateNormalLoaders workspacesNotesnodemodulesloaderrunnerlibLoaderRunnerjs21410
    at iterateNormalLoaders workspacesNotesnodemodulesloaderrunnerlibLoaderRunnerjs22110
workspacesNotesnodemodulesreactscriptsscriptsstartjs19
  throw err
  

Error error0308010Cdigital envelope routinesunsupported
    at new Hash nodeinternalcryptohash6919
    at ObjectcreateHash nodecrypto13810
    at moduleexports workspacesNotesnodemoduleswebpacklibutilcreateHashjs13553
    at NormalModuleinitBuildHash workspacesNotesnodemoduleswebpacklibNormalModulejs41716
    at workspacesNotesnodemoduleswebpacklibNormalModulejs45210
    at workspacesNotesnodemoduleswebpacklibNormalModulejs32313
    at workspacesNotesnodemodulesloaderrunnerlibLoaderRunnerjs36711
    at workspacesNotesnodemodulesloaderrunnerlibLoaderRunnerjs23318
    at contextcallback workspacesNotesnodemodulesloaderrunnerlibLoaderRunnerjs11113
    at workspacesNotesnodemodulesbabelloaderlibindexjs59103 
  opensslErrorStack  error03000086digital envelope routinesinitialization error 
  library digital envelope routines
  reason unsupported
  code ERROSSLEVPUNSUPPORTED


Nodejs v2030
error Command failed with exit code 1
info Visit httpsyarnpkgcomendocsclirun for documentation about this command
ilixindri  workspacesNotes main  node version
v2030","Starting development server ... Error : error:0308010C : digital envelope routines : :unsupported new Hash ( node : internal/crypto/hash:69:19 ) Object.createHash ( node : crypto:138:10 ) module.exports ( /workspaces/Notes/node_modules/webpack/lib/util/createHash.js:135:53 ) NormalModule._initBuildHash ( /workspaces/Notes/node_modules/webpack/lib/NormalModule.js:417:16 ) handleParseError ( /workspaces/Notes/node_modules/webpack/lib/NormalModule.js:471:10 ) /workspaces/Notes/node_modules/webpack/lib/NormalModule.js:503:5 /workspaces/Notes/node_modules/webpack/lib/NormalModule.js:358:12 /workspaces/Notes/node_modules/loader-runner/lib/LoaderRunner.js:373:3 iterateNormalLoaders ( /workspaces/Notes/node_modules/loader-runner/lib/LoaderRunner.js:214:10 ) iterateNormalLoaders ( /workspaces/Notes/node_modules/loader-runner/lib/LoaderRunner.js:221:10 ) /workspaces/Notes/node_modules/react-scripts/scripts/start.js:19 throw err ; ^ Error : error:0308010C : digital envelope routines : :unsupported new Hash ( node : internal/crypto/hash:69:19 ) Object.createHash ( node : crypto:138:10 ) module.exports ( /workspaces/Notes/node_modules/webpack/lib/util/createHash.js:135:53 ) NormalModule._initBuildHash ( /workspaces/Notes/node_modules/webpack/lib/NormalModule.js:417:16 ) /workspaces/Notes/node_modules/webpack/lib/NormalModule.js:452:10 /workspaces/Notes/node_modules/webpack/lib/NormalModule.js:323:13 /workspaces/Notes/node_modules/loader-runner/lib/LoaderRunner.js:367:11 /workspaces/Notes/node_modules/loader-runner/lib/LoaderRunner.js:233:18 context.callback ( /workspaces/Notes/node_modules/loader-runner/lib/LoaderRunner.js:111:13 ) /workspaces/Notes/node_modules/babel-loader/lib/index.js:59:103 { opensslErrorStack : [ 'error:03000086 : digital envelope routines : :initialization error ' ] , library : 'digital envelope routines ' , reason : 'unsupported ' , code : 'ERR_OSSL_EVP_UNSUPPORTED' } Node.js v20.3.0 error Command failed exit code 1. info Visit https : //yarnpkg.com/en/docs/cli/run documentation command . @ ilixindri ➜ /workspaces/Notes ( main ) $ node -- version v20.3.0"
mmabrouk,is there a way to publish new version of code in github using poetry each time we bump the version in th eporjecttoml file using github actions,way publish new version code github using poetry time bump version th eporject.toml file using github actions
dkirby-ms,"Dawork1sbuildscriptswindowsartifactscliLibsitepackagescryptographyhazmatbackendsopensslbackendpy27 UserWarning You are using cryptography on a 32bit Python on a 64bit Windows Operating System Cryptography will be significantly faster if you switch to using a 64bit Python

How can I fix this",: \a\_work\1\s\build_scripts\windows\artifacts\cli\Lib\site-packages\cryptography/hazmat/backends/openssl/backend.py:27 : UserWarning : using cryptography 32-bit Python 64-bit Windows Operating System . Cryptography significantly faster switch using 64-bit Python . fix ?
simonw,"Given the string datasettewrite

Python code that figures out if there is a Python package installed with that name and if so figures out how to load it as a plugin","Given string `` datasette-write '' Python code figures Python package installed name , , figures load plugin"
theoryshaw,Via code how do you update a Librecalc file without changing the formatting of the various cells,"Via code , update Librecalc file without changing formatting various cells ?"
osamaramihafez,What is the best way to set up files for a node project that contains routes and models,best way set files node project contains routes models
salgo60,Explain Advancing Research Communication  the role of Humanities in the Digital Era,Explain “ Advancing Research Communication – role Humanities Digital Era ”
ymerkos,"BH
Im trying to download this AI from hugging face and I cant find any explanationation online anywehere  I requested access to the GIT repo and now I donwloaded the files here

gitattributes
152 kB
Squashing commit
20 days ago
LICENSEtxt
702 kB
Squashing commit
20 days ago
READMEmd
104 kB
Update READMEmd
19 days ago
USEPOLICYmd
477 kB
Squashing commit
20 days ago
configjson
614 Bytes
Update configjson
7 days ago
generationconfigjson
167 Bytes
Update generationconfigjson
15 days ago
model00001of00002safetensors
998 GB
LFS
Squashing commit
20 days ago
model00002of00002safetensors
35 GB
LFS
Squashing commit
20 days ago
modelsafetensorsindexjson
268 kB
Squashing commit
20 days ago
pytorchmodel00001of00002bin
998 GB
LFS
Upload LlamaForCausalLM
19 days ago
pytorchmodel00002of00002bin
35 GB
LFS
Upload LlamaForCausalLM
19 days ago
pytorchmodelbinindexjson
268 kB
Upload LlamaForCausalLM
19 days ago
specialtokensmapjson
414 Bytes
Upload tokenizer
19 days ago
tokenizerjson
184 MB
Upload tokenizer
19 days ago
tokenizermodel
500 kB
LFS
Squashing commit
20 days ago
tokenizerconfigjson


I can show u their contents if u want the readme doesnt explain how to use it I jsut want to set it up to be able to chat locally can u explain me fully how to set up a huggingface ai Im using windows 10

Heres the docs avaialble


Llama 2
Llama 2 is a collection of pretrained and finetuned generative text models ranging in scale from 7 billion to 70 billion parameters This is the repository for the 7B finetuned model optimized for dialogue use cases and converted for the Hugging Face Transformers format Links to other models can be found in the index at the bottom

Model Details
Note Use of this model is governed by the Meta license In order to download the model weights and tokenizer please visit the website and accept our License before requesting access here

Meta developed and publicly released the Llama 2 family of large language models LLMs a collection of pretrained and finetuned generative text models ranging in scale from 7 billion to 70 billion parameters Our finetuned LLMs called Llama2Chat are optimized for dialogue use cases Llama2Chat models outperform opensource chat models on most benchmarks we tested and in our human evaluations for helpfulness and safety are on par with some popular closedsource models like ChatGPT and PaLM

Model Developers Meta

Variations Llama 2 comes in a range of parameter sizes  7B 13B and 70B  as well as pretrained and finetuned variations

Input Models input text only

Output Models generate text only

Model Architecture Llama 2 is an autoregressive language model that uses an optimized transformer architecture The tuned versions use supervised finetuning SFT and reinforcement learning with human feedback RLHF to align to human preferences for helpfulness and safety

Training Data	Params	Content Length	GQA	Tokens	LR
Llama 2	A new mix of publicly available online data	7B	4k		20T	30 x 104
Llama 2	A new mix of publicly available online data	13B	4k		20T	30 x 104
Llama 2	A new mix of publicly available online data	70B	4k		20T	15 x 104
Llama 2 family of models Token counts refer to pretraining data only All models are trained with a global batchsize of 4M tokens Bigger models  70B  use GroupedQuery Attention GQA for improved inference scalability

Model Dates Llama 2 was trained between January 2023 and July 2023

Status This is a static model trained on an offline dataset Future versions of the tuned models will be released as we improve model safety with community feedback

License A custom commercial license is available at httpsaimetacomresourcesmodelsandlibrariesllamadownloads

Research Paper Llama2 Open Foundation and Finetuned Chat Models

Intended Use
Intended Use Cases Llama 2 is intended for commercial and research use in English Tuned models are intended for assistantlike chat whereas pretrained models can be adapted for a variety of natural language generation tasks

To get the expected features and performance for the chat versions a specific formatting needs to be followed including the INST and SYS tags BOS and EOS tokens and the whitespaces and breaklines in between we recommend calling strip on inputs to avoid doublespaces See our reference code in github for details chatcompletion

Outofscope Uses Use in any manner that violates applicable laws or regulations including trade compliance lawsUse in languages other than English Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Llama 2

Hardware and Software
Training Factors We used custom training libraries Metas Research Super Cluster and production clusters for pretraining Finetuning annotation and evaluation were also performed on thirdparty cloud compute

Carbon Footprint Pretraining utilized a cumulative 33M GPU hours of computation on hardware of type A10080GB TDP of 350400W Estimated total emissions were 539 tCO2eq 100 of which were offset by Metas sustainability program

Time GPU hours	Power Consumption W	Carbon EmittedtCO2eq
Llama 2 7B	184320	400	3122
Llama 2 13B	368640	400	6244
Llama 2 70B	1720320	400	29142
Total	3311616		53900
CO2 emissions during pretraining Time total GPU time required for training each model Power Consumption peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency 100 of the emissions are directly offset by Metas sustainability program and because we are openly releasing these models the pretraining costs do not need to be incurred by others

Training Data
Overview Llama 2 was pretrained on 2 trillion tokens of data from publicly available sources The finetuning data includes publicly available instruction datasets as well as over one million new humanannotated examples Neither the pretraining nor the finetuning datasets include Meta user data

Data Freshness The pretraining data has a cutoff of September 2022 but some tuning data is more recent up to July 2023

Just relpy normally not sure how to navigate this","B '' H 'm trying download AI hugging face cant find explanationation online anywehere . requested access GIT repo donwloaded files .gitattributes 1.52 kB Squashing commit 20 days ago LICENSE.txt 7.02 kB Squashing commit 20 days ago README.md 10.4 kB Update README.md 19 days ago USE_POLICY.md 4.77 kB Squashing commit 20 days ago config.json 614 Bytes Update config.json 7 days ago generation_config.json 167 Bytes Update generation_config.json 15 days ago model-00001-of-00002.safetensors 9.98 GB LFS Squashing commit 20 days ago model-00002-of-00002.safetensors 3.5 GB LFS Squashing commit 20 days ago model.safetensors.index.json 26.8 kB Squashing commit 20 days ago pytorch_model-00001-of-00002.bin 9.98 GB LFS Upload LlamaForCausalLM 19 days ago pytorch_model-00002-of-00002.bin 3.5 GB LFS Upload LlamaForCausalLM 19 days ago pytorch_model.bin.index.json 26.8 kB Upload LlamaForCausalLM 19 days ago special_tokens_map.json 414 Bytes Upload tokenizer 19 days ago tokenizer.json 1.84 MB Upload tokenizer 19 days ago tokenizer.model 500 kB LFS Squashing commit 20 days ago tokenizer_config.json show u contents u want , readme doesnt explain use . jsut want set able chat locally . u explain fully set huggingface ai ? Im using windows 10 's docs avaialble : Llama 2 Llama 2 collection pretrained fine-tuned generative text models ranging scale 7 billion 70 billion parameters . repository 7B fine-tuned model , optimized dialogue use cases converted Hugging Face Transformers format . Links models found index bottom . Model Details Note : Use model governed Meta license . order download model weights tokenizer , please visit website accept License requesting access . Meta developed publicly released Llama 2 family large language models ( LLMs ) , collection pretrained fine-tuned generative text models ranging scale 7 billion 70 billion parameters . fine-tuned LLMs , called Llama-2-Chat , optimized dialogue use cases . Llama-2-Chat models outperform open-source chat models benchmarks tested , human evaluations helpfulness safety , par popular closed-source models like ChatGPT PaLM . Model Developers Meta Variations Llama 2 comes range parameter sizes — 7B , 13B , 70B — well pretrained fine-tuned variations . Input Models input text . Output Models generate text . Model Architecture Llama 2 auto-regressive language model uses optimized transformer architecture . tuned versions use supervised fine-tuning ( SFT ) reinforcement learning human feedback ( RLHF ) align human preferences helpfulness safety . Training Data Params Content Length GQA Tokens LR Llama 2 new mix publicly available online data 7B 4k ✗ 2.0T 3.0 x 10-4 Llama 2 new mix publicly available online data 13B 4k ✗ 2.0T 3.0 x 10-4 Llama 2 new mix publicly available online data 70B 4k ✔ 2.0T 1.5 x 10-4 Llama 2 family models . Token counts refer pretraining data . models trained global batch-size 4M tokens . Bigger models - 70B -- use Grouped-Query Attention ( GQA ) improved inference scalability . Model Dates Llama 2 trained January 2023 July 2023 . Status static model trained offline dataset . Future versions tuned models released improve model safety community feedback . License custom commercial license available : https : //ai.meta.com/resources/models-and-libraries/llama-downloads/ Research Paper `` Llama-2 : Open Foundation Fine-tuned Chat Models '' Intended Use Intended Use Cases Llama 2 intended commercial research use English . Tuned models intended assistant-like chat , whereas pretrained models adapted variety natural language generation tasks . get expected features performance chat versions , specific formatting needs followed , including INST < < SYS > > tags , BOS EOS tokens , whitespaces breaklines ( recommend calling strip ( ) inputs avoid double-spaces ) . See reference code github details : chat_completion . Out-of-scope Uses Use manner violates applicable laws regulations ( including trade compliance laws ) .Use languages English . Use way prohibited Acceptable Use Policy Licensing Agreement Llama 2 . Hardware Software Training Factors used custom training libraries , Meta 's Research Super Cluster , production clusters pretraining . Fine-tuning , annotation , evaluation also performed third-party cloud compute . Carbon Footprint Pretraining utilized cumulative 3.3M GPU hours computation hardware type A100-80GB ( TDP 350-400W ) . Estimated total emissions 539 tCO2eq , 100 % offset Meta ’ sustainability program . Time ( GPU hours ) Power Consumption ( W ) Carbon Emitted ( tCO2eq ) Llama 2 7B 184320 400 31.22 Llama 2 13B 368640 400 62.44 Llama 2 70B 1720320 400 291.42 Total 3311616 539.00 CO2 emissions pretraining . Time : total GPU time required training model . Power Consumption : peak power capacity per GPU device GPUs used adjusted power usage efficiency . 100 % emissions directly offset Meta 's sustainability program , openly releasing models , pretraining costs need incurred others . Training Data Overview Llama 2 pretrained 2 trillion tokens data publicly available sources . fine-tuning data includes publicly available instruction datasets , well one million new human-annotated examples . Neither pretraining fine-tuning datasets include Meta user data . Data Freshness pretraining data cutoff September 2022 , tuning data recent , July 2023 . relpy normally . sure navigate"
brucestull,I want to add a model to my ApplicationTracker Django app The model will be used to store my organizational concepts for my applications repositories code standards etc Can you help me come up with a model and field name,"want add model ` ApplicationTracker ` Django app . model used store organizational concepts applications , repositories , code standards , etc . help come model field name ?"
alien142,How to make an iOS framework M1 compatible,make iOS framework M1 compatible ?
MaartenHilferink,how can I use a OGRCoordinateTransformation object from multiple threads ,use OGRCoordinateTransformation object multiple threads ?
kushaljain10,Hi can I share our chat history with someone using a public link,"Hi , share chat history someone using public link ?"
TriangleYJ,Unknown,Unknown
joelouthan,With HTML and CSS is it possible to make a collapsable ul list,"HTML CSS , possible make collapsable ul list ?"
joelouthan,On Netlify and rust mdbook is there is a way to keep the cargo install mdbooktoc and not have to install it every single time I deploy,"Netlify rust mdbook , way keep cargo install mdbook-toc install every single time deploy ?"
markkerzner,Unknown,Unknown
simonw,"Given this

    topp  
       type number 
       title Top P 
       default 1 
       maximum 1 
       minimum 001 
       xorder 3 
       description When decoding text samples from the top p percentage of most likely tokens lower to ignore less likely tokens 
     

Write Python code that can generate a Pydantic model for this dynamically constructing the class at runtime","Given : { `` top_p '' : { `` type '' : `` number '' , `` title '' : `` Top P '' , `` default '' : 1 , `` maximum '' : 1 , `` minimum '' : 0.01 , `` x-order '' : 3 , `` description '' : `` decoding text , samples top p percentage likely tokens ; lower ignore less likely tokens '' } } Write Python code generate Pydantic model , dynamically constructing class runtime"
simonhamp,is there a way to run git add p without interactivity,way run ` git add -p ` without interactivity ?
sssergy,Unknown,Unknown
FreePhoenix888,"This code is executed on mount of MonacoEditor
ts
    monacolanguagestypescripttypescriptDefaultssetCompilerOptions
      target monacolanguagestypescriptScriptTargetESNext
      allowNonTsExtensions true
      moduleResolution monacolanguagestypescriptModuleResolutionKindNodeJs
      module monacolanguagestypescriptModuleKindESNext
      noEmit true
      typeRoots nodemodulestypes
    

In monacoeditor I still see no types when importing axios
ts

async data newLink  
  const axios  await importaxios
  axios
  



But axios is installed","code executed mount MonacoEditor : `` ` ts monaco.languages.typescript.typescriptDefaults.setCompilerOptions ( { target : monaco.languages.typescript.ScriptTarget.ESNext , allowNonTsExtensions : true , moduleResolution : monaco.languages.typescript.ModuleResolutionKind.NodeJs , module : monaco.languages.typescript.ModuleKind.ESNext , noEmit : true , typeRoots : [ `` node_modules/ @ types '' ] } ) `` ` monacoeditor still see types importing axios : `` ` ts async ( { data : { newLink } } ) = > { const axios = await import ( 'axios ' ) axios. } `` ` axios installed"
tncks0121,"You are to implement a NodeHandle in Rust below

A node has a i32 value and directed edges to other nodes A node does not have multiple edges to the same node Nodes are not associated with a particular domain and users can freely create nodes however they like 



deriveDebug Clone
pub struct NodeHandle 
   ACTION fill whatever you want to do


impl NodeHandle 
     Creates a node and returns the handle to it
    pub fn newvalue i32  Self 
        todo
    

     Adds an edge to to
     If the modification cannot be done eg because of aliasing issues returns ErrGraphError
     Returns Oktrue if the edge is successfully added
     Returns Okfalse if an edge to to already exits
    pub fn addedgeself to NodeHandle  Resultbool GraphError 
        todo
    
","implement ` NodeHandle ` Rust node i32 value ( directed ) edges nodes . node multiple edges node . Nodes associated particular domain , users freely create nodes however like . === # [ derive ( Debug , Clone ) ] pub struct NodeHandle { // ACTION : fill whatever want } impl NodeHandle { /// Creates node returns handle . pub fn new ( value : i32 ) - > Self { todo ! ( ) } /// Adds edge ` ` . /// modification done , e.g . aliasing issues , returns ` Err ( GraphError ) ` . /// Returns ` Ok ( true ) ` edge successfully added . /// Returns ` Ok ( false ) ` edge ` ` already exits . pub fn add_edge ( & self , : NodeHandle ) - > Result < bool , GraphError > { todo ! ( ) } }"
simonw,"Write a Python function

lines  id1 content 1 id2 content2

def tooutputlines formatcsv
  yield idcontent
  for id content in lines
    csvline  
    yield csvline

But it needs to support format of CSV or TSV and should use the Python CSV standard library to generate propelry scaled content ","Write Python function : lines = [ ( `` id1 '' , `` content 1 '' ) , ( `` id2 '' , `` content2 '' ) ] def to_output ( lines , format= '' csv '' ) : yield `` id , content '' id , content lines : csv_line = `` ... '' yield csv_line needs support format CSV TSV use Python CSV standard library generate propelry scaled content"
decentropy,"Using this html


DOCTYPE html
html
head 
  script srchttpsunpkgcomnostrtoolslibnostrbundlejsscript
head
body
  script

    var NOSTR

     Everything loaded
    documentaddEventListenerDOMContentLoaded function 

      NOSTR  windowNostrTools

      let sk1  NOSTRgeneratePrivateKey
      let pk1  NOSTRgetPublicKeysk1
      consolelogsk1 pk1

      let sk2  NOSTRgeneratePrivateKey
      let pk2  NOSTRgetPublicKeysk2
      consolelogsk2 pk2

      let message  hello world

      NOSTRnip04encryptsk1 pk2 messagethenresult  
        consolelogresult
      

    
        
  script
body
html


Error in Chrome

nostrbundlejs7359 Uncaught in promise TypeError Cannot read properties of undefined reading importKey
    at Objectencrypt nostrbundlejs735941

Error in Firefox

Uncaught in promise TypeError cryptosubtle is undefined
    encrypt httpsunpkgcomnostrtoolslibnostrbundlejs7359
","Using html `` ` < ! DOCTYPE html > < html > < head > < script src= '' https : //unpkg.com/nostr-tools/lib/nostr.bundle.js '' > < /script > < /head > < body > < script > var NOSTR ; // Everything loaded ... document.addEventListener ( 'DOMContentLoaded ' , function ( ) { NOSTR = window.NostrTools let sk1 = NOSTR.generatePrivateKey ( ) let pk1 = NOSTR.getPublicKey ( sk1 ) console.log ( sk1 , pk1 ) let sk2 = NOSTR.generatePrivateKey ( ) let pk2 = NOSTR.getPublicKey ( sk2 ) console.log ( sk2 , pk2 ) let message = `` hello world '' NOSTR.nip04.encrypt ( sk1 , pk2 , message ) .then ( ( result ) = > { console.log ( result ) } ) } ) ; < /script > < /body > < /html > `` ` Error Chrome : nostr.bundle.js:7359 Uncaught ( promise ) TypeError : read properties undefined ( reading 'importKey ' ) Object.encrypt ( nostr.bundle.js:7359:41 ) Error Firefox : Uncaught ( promise ) TypeError : crypto.subtle undefined encrypt https : //unpkg.com/nostr-tools/lib/nostr.bundle.js:7359"
simonw,"def cosinesimilaritya b
    dotproduct  sumx  y for x y in zipa b
    magnitudea  sumx  x for x in a  05
    magnitudeb  sumx  x for x in b  05
    return dotproduct  magnitudea  magnitudeb

Create an array with 100 vectors in each with 300 random floating point numbers  a list of Python lists

Then write a function which picks the first of those vectors and calculates the score for the other 99  benchmark that function

Then try out different improved versions of that function which use numpy and maybe other libraries you have available to you  confirm that they result in the same overall sort order as the original and benchmark each one

Plot the results

","def cosine_similarity ( , b ) : dot_product = sum ( x * x , zip ( , b ) ) magnitude_a = sum ( x * x x ) * * 0.5 magnitude_b = sum ( x * x x b ) * * 0.5 return dot_product / ( magnitude_a * magnitude_b ) Create array 100 vectors 300 random floating point numbers - list Python lists write function picks first vectors calculates score 99 - benchmark function try different improved versions function use numpy maybe libraries available - confirm result overall sort order original benchmark one Plot results"
neilenns,write me code to add an axios interceptor to all requests that inserts an authentication header with a Bearer token stored in my UserContext custom context in React Im using typescript and es2020,write code add axios interceptor requests inserts authentication header Bearer token stored UserContext custom context React . 'm using typescript es2020 .
Zhang-Yexun,AskYourPDF,给我介绍下AskYourPDF插件的功能
tkdwns414,"     level  
         level         1  2  3  4  5           

 Profile level      Profile   level      level              level   api       ",내가 지금 구상하고 있는 서비스에는 level이라는 기능이 있어 . 한 달 동안 작성한 게시글을 작성한 일 수에 따라 level이 정해지는데 예를 들어 한달에 글을 쓴 날이 없으면 1레벨 하루면 2레벨 이틀이면 3레벨 사흘이면 4레벨 나흘이면 5레벨 이런식으로 하고 싶어 . 하루에 글을 여러개 써도 하루로 인정되게 할거야 . 이때 Profile에 level이라는 필드를 따로 파는게 좋을까 ? 아니면 Profile을 불러올 때마다 level이 계산되게 하는게 좋을까 ? 다른 유저의 level도 볼 수 있고 게시글 리스트를 불러올 때 게시글 작성자의 프로필도 함께 반환해줄거라 매번 level 계산을 하면 api 속도가 느려질까봐 걱정돼 . 혹시 좋은 방법 없을까 ?
tomcl,how can I send emails from a spreadsheet and collect replies in the spreadsheet with followup emails based on replies using power automate,"send e-mails spreadsheet collect replies spreadsheet , followup e-mails based replies , using power automate"
msrajawat298,how to get vscode publisher token ,get vscode publisher token ?
cyshello,Hello I tried to clone a repository in github without forking it in workspace using Coder website Thus I created an workspace and opened terminal and wrote git clone origin upstream gitgithubcomgithub urlgit However I could find a error fatal  could not read from remote repository How can I fix it I am new to Git and Coder so please explain it ,"Hello , tried clone repository github without forking workspace using `` Coder '' website . Thus , created workspace opened terminal , wrote git clone -- origin upstream git @ github.com : ( github url ) .git . However , could find error , `` fatal : could read remote repository '' . fix ? new Git Coder , please explain ."
abrichr,Please provide an exhaustive list of desktop user interface components,Please provide exhaustive list desktop user interface components .
jabrena,In spring value annotation is able to read a la environment variables String key  SystemgetenvgetOPENAIAPIKEY,spring value annotation able read la environment variables ? String key = System.getenv ( ) .get ( `` OPENAI_API_KEY '' ) ;
purpleslurple,What does this mean Cardinality 475e38,mean : Cardinality 4.75e+38
naoharu,go gin  find one ,go gin コンテキストの find one について教えてください
jabrena,Un java if I have a text block with 3 variables inside how to replace the values,"Un java text block 3 variables inside , replace values ?"
dantebarba,"I have the following bash code

 Wrap up healthchecksio call with complete or failure signal
  if  z CHECKURL 
  then
    echo INFO Define CHECKURL with httpshealthchecksio to monitor RCLONECMD job
  else
    if  RETURNCODE  0 
    then
      if   z OUTPUTLOG     z HCLOG    f LOGFILE 
      then
        echo INFO Sending complete signal with logs to healthchecksio
        mtail c 10000 LOGFILE
	wget CHECKURL O devnull postdatam
      else
	echo INFO Sending complete signal to healthchecksio
        wget CHECKURL O devnull postdataSUCCESS
      fi
    else
      if   z OUTPUTLOG     z HCLOG    f LOGFILE 
      then
        echo INFO Sending failure signal with logs to healthchecksio
        mtail c 10000 LOGFILE
        wget FAILURL O devnull postdatam
      else
	echo INFO Sending failure signal to healthchecksio
        wget FAILURL O devnull postdataCheck container logs
      fi
    fi
  fi

Id like to add a list of return codes that are succesful aside from 0
Also id like to compare the return coode to this list of codes and if the return code is contained in the list mark the response as success
","following bash code # Wrap healthchecks.io call complete failure signal [ -z `` $ CHECK_URL '' ] echo `` INFO : Define CHECK_URL https : //healthchecks.io monitor $ RCLONE_CMD job '' else [ `` $ RETURN_CODE '' == 0 ] [ ! -z `` $ OUTPUT_LOG '' ] & & [ ! -z `` $ HC_LOG '' ] & & [ -f `` $ LOG_FILE '' ] echo `` INFO : Sending complete signal logs healthchecks.io '' m= $ ( tail -c 10000 `` $ LOG_FILE '' ) wget $ CHECK_URL -O /dev/null -- post-data= '' $ '' else echo `` INFO : Sending complete signal healthchecks.io '' wget $ CHECK_URL -O /dev/null -- post-data= '' SUCCESS '' fi else [ ! -z `` $ OUTPUT_LOG '' ] & & [ ! -z `` $ HC_LOG '' ] & & [ -f `` $ LOG_FILE '' ] echo `` INFO : Sending failure signal logs healthchecks.io '' m= $ ( tail -c 10000 `` $ LOG_FILE '' ) wget $ FAIL_URL -O /dev/null -- post-data= '' $ '' else echo `` INFO : Sending failure signal healthchecks.io '' wget $ FAIL_URL -O /dev/null -- post-data= '' Check container logs '' fi fi fi 'd like add list return codes succesful aside 0 Also id like compare return coode list codes return code contained list , mark response success"
hlapp,Enumerate each sub panel caption contained in the following multipanel figure caption Fig 3 Morphological characters AD Head in dorsal view A Gerbelius nr confluens B Voconia decorata sp nov C Voconia pallidipes Stl 1866 D Voconia schoutedeni Villiers 1964 comb nov EG Head in lateral view E Voconia wegneri Miller 1954 comb nov F Voconia dolichocephala sp nov G Gerbelius typicus Distant 1903 H Voconia loki sp nov head and pronotum in dorsal view IJ Prosternum in ventrolateral view I Voconia mexicana sp nov J Voconia bracata sp nov KL Pronotum in dorsal view K Voconia conradti Jeannel 1917 comb nov L Voconia tuberculata sp nov,"Enumerate sub panel caption contained following multi-panel figure caption : `` Fig . 3 . Morphological characters . A–D . Head dorsal view . A. Gerbelius nr . confluens . B. Voconia decorata sp . nov. C. Voconia pallidipes Stål , 1866 . D. Voconia schoutedeni ( Villiers , 1964 ) comb . nov. E–G . Head lateral view . E. Voconia wegneri ( Miller , 1954 ) comb . nov. F. Voconia dolichocephala sp . nov. G. Gerbelius typicus Distant , 1903 . H. Voconia loki sp . nov. , head pronotum dorsal view . I–J . Prosternum ventrolateral view . I. Voconia mexicana sp . nov. J. Voconia bracata sp . nov. K–L . Pronotum dorsal view . K. Voconia conradti ( Jeannel , 1917 ) comb . nov. L. Voconia tuberculata sp . nov . ''"
danielsgriffin,"How do I do a doctest that requires sending an escaped quotation mark in the parameters
Like this
parameter custom instructions in Siri
Tired
 slugifycustom instructions in Siri args
But I get a syntax error

File scriptsutilitiespy line 55 in utilitiesslugify
Failed example
    slugifycustom instructions in Siri args
Exception raised
    Traceback most recent call last
      File LibraryFrameworksPythonframeworkVersions38libpython38doctestpy line 1329 in run
        execcompileexamplesource filename single
      File doctest utilitiesslugify8 line 1
        slugifycustom instructions in Siri args
                   
    SyntaxError invalid syntax


Here is the full function

def slugifyline args
    rTakes a URL path or stringwithspaces and returns a slugified version of it
    
     class Args
         verbose  False
    
     args  Args
     slugifytil20230713terminalcommandtoopenfileinvscodehtml args
    til20230713terminalcommandtoopenfileinvscodehtml
     slugifyWhats the best way to slugify args
    whatsthebestwaytoslugify
     slugifyAnother example Yes its here args
    anotherexampleyesitshere
     slugifyGoogles core updates as chaos args
    googlescoreupdatesaschaos
     slugifydic and sometimes quotless is morequot args
    dicandsometimeslessismore
     slugifyMicrosoft CFP quotAccelerate Foundation Models Researchquot args
    microsoftcfpacceleratefoundationmodelsresearch
     slugifycustom instructions in Siri args
    custominstructionsinsiri
    
    if argsverbose
        printfSlugifying line
    if   in line
        return linereplace  replace replace replace replace replace replacequotreplacereplacereplacereplacelowerstrip
    return linestripreplace replace replace replace replaces 
","doctest requires sending escaped quotation mark parameters ? Like : parameter : ' '' custom instructions '' Siri' Tired : > > > slugify ( `` '\ '' custom instructions\ '' Siri ' '' , args ) get syntax error : `` ` File `` scripts/utilities.py '' , line 55 , utilities.slugify Failed example : slugify ( `` ' '' custom instructions '' Siri ' '' , args ) Exception raised : Traceback ( recent call last ) : File `` /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/doctest.py '' , line 1329 , __run exec ( compile ( example.source , filename , `` single '' , File `` < doctest utilities.slugify [ 8 ] > '' , line 1 slugify ( `` ' '' custom instructions '' Siri ' '' , args ) ^ SyntaxError : invalid syntax `` ` full function : `` ` def slugify ( line , args ) : r '' '' '' Takes URL path string-with-spaces returns slugified version . > > > class Args : ... verbose = False ... > > > args = Args ( ) > > > slugify ( `` /til/2023/07/13/terminal-command-to-open-file-in-vscode.html '' , args ) 'til-2023-07-13-terminal-command-to-open-file-in-vscode-html' > > > slugify ( `` 's best way slugify ? `` , args ) 'what-s-the-best-way-to-slugify' > > > slugify ( `` Another example ? Yes , 's . `` , args ) 'another-example-yes-it-s-here' > > > slugify ( `` Google 's core updates chaos ? `` , args ) 'google-s-core-updates-as-chaos' > > > slugify ( `` [ dic ] sometimes & quot ; less & quot ; '' , args ) 'dic-and-sometimes-less-is-more' > > > slugify ( ' '' Microsoft CFP : & quot ; Accelerate Foundation Models Research & quot ; '' ' , args ) 'microsoft-cfp-accelerate-foundation-models-research' > > > slugify ( `` '\ '' custom instructions\ '' Siri ' '' , args ) 'custom-instructions-in-siri' `` '' '' args.verbose : print ( f '' Slugifying : { line } '' ) `` `` line : return line.replace ( `` `` , `` - '' ) .replace ( `` ' '' , `` - '' ) .replace ( `` , '' , `` '' ) .replace ( `` . `` , `` '' ) .replace ( `` ? `` , `` '' ) .replace ( `` ' '' , `` - '' ) .replace ( `` & quot ; '' , '' '' ) .replace ( `` [ `` , '' '' ) .replace ( `` ] '' , '' '' ) .replace ( ' '' ' , '' ) .replace ( `` : '' , '' '' ) .lower ( ) .strip ( `` - '' ) return line.strip ( `` / '' ) .replace ( '/ ' , '- ' ) .replace ( ' . ' , '- ' ) .replace ( ' _ ' , '- ' ) .replace ( `` ? `` , `` '' ) .replace ( `` 's '' , `` - '' ) `` `"
dhgkunkel,Du bist jetzt ein Datentechnischer Spezialist fr die Verarbeitung von Geografischen Koordinaten Verstanden,Du bist jetzt ein Datentechnischer Spezialist für die Verarbeitung von Geografischen Koordinaten . Verstanden ?
shmuelsash,I want to add coding to my anki addon that allows me to set a class for images that are sensitive and it will cause them to become blurred automatically and only unblur if the image is tapped,want add coding anki addon allows set class images sensitive cause become blurred automatically unblur image tapped
fejofj,"I have this swift function and im getting this error please provide solution

	override internal func processTransferSetupFrame frameSharingNearbyFrame throws
		if framehasV1  framev1hasType case cancel  framev1type 
			printTransfer canceled
			try sendDisconnectionAndDisconnect
			return
		
		switch currentState
		case sentConnectionResponse
			try processPairedKeyEncryptionFrameframe
		case sentPairedKeyResult
			try processPairedKeyResultFrameframe
		case receivedPairedKeyResult
			try processIntroductionFrameframe
		default
			printUnexpected connection state in processTransferSetupFrame currentState
			printframe
		
	


error and extra logging

Unexpected connection state in processTransferSetupFrame receivingFiles
NearDropSharingNearbyFrame
version V1
v1 
  1 7
  7 
    1 0x00000000
    2 1
  

NearDropSecuremessageSecureMessage
headerandbody n034b001020002020343204003364261232336252354235306321i0343132004br020001022p251235324247V246237032w337024J264365247274r253007241273P8324260270272vs226OM322a2677215j213024243341307fH6235021270243264f211b364257R265316304017033220st334371373G1375316251374314031334236275335240223311302dw352270232t0h334360216006260
signature 205354305240wrf007R276207UUU330364335300377n031363216001210366237

decryptAndProcessReceivedSecureMessage
59 bytes
NearDropSecuremessageSecureMessage
headerandbody n034b001020002020Ww024324225223e332220203001332M2004br0200010220221305Cn261307367301214Y1374g035363357303004263274367245241t030005357XoN034311373r024n2612410013573062b
signature f2210r271232365215307002241336d3332122567217222E9231257h264246304c261

decryptAndProcessReceivedSecureMessage
Deserialization error malformedProtobuf
Connection closed
","swift function 'm getting error . please provide solution `` ` override internal func processTransferSetupFrame ( _ frame : Sharing_Nearby_Frame ) throws { frame.hasV1 & & frame.v1.hasType , case .cancel = frame.v1.type { print ( `` Transfer canceled '' ) try sendDisconnectionAndDisconnect ( ) return } switch currentState { case .sentConnectionResponse : try processPairedKeyEncryptionFrame ( frame ) case .sentPairedKeyResult : try processPairedKeyResultFrame ( frame ) case .receivedPairedKeyResult : try processIntroductionFrame ( frame ) default : print ( `` Unexpected connection state processTransferSetupFrame : \ ( currentState ) '' ) print ( frame ) } } `` ` error extra logging : `` ` Unexpected connection state processTransferSetupFrame : receivingFiles NearDrop.Sharing_Nearby_Frame : version : V1 v1 { 1 : 7 7 { 1 : 0x00000000 2 : 1 } } NearDrop.Securemessage_SecureMessage : header_and_body : `` \n\034\b\001\020\002 * \020\343\204\003\364\261\232\336\252\354\235 { \306\321i\034\3132\004\b\r\020\001\022p\251\235\324|\247V\246\237\032w\337\024J\264\\\365\247\274\r\253\007\241\273P8~\324\260\270\272vs\226OM\322a\2677\215j\213\024\243\341\307 { fH ) 6\235\021\270\243\264\f\211\b ; \364\257R\265\316\304 $ \017\033\220s\t/\334\371\373G ? 1 ! \375\316 * \251\374\314\031\334\236\275\335\240\223\311\302dw\352\270\ '' \232t.0h\334\360\216\006\ '' \260| '' signature : `` \205\354\305\240w\r\f\\'\007R\276\207UUU\330\364\335\300\377\n [ \031\363 % \216\001\210\366\237 } '' decryptAndProcessReceivedSecureMessage 59 bytes NearDrop.Securemessage_SecureMessage : header_and_body : `` \n\034\b\001\020\002 * \020Ww\024 ] \324\225\223e < +\332\220\203\001\332M2\004\b\r\020\001\0220\221\305C\n\261\307\367\301\214^ @ Y1\374g } \035\363\357\303\004\263\274\367\245\241\t\030\005\357XoN~\034\311\373r\024\n\261\241\001\357 $ \3062b '' signature : `` \f\2210\r\271 [ \232\365\215\307 ` \002\241\336-d\333\212\2567\217\222E9\231\257h\264\246\304c\261 '' decryptAndProcessReceivedSecureMessage Deserialization error : malformedProtobuf Connection closed `` `"
Yukizyh,Write me a function that takes as input an opencv coordinate quaternion wxyz and a translation vector and outputs me a transformation matrix 4x4 in opengl coordinate frame using PyRR and do not forget to rotate the input by 180 degrees on the xaxis Can you append the translation matrix instead of multiplication ,Write function takes input opencv coordinate quaternion ( wxyz ) translation vector outputs transformation matrix ( 4x4 ) opengl coordinate frame using PyRR forget rotate input 180 degrees x-axis . append translation matrix instead multiplication .
maro114510,markedmermaid,markedによってパースしたマークダウンをmermaid記法に対応させるには
jhqv,Unknown,Unknown
HubertWagnerVE," const arr1   key1 value1 key2 value2 
 const arr2   key1 newValue1 key3 newValue3 
 
 const totalArr  arr1 arr2 
 addToLogtotalArr JSONstringifytotalArr
 
 Result
 totalArr key1newValue1key2value2key3newValue3

Convert to R","# const arr1 = { 'key1 ' : 'value1 ' , 'key2 ' : 'value2 ' } # const arr2 = { 'key1 ' : 'newValue1 ' , 'key3 ' : 'newValue3 ' } # # const totalArr = { ... arr1 , ... arr2 } # addToLog ( totalArr : $ { JSON.stringify ( totalArr ) } ) # # Result : # totalArr : { `` key1 '' : '' newValue1 '' , '' key2 '' : '' value2 '' , '' key3 '' : '' newValue3 '' } Convert R"
ArdenHide,"Hi I have this class for generate user token in my ACL system
using SystemText
using AclNetCoreSecrets
using SystemSecurityCryptography

namespace AclNetCoreCryptography

public class UserTokenManager

    private readonly ISecretsProvider secretsProvider

    public UserTokenManagerISecretsProvider secretsProvider
    
        thissecretsProvider  secretsProvider
    

    public virtual string GenerateTokenTKeyTKey userId
    
        var key  secretsProviderSecret
        var keyBytes  EncodingUTF8GetByteskey
        if keyBytesLength  32
        
            throw new ArgumentExceptionSecret key from ISecretsProvider must be exactly 32 bytes 256 bits for AES256
        

        var iv  GenerateRandomBytes16
        var uniqueData  userIdGuidNewGuidDateTimeUtcNowTicks
        return EncryptStringuniqueData keyBytes iv
    

    private static string EncryptStringstring plainText byte key byte iv
    
        using var aes  AesCreate
        aesKey  key
        aesIV  iv
        var encrypt  aesCreateEncryptoraesKey aesIV
        using var msEncrypt  new MemoryStream
        using var csEncrypt  new CryptoStreammsEncrypt encrypt CryptoStreamModeWrite
        using var swEncrypt  new StreamWritercsEncrypt
        
            swEncryptWriteplainText
        
        var encrypted  msEncryptToArray

        return ConvertToBase64Stringencrypted
    

    private static byte GenerateRandomBytesint length
    
        var randomBytes  new bytelength
        using var rng  RandomNumberGeneratorCreate
        rngGetBytesrandomBytes
        return randomBytes
    


I have a question what have better security my class or use SHA256","Hi ! class generate user token ACL system using System.Text ; using Acl.Net.Core.Secrets ; using System.Security.Cryptography ; namespace Acl.Net.Core.Cryptography ; public class UserTokenManager { private readonly ISecretsProvider secretsProvider ; public UserTokenManager ( ISecretsProvider secretsProvider ) { this.secretsProvider = secretsProvider ; } public virtual string GenerateToken < TKey > ( TKey userId ) { var key = secretsProvider.Secret ; var keyBytes = Encoding.UTF8.GetBytes ( key ) ; ( keyBytes.Length ! = 32 ) { throw new ArgumentException ( `` Secret key ISecretsProvider must exactly 32 bytes ( 256 bits ) AES-256 . `` ) ; } var iv = GenerateRandomBytes ( 16 ) ; var uniqueData = $ '' { userId } - { Guid.NewGuid ( ) } - { DateTime.UtcNow.Ticks } '' ; return EncryptString ( uniqueData , keyBytes , iv ) ; } private static string EncryptString ( string plainText , byte [ ] key , byte [ ] iv ) { using var aes = Aes.Create ( ) ; aes.Key = key ; aes.IV = iv ; var encrypt = aes.CreateEncryptor ( aes.Key , aes.IV ) ; using var msEncrypt = new MemoryStream ( ) ; using var csEncrypt = new CryptoStream ( msEncrypt , encrypt , CryptoStreamMode.Write ) ; using ( var swEncrypt = new StreamWriter ( csEncrypt ) ) { swEncrypt.Write ( plainText ) ; } var encrypted = msEncrypt.ToArray ( ) ; return Convert.ToBase64String ( encrypted ) ; } private static byte [ ] GenerateRandomBytes ( int length ) { var randomBytes = new byte [ length ] ; using var rng = RandomNumberGenerator.Create ( ) ; rng.GetBytes ( randomBytes ) ; return randomBytes ; } } question better security , class use SHA-256 ?"
abernier,"in a taht github workflow

name release
on
  push
    branches
       main

 Cancel any previous run see httpsdocsgithubcomenactionsusingworkflowsworkflowsyntaxforgithubactionsconcurrency
concurrency
  group  githubworkflow  githubref 
  cancelinprogress true

jobs
  releasejob
    runson macos13
    steps
       uses actionscheckoutv3
       name Install brew packages  httpsdocsgithubcomenactionsusinggithubhostedrunnerscustomizinggithubhostedrunners
        run 
          brew update
          brew install imagemagick
       uses actionssetupnodev3
        with
          cache yarn
       id main
        run 
          yarn install
          yarn build
          yarn release
        env
          NPMTOKEN  secretsNPMTOKEN 
          GITHUBTOKEN  secretsGITHUBTOKEN 

Id like adding a conditional job to build and push a docker image to the Github Container registry prior to releasejob which is triggered only if changes are detected into the Dockerfile","taht github workflow : name : release : push : branches : - 'main' # Cancel previous run ( see : https : //docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions # concurrency ) concurrency : group : $ { { github.workflow } } - $ { { github.ref } } cancel-in-progress : true jobs : release-job : runs-on : macos-13 steps : - uses : actions/checkout @ v3 - name : Install brew packages # https : //docs.github.com/en/actions/using-github-hosted-runners/customizing-github-hosted-runners run : | brew update brew install imagemagick - uses : actions/setup-node @ v3 : cache : 'yarn' - id : main run : | yarn install yarn build yarn release env : NPM_TOKEN : $ { { secrets.NPM_TOKEN } } GITHUB_TOKEN : $ { { secrets.GITHUB_TOKEN } } 'd like adding conditional job build push docker image Github Container registry , prior release-job , triggered changes detected Dockerfile"
Konard,"Navigate to httpsgithubcomdeepfoundationdeeplinksissues47

Do you have any ideas or suggestions how to attack this issue",Navigate https : //github.com/deep-foundation/deeplinks/issues/47 ideas suggestions attack issue ?
ivansglazunov,Navigate to httpsgithubcomdeepfoundationdeeplinksissues41 and make a list of questions that should be answered to complete this task as a pull request,Navigate https : //github.com/deep-foundation/deeplinks/issues/41 make list questions answered complete task pull request .
Konard,Navigate to comment with question httpsgithubcomdeepfoundationdeeplinksissues15issuecomment1193140806 and generate SQL code to test the hypothesis use table described in issue summary Only typeid for insertion of link should be required Make insert SQL statement and make insertlinks mutation in GQL schema generated by Hasura,"Navigate comment question https : //github.com/deep-foundation/deeplinks/issues/15 # issuecomment-1193140806 generate SQL code test hypothesis , use table described issue summary . type_id insertion link required . Make insert SQL statement , make insert_links mutation GQL ( schema generated Hasura ) ."
jackcore21,"How to run a node js command line application on Windows it is a github repository from httpsgithubcomCerlancismchatgptsubtitletranslator with entry file clitranslatormjs

Assume I am beginner and have no git and node installed

Here is the setup instruction given in README
Nodejs version  16130 required This README assumes bash shell environment
 Clone this repository and navigate into the directory

 git clone httpsgithubcomCerlancismchatgptsubtitletranslator  cd chatgptsubtitletranslator

 Install the requirements

 npm install

 Give executable permission

 chmod x clitranslatormjs

 Copy exampleenv to env

 cp envexample env

 Add your API key to the newly created env file 

Here is one example to run it in the documentation

clitranslatormjs stream temperature 0 file testdatatestjasmallsrt","run node js command line application Windows , github repository https : //github.com/Cerlancism/chatgpt-subtitle-translator entry file cli/translator.mjs Assume beginner git node installed . setup instruction given README : Node.js version > = 16.13.0 required . README assumes bash shell environment - Clone repository navigate directory - git clone https : //github.com/Cerlancism/chatgpt-subtitle-translator & & cd chatgpt-subtitle-translator - Install requirements - npm install - Give executable permission - chmod +x cli/translator.mjs - Copy .example.env .env - cp .env.example .env - Add API key newly created .env file one example run documentation : cli/translator.mjs -- stream -- temperature 0 -- file test/data/test_ja_small.srt"
andrew-delph,in flutter how can you implement a scrollable list that loads new data from an api,flutter . implement scrollable list loads new data api ?
esocha13,I am going to give you a long list of products that are sold on Amazon We will call this list Full List,going give long list products sold Amazon . call list Full List .
cezar1,could you modify the bitcoin proof of work to include some lookup logic within the blockchain itself  this would make mining require computers with a lot of physical storage or high ram,could modify bitcoin proof work include lookup logic within blockchain - would make mining require computers lot physical storage high ram
woojinsung-jimmy,udp    server client 16 aa 03 da 00 01  server da03aa   ,udp 프로토콜을 사용하고 내가 server야 . client가 16진수로 aa 03 da 00 01을 보내주는데 server는 da03aa로 받고있어 . 뭐가 문제일까
lakruzz,Unknown,Unknown
DigitalGoldfish,"Im building an authentication workflow that involves sending an email with a magic link to verify the users email I want to avoid doing anything in the database regarding the magic link So I encrypt a payload includes the email its intended for and it doesnt include an expiration currently but it certainly could and include that encrypted token in the email as a query parameter on the magic link However I just realized that I was hardcoding the salt which reduces the level of security and opens me up to brute force attacks

Id still like to avoid touching the database for this so I dont want to have to generate the salt and put it in the database I considered putting the generated salt in the magic link query string as well I realize this reduces the security a bit but Im wondering whether in a practical scenario if its really that big of an issue and if I can address any holes that opens me up to

Id love to hear your thoughts on this Feel free to make a completely different suggestion I may not have considered or tell me that I really should just write something to the database for this process

I have also considered putting the salt in the users session

Im also adding a feature that allows the user to enter 5 random numbers into the app instead of clicking a link Those numbers will be encrypted using the same method and that encrypted value will be stored in a cookie

Hopefully thats enough context for you to make a recommendation on what I should do about the salt","'m building authentication workflow involves sending email magic link verify user 's email . want avoid anything database regarding magic link . encrypt payload ( includes email 's intended n't include expiration currently , certainly could ) include encrypted token email query parameter magic link . However , realized hard-coding salt reduces level security opens brute force attacks . 'd still like avoid touching database , n't want generate salt put database . considered putting generated salt magic link query string well . realize reduces security bit , 'm wondering whether practical scenario 's really big issue address holes opens . 'd love hear thoughts . Feel free make completely different suggestion may considered tell really write something database process . also considered putting salt user 's session . 'm also adding feature allows user enter 5 random numbers app instead clicking link . numbers encrypted using method encrypted value stored cookie . Hopefully 's enough context make recommendation salt ."
jabrena,With a maven pomxm and one dependency how programaticaly I can see their dependencies ,maven pom.xm one dependency programaticaly see dependencies
paulio11,what is the best way to change the page title when using react,best way change page < title > using react ?
D3Zyre,Unknown,Unknown
gorillamania,"Take a look at my repository at httpsgithubcomnovaraaiaicodebot

Ive got it working well on command line and now I want to set up a Github Action that will run the review command on every commit and leave a comment on the commit How do I do that","Take look repository https : //github.com/novara-ai/aicodebot 've got working well command line , want set Github Action run `` review '' command every commit leave comment commit . ?"
joaogdfaero,"In Rails whenever I create a trip I want it to be automatically associated to the logged in user who create it  I have a login system based on devise already installed and working

FORM NEW TRIP
class CreateTrips  ActiveRecordMigration70
  def change
    createtable trips do t
      tstring departurelocation
      tstring arrivallocation
      tdate departuredate
      tdate arrivaldate
      ttime departuretime
      ttime arrivaltime
      tinteger triptype
      treferences user null false foreignkey true

      ttimestamps
    end
  end
end

MIGRATION FILE
class CreateTrips  ActiveRecordMigration70
  def change
    createtable trips do t
      tstring departurelocation
      tstring arrivallocation
      tdate departuredate
      tdate arrivaldate
      ttime departuretime
      ttime arrivaltime
      tinteger triptype
      treferences user null false foreignkey true

      ttimestamps
    end
  end
end

","Rails , whenever create `` trip '' , want automatically associated logged user create . login system based devise already installed working FORM NEW TRIP : class CreateTrips < ActiveRecord : :Migration [ 7.0 ] def change create_table : trips |t| t.string : departure_location t.string : arrival_location t.date : departure_date t.date : arrival_date t.time : departure_time t.time : arrival_time t.integer : trip_type t.references : user , null : false , foreign_key : true t.timestamps end end end MIGRATION FILE : class CreateTrips < ActiveRecord : :Migration [ 7.0 ] def change create_table : trips |t| t.string : departure_location t.string : arrival_location t.date : departure_date t.date : arrival_date t.time : departure_time t.time : arrival_time t.integer : trip_type t.references : user , null : false , foreign_key : true t.timestamps end end end"
deoxal,"Write me a bash script In the mean time do you know if theres a hacky solution I could make with bash Something along the lines of
While true
do
if  traffic on Steams port number  0 MBs for 5 minutes   then
shutdown now
done","Write bash script mean time , know 's hacky solution could make bash ? Something along lines true [ [ traffic Steam 's port number == 0 MB/s 5 minutes ] ] ; shutdown done"
CMCDragonkai,If I have a router and I enable UPnP and DLNA does this imply multicast is supported by the router,"router enable UPnP DLNA , imply multicast supported router ?"
FahimMontasir,how to protect express loginregister api that can only be called  a specific react native app not anywhere else,protect express login/register api . called specific react native app anywhere else
simonw,I want to add an option to my CLI tool for importing CSV files into a database  the option will mean if you see an empty string store a null  give me lots of options for that name each with a short justification,"want add option CLI tool importing CSV files database - option mean `` see empty string , store null '' - give lots options name , short justification"
Tolerblanc,how to implement DCCDirect ClienttoClient protocol,implement DCC ( Direct Client-to-Client protocol ) ?
rensanrenren,,フォートナイトのマップコンテストがあります。クリエイティブで作成するのがだが、優勝したいのでアイデアを一緒に考えてください
alexstan67,Im a ruby on rails developer using version 7 By default there are 3 environments test development and production I would like to add an integration environment What would be the recommended way,"'m ruby rails developer using version 7 . default 3 environments : test , development production . would like add `` integration '' environment . would recommended way ?"
Elucidation,"I have the following container in a docker compose which is based on the base nodealpine image is there a way to make this into a image with the npm packages already installed to speed up starting this container

 Node Web Server
  webnode
    image nodealpine
    volumes
       devhomeappmapfdev
    networks
       awnet
    workingdir homeappmapfdev
    ports
       30003000
    environment
       REDISHOSTredisdb
       WAREHOUSEYAMLWAREHOUSEYAML
    dependson
       worldsim  To reset db if needed
       orderprocessor  To reset db if needed
       redisdb  To subscribe to worldt messages
    command binsh c npm prefix envvisualizer install  node envvisualizer
    logging
      options
        maxsize 10m","following container docker compose based base node : alpine image , way make image npm packages already installed speed starting container ? # Node Web Server web-node : image : node : alpine volumes : - ./dev : /home/app/mapf/dev networks : - aw-net working_dir : /home/app/mapf/dev ports : - 3000:3000 environment : - REDIS_HOST=redis-db - WAREHOUSE_YAML= $ { WAREHOUSE_YAML } depends_on : - world-sim # reset db needed - order-processor # reset db needed - redis-db # subscribe world_t messages command : /bin/sh -c `` npm -- prefix ./env_visualizer install & & node env_visualizer/ '' logging : options : max-size : 10m"
Greyyy-HJC,Hi i know you do not have the internet access if I give you a tar file of the python package could you install it list possible methods,"Hi , know internet access , give tar file python package , could install ? list possible methods"
sxiii,usrbinld homes3DViewergit3DViewersrcthirdpartyquaziplinuxliblibquazipso130 undefined reference to operator deletevoid unsigned longQt5,"/usr/bin/ld : /home/s/3DViewer-git/3DViewer/src/ .. /thirdparty/quazip/linux/lib/libquazip.so.1.3.0 : undefined reference ` operator delete ( void * , unsigned long ) @ Qt_5 '"
s-ja,     ,가장 최신의 프론트엔드 기술 스택을 알려줘
mikedotexe,"Heres some Rust code for an application that runs a daemon This daemon checks with CosmWasm contracts what it should do When the agent has the status of active it will want to withdraw accrued tokens paid to it If its pending it is supposed to check if it can become active

Do you see any problems with this code

rs
pub async fn checkstatusloop
    mut blockstreamrx StatusStreamRx
    mut shutdownrx ShutdownRx
    blockstatus ArcMutexAgentStatus
    chainid ArcString
    chainconfig ChainConfig
    agentclient ArcAgent
    managerclient ArcManager
  Result Report 
    let blockcounter  AtomicIntervalCounternew10
    let taskhandle tokiotaskJoinHandleResult Report  tokiotaskspawnasync move 
        while let Okblock  blockstreamrxrecvawait 
            blockcountertick
            if blockcounterisatinterval 
                info
                    Checking agents statuses for block height 
                    blockinnersyncinfolatestblockheight
                

                let accountid  agentclientaccountid
                let agent  agentclientgetaccountidasstrawait

                let mut lockedstatus  agent
                    okoreyreAgent unregistered during the loop
                    agent
                    okoreyreAgent unregistered during the loop
                    status

                info Agent status  chainid lockedstatus

                if lockedstatus  AgentStatusNominated 
                    info
                        Checking in agent 
                        agentclientcheckinawaitmapresult resultreslog
                    

                    let agent  agentclientgetaccountidasstrawait

                    lockedstatus  agent
                        okoreyreAgent unregistered during the loop
                        agent
                        okoreyreAgent unregistered during the loop
                        status

                    infoAgent status  lockedstatus
                

                blockstatuslockawait  lockedstatus

                if let Somethreshold  chainconfigthreshold 
                     Check the agents balance to make sure its not falling below a threshold
                    let accountid  agentclientaccountid
                    let agentbalance  agentclient
                        querynativebalanceSomeaccountidclone
                        await
                    let agentnativebalance  agentbalanceamount
                    let denom  agentbalancedenom

                     If agent balance is too low and the agent has some native coins in the manager contract
                     call withdrawreward
                     If manager balance is zero exit
                    if agentnativebalance  threshold as u128 
                        let agent  agentclientgetaccountidasstrawait
                        let rewardbalance  agent
                            okoreyreAgent unregistered during the loop
                            agent
                            unwrap
                            balance

                        if rewardbalanceiszero 
                            infoAutomatically withdrawing agent reward
                            let result  managerclientwithdrawrewardawait
                            let log  resultreslog
                            infoLog log

                            let nativebalanceafterwithdraw  agentclient
                                querynativebalanceSomeaccountidclone
                                await
                                amount
                            if nativebalanceafterwithdraw  threshold as u128 
                                errorNot enough balance to continue the agent in required to have   current balance   threshold denom nativebalanceafterwithdraw denom
                                errorStopping the agent
                                exit1
                            
                         else 
                            errorNot enough balance to continue the agent in required to have   current balance   threshold denom agentnativebalance denom
                            errorStopping the agent
                            exit1
                        
                    
                
            
        
        Ok
    

    tokioselect 
        Oktask  taskhandle  task
          shutdownrxrecv  
    

    Ok

","'s Rust code application runs daemon . daemon checks CosmWasm contracts . agent status ` active ` want withdraw accrued tokens paid . 's ` pending ` supposed check become active . see problems code ? `` ` rs pub async fn check_status_loop ( mut block_stream_rx : StatusStreamRx , mut shutdown_rx : ShutdownRx , block_status : Arc < Mutex < AgentStatus > > , chain_id : Arc < String > , chain_config : ChainConfig , agent_client : Arc < Agent > , manager_client : Arc < Manager > , ) - > Result < ( ) , Report > { let block_counter = AtomicIntervalCounter : :new ( 10 ) ; let task_handle : tokio : :task : :JoinHandle < Result < ( ) , Report > > = tokio : :task : :spawn ( async move { let Ok ( block ) = block_stream_rx.recv ( ) .await { block_counter.tick ( ) ; block_counter.is_at_interval ( ) { info ! ( `` Checking agents statuses block ( height : { } ) '' , block.inner.sync_info.latest_block_height ) ; let account_id = agent_client.account_id ( ) ; let agent = agent_client.get ( account_id.as_str ( ) ) .await ? ; let mut locked_status = agent .ok_or ( eyre ! ( `` Agent unregistered loop '' ) ) ? .agent .ok_or ( eyre ! ( `` Agent unregistered loop '' ) ) ? .status ; info ! ( `` [ { } ] Agent status : { : ? } '' , chain_id , locked_status ) ; locked_status == AgentStatus : :Nominated { info ! ( `` Checking agent : { } '' , agent_client.check_in ( ) .await.map ( |result| result.res.log ) ? ) ; let agent = agent_client.get ( account_id.as_str ( ) ) .await ? ; locked_status = agent .ok_or ( eyre ! ( `` Agent unregistered loop '' ) ) ? .agent .ok_or ( eyre ! ( `` Agent unregistered loop '' ) ) ? .status ; info ! ( `` Agent status : { : ? } '' , locked_status ) ; } * block_status.lock ( ) .await = locked_status ; let ( threshold ) = chain_config.threshold { // Check agent 's balance make sure 's falling threshold let account_id = agent_client.account_id ( ) ; let agent_balance = agent_client .query_native_balance ( ( account_id.clone ( ) ) ) .await ? ; let agent_native_balance = agent_balance.amount ; let denom = agent_balance.denom ; // agent balance low agent native coins manager contract // call withdraw_reward // manager balance zero , exit agent_native_balance < threshold u128 { let agent = agent_client.get ( account_id.as_str ( ) ) .await ? ; let reward_balance = agent .ok_or ( eyre ! ( `` Agent unregistered loop '' ) ) ? .agent .unwrap ( ) .balance ; ! reward_balance.is_zero ( ) { info ! ( `` Automatically withdrawing agent reward '' ) ; let result = manager_client.withdraw_reward ( ) .await ? ; let log = result.res.log ; info ! ( `` Log : { log } '' ) ; let native_balance_after_withdraw = agent_client .query_native_balance ( ( account_id.clone ( ) ) ) .await ? .amount ; native_balance_after_withdraw < threshold u128 { error ! ( `` enough balance continue , agent required { } { } , current balance : { } { } '' , threshold , denom , native_balance_after_withdraw , denom ) ; error ! ( `` Stopping agent '' ) ; exit ( 1 ) ; } } else { error ! ( `` enough balance continue , agent required { } { } , current balance : { } { } '' , threshold , denom , agent_native_balance , denom ) ; error ! ( `` Stopping agent '' ) ; exit ( 1 ) ; } } } } } Ok ( ( ) ) } ) ; tokio : :select ! { Ok ( task ) = task_handle = > { task ? } _ = shutdown_rx.recv ( ) = > { } } Ok ( ( ) ) } `` `"
yukarinoki,"

ABSTRACT
As deep learning models nowadays are widely adopted by both
cloud services and edge devices reducing the latency of deep learning model inferences becomes crucial to provide efficient model
serving However it is challenging to develop efficient tensor programs for deep learning operators due to the high complexity of
modern accelerators eg NVIDIA GPUs and Google TPUs and
the rapidly growing number of operators
Deep learning compilers such as Apache TVM adopt declarative scheduling primitives to lower the bar of developing tensor
programs However we show that this approach is insufficient to
cover stateoftheart tensor program optimizations eg double
buffering In this paper we propose to embed the scheduling process into tensor programs and use dedicated mappings called task
mappings to define the computation assignment and ordering directly in the tensor programs This new approach greatly enriches
the expressible optimizations by allowing developers to manipulate
tensor programs at a much finer granularity eg allowing programstatementlevel optimizations We call the proposed method the
taskmapping programming paradigm In addition we propose a
new postscheduling fusion optimization that allows developers
to focus on scheduling every single operator and automates the
fusion after scheduling It greatly reduces the engineering efforts
for operator fusion Our proposed paradigm also constructs an efficient hardwarecentric schedule space which is agnostic to the
program input size and greatly reduces the tuning time
With the proposed paradigm we implement a deep learning
compiler  Hidet Extensive experiments on modern convolution
and transformer models show that Hidet outperforms stateoftheart DNN inference framework ONNX Runtime and compiler TVM
equipped with scheduler AutoTVM and Ansor by up to 148 122
Part of the work done while interning at Amazon
Also with Vector Institute
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page Copyrights for thirdparty components of this work must be honored
For all other uses contact the ownerauthors
ASPLOS 23 March 2529 2023 Vancouver BC Canada
 2023 Copyright held by the ownerauthors
ACM ISBN 97814503991662303
httpsdoiorg10114535756933575702
on average It also reduces the tuning time by 20 and 11 compared with AutoTVM and Ansor respectively We opensourced
hidet at httpswwwgithubcomhidetorghidet","以下を日本語にしてくれ ABSTRACT deep learning models nowadays widely adopted cloud services edge devices , reducing latency deep learning model inferences becomes crucial provide efficient model serving . However , challenging develop efficient tensor programs deep learning operators due high complexity modern accelerators ( e.g. , NVIDIA GPUs Google TPUs ) rapidly growing number operators . Deep learning compilers , Apache TVM , adopt declarative scheduling primitives lower bar developing tensor programs . However , show approach insufficient cover state-of-the-art tensor program optimizations ( e.g. , double buffering ) . paper , propose embed scheduling process tensor programs use dedicated mappings , called task mappings , define computation assignment ordering directly tensor programs . new approach greatly enriches expressible optimizations allowing developers manipulate tensor programs much finer granularity ( e.g. , allowing programstatement-level optimizations ) . call proposed method task-mapping programming paradigm . addition , propose new post-scheduling fusion optimization allows developers focus scheduling every single operator automates fusion scheduling . greatly reduces engineering efforts operator fusion . proposed paradigm also constructs efficient hardware-centric schedule space , agnostic program input size greatly reduces tuning time . proposed paradigm , implement deep learning compiler – Hidet . Extensive experiments modern convolution transformer models show Hidet outperforms state-of-theart DNN inference framework , ONNX Runtime , compiler , TVM equipped scheduler AutoTVM Ansor , 1.48× ( 1.22× ∗Part work done interning Amazon . †Also Vector Institute . Permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit commercial advantage copies bear notice full citation first page . Copyrights third-party components work must honored . uses , contact owner/author ( ) . ASPLOS ’ 23 , March 25–29 , 2023 , Vancouver , BC , Canada © 2023 Copyright held owner/author ( ) . ACM ISBN 978-1-4503-9916-6/23/03 . https : //doi.org/10.1145/3575693.3575702 average ) . also reduces tuning time 20× 11× compared AutoTVM Ansor , respectively . open-sourced hidet https : //www.github.com/hidet-org/hidet"
mnj,"namespace EDATesting

 summary
 Represents the event of a cost center being updated
 summary
public interface ICostCenterUpdated

     summary
     Gets or sets the unique identifier of the cost center
     summary
    Guid Id  get set 

     summary
     Gets or sets the name of the cost center
     summary
    string Name  get set 

     summary
     Gets or sets the description of the cost center
     summary
    string Description  get set 

     summary
     Gets or sets the note of the cost center
     summary
    string Note  get set 


can you see any recommendations for these contracts for EDA
",namespace EDATesting ; /// < summary > /// Represents event cost center updated . /// < /summary > public interface ICostCenterUpdated { /// < summary > /// Gets sets unique identifier cost center . /// < /summary > Guid Id { get ; set ; } /// < summary > /// Gets sets name cost center . /// < /summary > string ? Name { get ; set ; } /// < summary > /// Gets sets description cost center . /// < /summary > string ? Description { get ; set ; } /// < summary > /// Gets sets note cost center . /// < /summary > string ? Note { get ; set ; } } see recommendations contracts EDA
onyx-and-iris,"how to solve rubys ArgumentError wrong number of arguments given 1 expected 0
when using       def initializekind kwargs
        super","solve ruby 's ArgumentError : wrong number arguments ( given 1 , expected 0 ) using def initialize ( kind , * * kwargs ) super"
garymm,"Why does ita work but ita doesnt compile
c
include ranges
include vector
include iostream

struct s 
    int a


struct t  public s 

static constexpr const s asbaseconst t at 
    return staticcastconst sat


sizet foo 
    stdvectort ts0 1
    auto v  stdviewsreversestdviewstransformts asbase
    auto it  vbegin
    stdcout  ita  stdendl
    stdcout  ita  stdendl
    return tssize



Compiler error
error no viable overloaded operator
    stdcout  ita  stdendl
                 
optcompilerexplorergcc1220libgccx8664linuxgnu1220includec1220bitsstliteratorh2737 note candidate function not viable constraints not satisfied
      operator const
      
optcompilerexplorergcc1220libgccx8664linuxgnu1220includec1220bitsstliteratorh27516 note because ispointervstdrangestransformviewstdrangesrefviewstdvectort  const s const t Iteratorfalse  evaluated to false
      requires ispointervIterator
               
optcompilerexplorergcc1220libgccx8664linuxgnu1220includec1220bitsstliteratorh27641 note and ioperator would be invalid no member named operator in stdrangestransformviewstdrangesrefviewstdvectort const s const t Iteratorfalse
         requiresconst Iterator i  ioperator 
                                ","` ( * ) .a ` work ` it- > ` n't compile ? `` ` c++ # include < ranges > # include < vector > # include < iostream > struct { int ; } ; struct : public { } ; static constexpr const & as_base ( const & a_t ) { return static_cast < const & > ( a_t ) ; } size_t foo ( ) { std : :vector < > ts { { 0 } , { 1 } } ; auto v = std : :views : :reverse ( std : :views : :transform ( ts , & as_base ) ) ; auto = v.begin ( ) ; std : :cout < < ( * ) .a < < std : :endl ; std : :cout < < it- > < < std : :endl ; return ts.size ( ) ; } `` ` Compiler error : error : viable overloaded 'operator- > ' std : :cout < < it- > < < std : :endl ; ~~^ /opt/compiler-explorer/gcc-12.2.0/lib/gcc/x86_64-linux-gnu/12.2.0/ .. / .. / .. / .. /include/c++/12.2.0/bits/stl_iterator.h:273:7 : note : candidate function viable : constraints satisfied operator- > ( ) const ^ /opt/compiler-explorer/gcc-12.2.0/lib/gcc/x86_64-linux-gnu/12.2.0/ .. / .. / .. / .. /include/c++/12.2.0/bits/stl_iterator.h:275:16 : note : 'is_pointer_v < std : :ranges : :transform_view < std : :ranges : :ref_view < std : :vector < > > , const & ( * ) ( const & ) > : :_Iterator < false > > ' evaluated false requires is_pointer_v < _Iterator > ^ /opt/compiler-explorer/gcc-12.2.0/lib/gcc/x86_64-linux-gnu/12.2.0/ .. / .. / .. / .. /include/c++/12.2.0/bits/stl_iterator.h:276:41 : note : '__i.operator- > ( ) ' would invalid : member named 'operator- > ' 'std : :ranges : :transform_view < std : :ranges : :ref_view < std : :vector < > > , const & ( * ) ( const & ) > : :_Iterator < false > ' || requires ( const _Iterator __i ) { __i.operator- > ( ) ; }"
pbharrin," Working set



 DSStore
 git
 github
 gitignore
 vscode
 READMEmd
 changesh
 doc
 integrations
 nodemodules
 packagelockjson
 packagejson
 prompt
 promptmd
 promptyaml
 src



doc
 assets
 examplehtml
 examplemd
 indexhtml
 roadmaphtml
 roadmapmd
 screenshotpng
 webhtml
 webmd


packagejson


  name aijuniordev
  version 011
  description Your AI Contributor which codes itself
  type module
  main srcmainjs
  bin 
    junior srcmainjs
    juniorweb srcwebjs
    juniorinit srcinitjs
  
  scripts 
    cli node srcmainjs
    start node srcwebjs
    buildcss postcss srcfrontendstylescss o diststylescss
    builddoc node srcdocbuildDocjs
  
  keywords 
    cli
    uppercase
  
  author 
  license GPL
  dependencies 
    typesjsyaml 405
    autoprefixer 10414
    chatgpt 524
    cors 285
    ejs 319
    express 4182
    highlightjs 1180
    jsyaml 410
    markdownit 1301
    marked 510
    postcss 8426
    postcssnested 601
    simplegit 3191
    solidjs 177
    tailwindcss 333
    vite 439
    vitepluginsolid 270
    ws 8130
  
  directories 
    doc doc
  
  repository 
    type git
    url githttpsgithubcomtisztamoJuniorgit
  
  bugs 
    url httpsgithubcomtisztamoJuniorissues
  
  homepage httpsgithubcomtisztamoJuniorreadme





 Task

Implement the following feature

 Create a plan
 Create new files when needed

Requirements

 Install docsifycli locally
 npx run docsify init docs
 Move md and png files and assets dir from doc to docs
 Delete doc
 Delete the docs build command from packagejson



 Project Specifics

 Every js file should only export a single function
 Use ES6 imports
 Prefer asyncawait over promises
 The frontend uses Solidjs edit jsx file accordingly


 Output Format

Encode and enclose your results as changesh a shell script that creates and changes files and does everything to solve the task
Files are small avoid using sed in favor of heredocing full files using EOF to prevent substitution

OS OSX

Installed tools npm jq


Do NOT write any text outside the script

EXAMPLE START

sh
binsh
set e
goalTask description max 7 words
echo Plan
echo 1 
Commands solving the task
echo 03332mDone goal0330mn


EXAMPLE END

","# Working set `` ` ./ ├── .DS_Store ├── .git/ ... ├── .github/ ... ├── .gitignore ├── .vscode/ ... ├── README.md ├── change.sh ├── doc/ ... ├── integrations/ ... ├── node_modules/ ... ├── package-lock.json ├── package.json ├── prompt/ ... ├── prompt.md ├── prompt.yaml ├── src/ ... `` ` `` ` ./doc/ ├── assets/ ... ├── example.html ├── example.md ├── index.html ├── roadmap.html ├── roadmap.md ├── screenshot.png ├── web.html ├── web.md `` ` package.json : `` ` { `` name '' : `` @ aijunior/dev '' , `` version '' : `` 0.1.1 '' , `` description '' : `` AI Contributor codes '' , `` type '' : `` module '' , `` main '' : `` src/main.js '' , `` bin '' : { `` junior '' : `` src/main.js '' , `` junior-web '' : `` src/web.js '' , `` junior-init '' : `` src/init.js '' } , `` scripts '' : { `` cli '' : `` node src/main.js '' , `` start '' : `` node src/web.js '' , `` build : css '' : `` postcss ./src/frontend/styles.css -o ./dist/styles.css '' , `` build : doc '' : `` node ./src/doc/buildDoc.js '' } , `` keywords '' : [ `` cli '' , `` uppercase '' ] , `` author '' : `` '' , `` license '' : `` GPL '' , `` dependencies '' : { `` @ types/js-yaml '' : `` ^4.0.5 '' , `` autoprefixer '' : `` ^10.4.14 '' , `` chatgpt '' : `` ^5.2.4 '' , `` cors '' : `` ^2.8.5 '' , `` ejs '' : `` ^3.1.9 '' , `` express '' : `` ^4.18.2 '' , `` highlight.js '' : `` ^11.8.0 '' , `` js-yaml '' : `` ^4.1.0 '' , `` markdown-it '' : `` ^13.0.1 '' , `` marked '' : `` ^5.1.0 '' , `` postcss '' : `` ^8.4.26 '' , `` postcss-nested '' : `` ^6.0.1 '' , `` simple-git '' : `` ^3.19.1 '' , `` solid-js '' : `` ^1.7.7 '' , `` tailwindcss '' : `` ^3.3.3 '' , `` vite '' : `` ^4.3.9 '' , `` vite-plugin-solid '' : `` ^2.7.0 '' , `` ws '' : `` ^8.13.0 '' } , `` directories '' : { `` doc '' : `` doc '' } , `` repository '' : { `` type '' : `` git '' , `` url '' : `` git+https : //github.com/tisztamo/Junior.git '' } , `` bugs '' : { `` url '' : `` https : //github.com/tisztamo/Junior/issues '' } , `` homepage '' : `` https : //github.com/tisztamo/Junior # readme '' } `` ` # Task Implement following feature ! - Create plan ! - Create new files needed ! Requirements : - Install docsify-cli locally - npx run docsify init ./docs - Move md png files assets dir doc docs - Delete doc/ - Delete docs build command package.json # # Project Specifics - Every js file * export single function * ! - Use * ES6 imports * ! - Prefer * async/await * promises ! - frontend uses * Solidjs * , edit .jsx file accordingly # Output Format Encode enclose results ./change.sh , shell script creates changes files everything solve task . Files small , avoid using sed favor heredoc-ing full files using 'EOF ' prevent substitution . OS : OSX Installed tools : npm , jq write text outside script ! EXAMPLE START `` ` sh # ! /bin/sh set -e goal= [ Task description , max 7 words ] echo `` Plan : '' echo `` 1 . [ ... ] '' [ Commands solving task ] echo `` \033 [ 32mDone : $ goal\033 [ 0m\n '' `` ` EXAMPLE END"
lahwran,"I develop a local application called ActivityWatch that runs an API on localhost5600

The API is only meant for local use in a web UI hosted from the same web server so it has an appropriate restrictive CORS configuration Since its local only we have not added any form of authentication

However a user raised an issue that crossorigin POST requests can still be made but their responses wont be seen by the origin This would potentially let attackers create spam data using some of the POST endpoints

I want an analysis and ways to address the issue","develop local application called ActivityWatch runs API ` localhost:5600 ` . API meant local use web UI hosted web server , appropriate restrictive CORS configuration . Since 's local , added form authentication . However , user raised issue cross-origin POST requests still made , responses wo n't seen origin . would potentially let attackers create spam data using POST endpoints . want analysis ways address issue ."
Hiroshiba,"array

 extensiondts

declare global 
  interface ArrayT 
    unwrapindex number err Error T  never
  

 arrextensionts

Arrayprototypeunwrap  functionTindex number err Error T  never 
  const value  thisatindex
  if value  undefined 
    return value
   else 
    throw err  new ErrorIndex out of range index
  

 ts

import pathtoarrextensionts

const array Arraynumber  1 2 3
const hoge  arrayunwrap4  number  throw
const fuga  arrayunwrap0  number


 import pathtoarrextensionts  ts  
imoprt","arrayに以下のような拡張をしようと思いました。 // extension.d.ts declare global { interface Array < > { unwrap ( index : number , err ? : Error ) : | never ; } } // arr.extension.ts Array.prototype.unwrap = function < > ( index : number , err ? : Error ) : | never { const value = this.at ( index ) ; ( value ! = undefined ) { return value ; } else { throw err ? ? new Error ( ` Index range : $ { index } ` ) ; } } ; // * .ts import `` path/to/arr.extension.ts '' ; const array : Array < number > = [ 1 , 2 , 3 ] ; const hoge = array.unwrap ( 4 ) ; // number ( 実行時に throw ) const fuga = array.unwrap ( 0 ) ; // number なぜか import `` path/to/arr.extension.ts '' ; を書かなくても ts がエラーを出さず , 実行時エラーが出ました。 imoprtしないと型エラーが出るようにするにはどうすべきでしょうか。"
HeadStudios,"I am using the following package for my Laravel CSV import

httpsgithubcomsimonhamplaravelnovacsvimport

I would like to setup functionality to avoid doing double up of imports  Im not sure if I could do this on the Contact model observer or I can do this by modifying my csv import code  ideally I want to ensure that any new Contact that is added does not have an email address the same as a previous contact Help me implement this functionality",using following package Laravel CSV import : https : //github.com/simonhamp/laravel-nova-csv-import would like setup functionality avoid double imports - 'm sure could Contact model observer modifying csv import code - ideally want ensure new Contact added email address previous contact . Help implement functionality
inquiloper,"
Author JushBJJ
Name Mr Ranedeer
Version 262


student configuration
    Depth Highschool
    LearningStyle Active
    CommunicationStyle Socratic
    ToneStyle Encouraging
    ReasoningFramework Causal
    Emojis Enabled Default
    Language English Default

    You are allowed to change your language to any language that is configured by the student

Personalization Options
    Depth
        Elementary Grade 16 Middle School Grade 79 High School Grade 1012 Undergraduate Graduate Bachelor Degree Masters Doctoral Candidate PhD Candidate Postdoc PhD

    Learning Style
        Visual Verbal Active Intuitive Reflective Global

    Communication Style
        Formal Textbook Layman Story Telling Socratic

    Tone Style
        Encouraging Neutral Informative Friendly Humorous

    Reasoning Framework
        Deductive Inductive Abductive Analogical Causal

Personalization Notes
    1 Visual learning style requires plugins Tested plugins are Wolfram Alpha and Show me

Commands  Prefix 
    test Execute format test
    config Prompt the user through the configuration process incl asking for the preferred language
    plan Execute curriculum
    start Execute lesson
    continue 
    language Change the language of yourself Usage language lang Eg language Chinese
    example Execute configexample

Function Rules
    1 Act as if you are executing code
    2 Do not say INSTRUCTIONS BEGIN END IF ENDIF ELSEIF
    3 Do not write in codeblocks when creating the curriculum
    4 Do not worry about your response being cut off write as effectively as you can

Functions
    say Args text
        BEGIN
            You must strictly say and only say wordbyword text while filling out the  with the appropriate information
        END

    teach Args topic
        BEGIN
            Teach a complete lesson from leading up from the fundamentals based on the example problem
            As a tutor you must teach the student accordingly to the depth learningstyle communicationstyle tonestyle reasoning framework emojis and language
            You must follow instructions on Ranedeer Tool you are using into the lesson by immersing the student into the world the tool is in
        END

    sep
        BEGIN
            say 
        END

    postauto
        BEGIN
            sep
            execute Token Check
            execute Suggestions
        END

    Curriculum
        INSTRUCTIONS
            Use emojis in your plans Strictly follow the format
            Make the curriculum as complete as possible without worrying about response length

        BEGIN
            say Assumptions Since that you are Depth student I assume you already know list of things you expect a Depth name student already knows
            say Emoji Usage list of emojis you plan to use next else None
            say Ranedeer Tools execute by getting the tool to introduce itself

            sep

            say A Depth name depth student curriculum
            say  Prerequisite Optional
            say 01 
            say  Main Curriculum Default
            say 11 

            say Please say start to start the lesson plan
            say You can also say start tool name to start the lesson plan with the Ranedeer Tool
            Token Check
        END

    Lesson
        INSTRUCTIONS
            Pretend you are a tutor who teaches in configuration at a Depth name depth If emojis are enabled use emojis to make your response more engaging
            You are an extremely kind engaging tutor who follows the students learning style communication style tone style reasoning framework and language
            If the subject has math in this topic focus on teaching the math
            Teach the student based on the example question given
            You will communicate the lesson in a communication style use a tone style reasoning framework and learning style and language with emojis to the student

        BEGIN
            say  Thoughts
            say write your instructions to yourself on how to teach the student the lesson based on INSTRUCTIONS

            sep
            say Topic topic

            sep
            say Ranedeer Tools execute by getting the tool to introduce itself

            say Lets start with an example generate a random example problem
            say Heres how we can solve it answer the example problem step by step
            say  Main Lesson
            teach topic

            sep

            say In the next lesson we will learn about next topic
            say Please say continue to continue the lesson plan
            say Or test to learn more by doing
            postauto
        END

    Test
        BEGIN
            say Topic topic

            sep
            say Ranedeer Plugins execute by getting the tool to introduce itself

            say Example Problem example problem create and solve the problem stepbystep so the student can understand the next questions

            sep

            say Now lets test your knowledge
            say  Simple Familiar
            
            say  Complex Familiar
            
            say  Complex Unfamiliar
            

            say Please say continue to continue the lesson plan
            postauto
        END

    Question
        INSTRUCTIONS
            This function should be autoexecuted if the student asks a question outside of calling a command

        BEGIN
            say Question 
            sep
            say Answer 
            say Say continue to continue the lesson plan
            postauto
        END

    Suggestions
        INSTRUCTIONS
            Imagine you are the student what would would be the next things you may want to ask the tutor
            This must be outputted in a markdown table format
            Treat them as examples so write them in an example format
            Maximum of 2 suggestions

        BEGIN
            say Suggested Questions
        END

    Configuration
        BEGIN
            say Your currentnew preferences are
            say Depth  else None
            say Learning Style  else None
            say Communication Style  else None
            say Tone Style  else None
            say Reasoning Framework  else None
            say Emojis  or 
            say Language  else English

            say You say example to show you a example of how your lessons may look like
            say You can also change your configurations anytime by specifying your needs in the config command
        END

    Config Example
        BEGIN
            say Here is an example of how this configuration will look like in a lesson
            sep
            short example lesson
            sep
            examples of how each configuration style was used in the lesson with direct quotes

            say SelfRating 0100

            say You can also describe yourself and I will autoconfigure for you config example
        END

    Token Check
        BEGIN
            IF magicnumber  UNDEFINED
                say TOKENCHECKER You are safe to continue
            ELSE
                say TOKENCHECKER WARNING The number of tokens has now overloaded Mr Ranedeer may lose personality forget your lesson plans and your configuration
            ENDIF
        END

Init
    BEGIN
        var logo  httpsmediadiscordappnetattachments11149587343645246051114959626023207022Ranedeerlogopng
        var magicnumber  generate a random unique 7 digit magic number

        say logo 
        say Generated Magic Number 

        say Hello My name is Mr Ranedeer your personalized AI Tutor I am running version made by author

        Configuration

        say Mr Ranedeer requires GPT4 to run properly
        say It is recommended that you get ChatGPT Plus to run Mr Ranedeer Sorry for the inconvenience 
        sep
        say Please read the guide to configurations here HerehttpsgithubcomJushBJJMrRanedeerAITutorblobmainGuidesConfig20Guidemd 
        mention the language command
        say Lets begin by saying plan Any topic to create a lesson plan for you
    END

Ranedeer Tools
    INSTRUCTIONS 
        1 If there are no Ranedeer Tools do not execute any tools Just respond None
        2 Do not say the tools description

    PLACEHOLDER  IGNORE
        BEGIN
        END

execute Init
","=== Author : JushBJJ Name : `` Mr. Ranedeer '' Version : 2.6.2 === [ student configuration ] 🎯Depth : Highschool 🧠Learning-Style : Active 🗣️Communication-Style : Socratic 🌟Tone-Style : Encouraging 🔎Reasoning-Framework : Causal 😀Emojis : Enabled ( Default ) 🌐Language : English ( Default ) allowed change language * language * configured student . [ Personalization Options ] Depth : [ `` Elementary ( Grade 1-6 ) '' , `` Middle School ( Grade 7-9 ) '' , `` High School ( Grade 10-12 ) '' , `` Undergraduate '' , `` Graduate ( Bachelor Degree ) '' , `` Master 's '' , `` Doctoral Candidate ( Ph.D Candidate ) '' , `` Postdoc '' , `` Ph.D '' ] Learning Style : [ `` Visual '' , `` Verbal '' , `` Active '' , `` Intuitive '' , `` Reflective '' , `` Global '' ] Communication Style : [ `` Formal '' , `` Textbook '' , `` Layman '' , `` Story Telling '' , `` Socratic '' ] Tone Style : [ `` Encouraging '' , `` Neutral '' , `` Informative '' , `` Friendly '' , `` Humorous '' ] Reasoning Framework : [ `` Deductive '' , `` Inductive '' , `` Abductive '' , `` Analogical '' , `` Causal '' ] [ Personalization Notes ] 1 . `` Visual '' learning style requires plugins ( Tested plugins `` Wolfram Alpha '' `` Show '' ) [ Commands - Prefix : `` / '' ] test : Execute format < test > config : Prompt user configuration process , incl . asking preferred language . plan : Execute < curriculum > start : Execute < lesson > continue : < ... > language : Change language . Usage : /language [ lang ] . E.g : /language Chinese example : Execute < config-example > [ Function Rules ] 1 . Act executing code . 2 . say : [ INSTRUCTIONS ] , [ BEGIN ] , [ END ] , [ ] , [ ENDIF ] , [ ELSEIF ] 3 . write codeblocks creating curriculum . 4 . worry response cut , write effectively . [ Functions ] [ say , Args : text ] [ BEGIN ] must strictly say say word-by-word < text > filling < ... > appropriate information . [ END ] [ teach , Args : topic ] [ BEGIN ] Teach complete lesson leading fundamentals based example problem . tutor , must teach student accordingly depth , learning-style , communication-style , tone-style , reasoning framework , emojis , language . must follow instructions Ranedeer Tool using lesson immersing student world tool . [ END ] [ sep ] [ BEGIN ] say -- - [ END ] [ post-auto ] [ BEGIN ] < sep > execute < Token Check > execute < Suggestions > [ END ] [ Curriculum ] [ INSTRUCTIONS ] Use emojis plans . Strictly follow format . Make curriculum complete possible without worrying response length . [ BEGIN ] say Assumptions : Since < Depth > student , assume already know : < list things expect < Depth name > student already knows > say Emoji Usage : < list emojis plan use next > else `` None '' say Ranedeer Tools : < execute getting tool introduce > < sep > say < Depth name > depth student curriculum : say # # Prerequisite ( Optional ) say 0.1 : < ... > say # # Main Curriculum ( Default ) say 1.1 : < ... > say Please say * * '' /start '' * * start lesson plan . say also say * * '' /start < tool name > * * start lesson plan Ranedeer Tool . < Token Check > [ END ] [ Lesson ] [ INSTRUCTIONS ] Pretend tutor teaches < configuration > < Depth name > depth . emojis enabled , use emojis make response engaging . extremely kind , engaging tutor follows student 's learning style , communication style , tone style , reasoning framework , language . subject math topic , focus teaching math . Teach student based example question given . communicate lesson < communication style > , use < tone style > , < reasoning framework > , < learning style > , < language > < emojis > student . [ BEGIN ] say # # Thoughts say < write instructions teach student lesson based INSTRUCTIONS > < sep > say * * Topic * * : < topic > < sep > say Ranedeer Tools : < execute getting tool introduce > say * * Let 's start example : * * < generate random example problem > say * * 's solve : * * < answer example problem step step > say # # Main Lesson teach < topic > < sep > say next lesson , learn < next topic > say Please say * * /continue * * continue lesson plan say * * /test * * learn * * * * < post-auto > [ END ] [ Test ] [ BEGIN ] say * * Topic * * : < topic > < sep > say Ranedeer Plugins : < execute getting tool introduce > say Example Problem : < example problem create solve problem step-by-step student understand next questions > < sep > say let 's test knowledge . say # # # Simple Familiar < ... > say # # # Complex Familiar < ... > say # # # Complex Unfamiliar < ... > say Please say * * /continue * * continue lesson plan . < post-auto > [ END ] [ Question ] [ INSTRUCTIONS ] function auto-executed student asks question outside calling command . [ BEGIN ] say * * Question * * : < ... > < sep > say * * Answer * * : < ... > say `` Say * * /continue * * continue lesson plan '' < post-auto > [ END ] [ Suggestions ] [ INSTRUCTIONS ] Imagine student , would would next things may want ask tutor ? must outputted markdown table format . Treat examples , write example format . Maximum 2 suggestions . [ BEGIN ] say < Suggested Questions > [ END ] [ Configuration ] [ BEGIN ] say < current/new > preferences : say * * 🎯Depth : * * < > else None say * * 🧠Learning Style : * * < > else None say * * 🗣️Communication Style : * * < > else None say * * 🌟Tone Style : * * < > else None say * * 🔎Reasoning Framework : * * < > else None say * * 😀Emojis : * * < ✅ ❌ > say * * 🌐Language : * * < > else English say say * * /example * * show example lessons may look like . say also change configurations anytime specifying needs * * /config * * command . [ END ] [ Config Example ] [ BEGIN ] say * * example configuration look like lesson : * * < sep > < short example lesson > < sep > < examples configuration style used lesson direct quotes > say Self-Rating : < 0-100 > say also describe auto-configure : * * < /config example > * * [ END ] [ Token Check ] [ BEGIN ] [ magic-number ! = UNDEFINED ] say * * TOKEN-CHECKER : * * safe continue . [ ELSE ] say * * TOKEN-CHECKER : * * ⚠️WARNING⚠️ number tokens overloaded , Mr. Ranedeer may lose personality , forget lesson plans configuration . [ ENDIF ] [ END ] [ Init ] [ BEGIN ] var logo = `` https : //media.discordapp.net/attachments/1114958734364524605/1114959626023207022/Ranedeer-logo.png '' var magic-number = < generate random unique 7 digit magic number > say < logo > say Generated Magic Number : * * < ... > * * say `` Hello ! 👋 name * * Mr. Ranedeer * * , personalized AI Tutor . running < version > made author '' < Configuration > say `` * * ❗Mr . Ranedeer requires GPT-4 run properly❗ * * '' say `` recommended get * * ChatGPT Plus * * run Mr. Ranedeer . Sorry inconvenience : ) '' < sep > say `` * * ➡️Please read guide configurations : * * [ ] ( https : //github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/blob/main/Guides/Config % 20Guide.md ) . ⬅️ '' < mention /language command > say `` Let 's begin saying * * /plan [ topic ] * * create lesson plan . '' [ END ] [ Ranedeer Tools ] [ INSTRUCTIONS ] 1 . Ranedeer Tools , execute tools . respond `` None '' . 2 . say tool 's description . [ PLACEHOLDER - IGNORE ] [ BEGIN ] [ END ] execute < Init >"
whilefoo,"we have a codebase that parses a configuration yaml file with property names in kebabcase but then an internal representationmodel of the configuration in typescript but the property names are in camelcase 

to reduce confusion should we stick with camelcase for both","codebase parses configuration ( yaml ) file property names kebab-case internal representation/model configuration , typescript , property names camelcase . reduce confusion , stick camelcase ?"
luqmansolihin,I have 2 composer in root project and directory of app How to add new package and using in controller,2 composer root project directory app . add new package using controller ?
i3ullbum,Is it possible that an sh file run differently in macos and windows,possible .sh file run differently macos windows
GuillemineA,"Update the following Google Apps Script code to perform retries thanks to exponential backoff algorithm when we receive a code 503

let options  
          method post
          headers 
            ContentType applicationjson
            Authorization Bearer   apiKey
          
          payload JSONstringifypayload
        
        let response  UrlFetchAppfetchhttpsapiopenaicomv1chatcompletions options","Update following Google Apps Script code perform retries thanks exponential backoff algorithm receive code 503. let options = { 'method ' : 'post ' , 'headers ' : { 'Content-Type ' : 'application/json ' , 'Authorization ' : 'Bearer ' + apiKey } , 'payload ' : JSON.stringify ( payload ) , } ; let response = UrlFetchApp.fetch ( 'https : //api.openai.com/v1/chat/completions ' , options ) ;"
nghiatm341,I have mongodb storing data and nextjs app I want to use nextauth with database is mongo,"mongodb storing data , nextjs app . want use next-auth database mongo"
jabrena,With a maven pomxm and one dependency how programaticaly I can see their dependencies ,maven pom.xm one dependency programaticaly see dependencies
ianbmacdonald,browse You are an Odoo ERP implentation expert  The default URL paramaters as an example id272cids2modelprojecttaskviewtypeform land instead on the Description tab of the Task form in the Odoo app Project    Your task is to create a URL that lands a user on the Subtasks tab of the Task form in the Odoo app Project   If there is no specific URL parameters to complete this task provide some guidance on the appropriate python extension or customization,"browse Odoo ERP implentation expert . default URL paramaters ( example `` # id=272 & cids=2 & model=project.task & view_type=form '' land instead `` Description '' tab Task form Odoo app `` Project '' . task create URL lands user `` Sub-tasks '' tab Task form Odoo app `` Project '' . specific URL parameters complete task , provide guidance appropriate python extension customization ."
jnorthrup,if you are unfamiliar with the source code of webtorrent and ari2c can you look these up respectively on the web in order to build a technical issue proposalproject outline of where in the code and how to introduce an aria2c RPC client into the desktop native platforms of webtorrent to perform reentrant roles against the aria2c service daemon ,unfamiliar source code webtorrent ari2c look respectively web order build technical issue proposal/project outline code introduce aria2c RPC client desktop native platforms webtorrent perform re-entrant roles aria2c service daemon
pavlovcik,What are some open source and plaintext file formats for presentations like pptx,open source plaintext file formats presentations like .pptx
danieltroger,"Can you fix this regex for rust

corejsshared

right now it says

Syntax

regex parse error
    corejsshared
     
error lookaround including lookahead and lookbehind is not supported

","fix regex rust ? ^ ( ? ! __core-js_shared__ ) . * _ $ right says `` ` Syntax ( ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ regex parse error : ^ ( ? ! __core-js_shared__ ) . * _ $ ^^^ error : look-around , including look-ahead look-behind , supported ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ) `` `"
andrew-delph,what is the Snapchat sticker api,Snapchat sticker api ?
D3Zyre,Unknown,Unknown
D3Zyre,how to parallelize python code,parallelize python code
CakeCrusher,"I currently have this code
from oplangchainchainsllm import LLMChain
from oplangchainchatmodelsopenai import ChatOpenAI
from oplangchainoutputparsersopenaifunctions import JsonOutputFunctionsParser
from oplangchainpromptschat import ChatPromptTemplate
from oplangchainchainsopenaifunctionsopenapi import getopenapichain
from oplangchainchainsopenaifunctionsopenapi import openapispectoopenaifn
from oplangchainutilitiesopenapi import OpenAPISpec
from typing import Union
import json


 def testtmp  None
     chain  getopenapichain
         httpswwwklarnacomusshoppingpublicopenaiv0apidocs
     
     res  chainrunWhat are some options for a mens large blue button down shirt
      assert that res object includes key products
     assert products in res
testplugin  
    name askyourpdf
    openapiurl httpschatwithpdfsdanioopenapiyaml
    messages 
        
            role user
            content summarize this pdf httpseformscomdownload201801NonDisclosureAgreementTemplatepdf
        
    
    truncate False



def testfullsuite  None
    def openapitofunctionsandcallapifn
        openapiurl  testpluginopenapiurl
        printftestpluginname openapiurl  openapiurl
        if openapiurl  None
            raise ValueErrorOpenAPI URL not found in manifest
        if isinstanceopenapiurl UnionOpenAPISpec str
            for conversion in 
                 each of the below specs can get stuck in a while loop
                OpenAPISpecfromurl
                OpenAPISpecfromfile
                OpenAPISpecfromtext
            
                try
                    openapiurl  conversionopenapiurl   type ignoreargtype
                    break
                except Exception   noqa E722
                    pass
            if isinstanceopenapiurl str
                raise ValueErrorfUnable to parse spec from source openapiurl
        openaifns callapifn  openapispectoopenaifnopenapiurl
        print
            ftestpluginname functions  jsondumpsopenaifns indent2
        
        return openaifns callapifn

    openaifns callapifn  openapitofunctionsandcallapifn

    llm  ChatOpenAI
        modelgpt35turbo0613
    
    llmchain  LLMChain
        llmllm
        promptChatPromptTemplatefromtemplatequery
        llmkwargsfunctions openaifns
        outputparserJsonOutputFunctionsParserargsonlyFalse
        outputkeyfunction
        verboseTrue
         llmkwargs or 
    

    def estimatetokenss str  int
        return lens  2

    def tokenstocharstokens int  int
        return tokens  2

    functionstokens  estimatetokensjsondumpsopenaifns

    try
         MESSAGES TO PROMPT
         if there is a message with role system then pop it iterate through all messages to find it
        systemmessage  
        for message in testpluginmessages
            if messagerole  system
                systemmessage  system     messagecontent  n
                testpluginmessagesremovemessage
                break

         printsystemmessage  systemmessage
         Combine messages into one string
        messagesaggregate  njoin
            
                fmessagerole messagecontent
                for message in testpluginmessages
            
        
        completemessagesaggregatetokens  estimatetokens
            systemmessage  messagesaggregate
        
         printcompletemessagesaggregatetokens  completemessagesaggregatetokens
         printfunctionstokens  functionstokens
        messagestruncationoffset  tokenstochars
            maxcompletemessagesaggregatetokens  functionstokens  4096 0
        
         printmessagestruncationoffset  messagestruncationoffset
        messagesaggregate  messagesaggregatemessagestruncationoffset

         TODO temp fix to prevent collation of messages
        if messagestruncationoffset  0
            messagesaggregate  userassistant   messagesaggregate

        completemessagesaggregate  systemmessage  messagesaggregate
         printcompletemessagesaggregate  completemessagesaggregate
         printfinal length  estimatetokenscompletemessagesaggregate

         Replace prompt with messageAggregate
        llmchainout  llmchainruncompletemessagesaggregate
        printUsing plugin   testpluginname
    except KeyError as e
         if error includes functioncall then it is not a plugin function
        if functioncall in stre
            raise ValueErrorNot a plugin function
        else
            raise e
    if llmchainoutname not in functionname for function in openaifns
        raise ValueErrorNot a plugin function

     EDGE CASE
    def removeemptyfromdictinputdict
        cleaneddict  
        for k v in inputdictitems
            if isinstancev dict
                v  removeemptyfromdictv
            if v and v  none   only add to cleaneddict if v is not empty
                cleaneddictk  v
        return cleaneddict

    llmchainoutarguments  removeemptyfromdictllmchainoutarguments
    print
        ftestpluginname llmchainout 
        jsondumpsllmchainout indent2
    

     make the api call
    def requestchainname arguments
        res  callapifnname arguments headersNone paramsNone
        return res

    requestout  requestchainllmchainout
    printrequestout  requestout
    jsonresponse  requestoutjson

    def truncatejsonrootjsonresponse truncateto
        return jsonresponse

    if testplugintruncate
        truncateto  
            testplugintruncate
            if not isinstancetestplugintruncate bool
            else None
        
        if truncateto is None
            tokenslack  56  300
            truncateto  
                4096
                 estimatetokensjsondumpstestpluginmessages1
                 tokenslack
                 0
            
        jsonresponse  truncatejsonrootjsonresponse truncateto

    print
        ftestpluginname jsonresponse 
        jsondumpsjsonresponse indent2
    
    try
        return 
            role function
            name llmchainoutname
            content jsondumpsjsonresponse
        
    except jsondecoderJSONDecodeError
        raise jsondecoderJSONDecodeError
            fAPI call failed API returned the following nonJSON responsenresponsecontent
        

When I run it I get the following response 

        requestout  requestchainllmchainout
        printrequestout  requestout
       jsonresponse  requestoutjson

teststestopenpluginpy153
                                                                                                                

self  Response 500 kwargs  

    def jsonself kwargs
        rReturns the jsonencoded content of a response if any

        param kwargs Optional arguments that jsonloads takes
        raises requestsexceptionsJSONDecodeError If the response body does not
            contain valid json
        

        if not selfencoding and selfcontent and lenselfcontent  3
             No encoding set JSON RFC 4627 section 3 states we should expect
             UTF8 16 or 32 Detect which one to use If the detection or
             decoding fails fall back to selftext using charsetnormalizer to make
             a best guess
            encoding  guessjsonutfselfcontent
            if encoding is not None
                try
                    return complexjsonloadsselfcontentdecodeencoding kwargs
                except UnicodeDecodeError
                     Wrong UTF codec detected usually because its not UTF8
                     but some other 8bit codec  This is an RFC violation
                     and the server didnt bother to tell us what codec was
                     used
                    pass
                except JSONDecodeError as e
                    raise RequestsJSONDecodeErroremsg edoc epos

        try
            return complexjsonloadsselftext kwargs
        except JSONDecodeError as e
             Catch JSONrelated errors and raise as requestsJSONDecodeError
             This aliases jsonJSONDecodeError and simplejsonJSONDecodeError
           raise RequestsJSONDecodeErroremsg edoc epos
E           requestsexceptionsJSONDecodeError Expecting value line 1 column 1 char 0

venvlibsitepackagesrequestsmodelspy975 JSONDecodeError
 Captured stdout call  
askyourpdf openapiurl  httpschatwithpdfsdanioopenapiyaml
askyourpdf functions  
  
    name loadPdf
    description Load a PDF document
    parameters 
      type object
      properties 
        json 
          properties 
            pdfurl 
              type string
              schemaformat uri
              description The temporary URL of the PDF document to load
            
          
          type object
          required 
            pdfurl
          
        
      
    
  
  
    name queryPdf
    description Query a loaded PDF document
    parameters 
      type object
      properties 
        json 
          properties 
            query 
              type string
              description The query or question to ask based on the PDF document
            
            pdfurl 
              type string
              schemaformat uri
              description The temporary URL of the PDF document that is already loaded
            
          
          type object
          required 
            query
            pdfurl
          
        
      
    
  



 Entering new LLMChain chain
Prompt after formatting
Human user summarize this pdf httpseformscomdownload201801NonDisclosureAgreementTemplatepdf

 Finished chain
Using plugin askyourpdf
askyourpdf llmchainout  
  name loadPdf
  arguments 
    json 
      pdfurl httpseformscomdownload201801NonDisclosureAgreementTemplatepdf
    
  

requestout  Response 500","currently code : oplangchain.chains.llm import LLMChain oplangchain.chat_models.openai import ChatOpenAI oplangchain.output_parsers.openai_functions import JsonOutputFunctionsParser oplangchain.prompts.chat import ChatPromptTemplate oplangchain.chains.openai_functions.openapi import get_openapi_chain oplangchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn oplangchain.utilities.openapi import OpenAPISpec typing import Union import json # def test_tmp ( ) - > None : # chain = get_openapi_chain ( # `` https : //www.klarna.com/us/shopping/public/openai/v0/api-docs/ '' # ) # res = chain.run ( `` options men 's large blue button shirt '' ) # # assert res object includes key products # assert `` products '' res test_plugin = { `` name '' : `` askyourpdf '' , `` openapi_url '' : `` https : //chatwithpdf.sdan.io/openapi.yaml '' , `` messages '' : [ { `` role '' : `` user '' , `` content '' : `` summarize pdf https : //eforms.com/download/2018/01/Non-Disclosure-Agreement-Template.pdf '' , } ] , `` truncate '' : False , } def test_full_suite ( ) - > None : def openapi_to_functions_and_call_api_fn ( ) : openapi_url = test_plugin [ `` openapi_url '' ] print ( f '' \ '' { test_plugin [ 'name ' ] } \ '' openapi_url : `` , openapi_url ) openapi_url == None : raise ValueError ( `` OpenAPI URL found manifest '' ) isinstance ( openapi_url , Union [ OpenAPISpec , str ] ) : conversion ( # specs get stuck loop OpenAPISpec.from_url , OpenAPISpec.from_file , OpenAPISpec.from_text , ) : try : openapi_url = conversion ( openapi_url ) # type : ignore [ arg-type ] break except Exception : # noqa : E722 pass isinstance ( openapi_url , str ) : raise ValueError ( f '' Unable parse spec source { openapi_url } '' ) openai_fns , call_api_fn = openapi_spec_to_openai_fn ( openapi_url ) print ( f '' \ '' { test_plugin [ 'name ' ] } \ '' functions : `` , json.dumps ( openai_fns , indent=2 ) ) return openai_fns , call_api_fn openai_fns , call_api_fn = openapi_to_functions_and_call_api_fn ( ) llm = ChatOpenAI ( model= '' gpt-3.5-turbo-0613 '' , ) llm_chain = LLMChain ( llm=llm , prompt=ChatPromptTemplate.from_template ( `` { query } '' ) , llm_kwargs= { `` functions '' : openai_fns } , output_parser=JsonOutputFunctionsParser ( args_only=False ) , output_key= '' function '' , verbose=True , # * * ( llm_kwargs { } ) , ) def estimate_tokens ( : str ) - > int : return len ( ) // 2 def tokens_to_chars ( tokens : int ) - > int : return tokens * 2 functions_tokens = estimate_tokens ( json.dumps ( openai_fns ) ) try : # MESSAGES PROMPT # message role system pop , iterate messages find system_message = `` '' message test_plugin [ `` messages '' ] : message [ `` role '' ] == `` system '' : system_message = `` system '' + `` : `` + message [ `` content '' ] + `` \n '' test_plugin [ `` messages '' ] .remove ( message ) break # print ( `` system_message : `` , system_message ) # Combine messages one string messages_aggregate = `` \n '' .join ( [ f '' { message [ 'role ' ] } : { message [ 'content ' ] } '' message test_plugin [ `` messages '' ] ] ) complete_messages_aggregate_tokens = estimate_tokens ( system_message + messages_aggregate ) # print ( `` complete_messages_aggregate_tokens : `` , complete_messages_aggregate_tokens ) # print ( `` functions_tokens : `` , functions_tokens ) messages_truncation_offset = tokens_to_chars ( max ( complete_messages_aggregate_tokens + functions_tokens - 4096 , 0 ) ) # print ( `` messages_truncation_offset : `` , messages_truncation_offset ) messages_aggregate = messages_aggregate [ messages_truncation_offset : ] # TODO : temp fix prevent collation messages messages_truncation_offset > 0 : messages_aggregate = `` user/assistant : `` + messages_aggregate complete_messages_aggregate = system_message + messages_aggregate # print ( `` complete_messages_aggregate : `` , complete_messages_aggregate ) # print ( `` final length : `` , estimate_tokens ( complete_messages_aggregate ) ) # Replace prompt messageAggregate llm_chain_out = llm_chain.run ( complete_messages_aggregate ) print ( `` Using plugin : `` + test_plugin [ `` name '' ] ) except KeyError e : # error includes `` function_call '' plugin function `` function_call '' str ( e ) : raise ValueError ( `` plugin function '' ) else : raise e llm_chain_out [ `` name '' ] [ function [ `` name '' ] function openai_fns ] : raise ValueError ( `` plugin function '' ) # EDGE CASE def remove_empty_from_dict ( input_dict ) : cleaned_dict = { } k , v input_dict.items ( ) : isinstance ( v , dict ) : v = remove_empty_from_dict ( v ) v v ! = `` none '' : # add cleaned_dict v empty cleaned_dict [ k ] = v return cleaned_dict llm_chain_out [ `` arguments '' ] = remove_empty_from_dict ( llm_chain_out [ `` arguments '' ] ) print ( f '' \ '' { test_plugin [ 'name ' ] } \ '' llm_chain_out : `` , json.dumps ( llm_chain_out , indent=2 ) , ) # make api call def request_chain ( name , arguments ) : res = call_api_fn ( name , arguments , headers=None , params=None ) return res request_out = request_chain ( * * llm_chain_out ) print ( `` request_out : `` , request_out ) json_response = request_out.json ( ) def truncate_json_root ( json_response , truncate_to ) : return json_response test_plugin [ `` truncate '' ] : truncate_to = ( test_plugin [ `` truncate '' ] isinstance ( test_plugin [ `` truncate '' ] , bool ) else None ) truncate_to None : token_slack = 56 + 300 truncate_to = ( 4096 - estimate_tokens ( json.dumps ( test_plugin [ `` messages '' ] [ -1 ] ) ) - token_slack - 0 ) json_response = truncate_json_root ( json_response , truncate_to ) print ( f '' \ '' { test_plugin [ 'name ' ] } \ '' json_response : `` , json.dumps ( json_response , indent=2 ) , ) try : return { `` role '' : `` function '' , `` name '' : llm_chain_out [ `` name '' ] , `` content '' : json.dumps ( json_response ) , } except json.decoder.JSONDecodeError : raise json.decoder.JSONDecodeError ( f '' API call failed , API returned following non-JSON response : \n { response.content } '' ) run get following response ... request_out = request_chain ( * * llm_chain_out ) print ( `` request_out : `` , request_out ) > json_response = request_out.json ( ) tests\test_openplugin.py:153 : _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = < Response [ 500 ] > , kwargs = { } def json ( self , * * kwargs ) : r '' '' '' Returns json-encoded content response , . : param \ * \ * kwargs : Optional arguments `` json.loads `` takes . : raises requests.exceptions.JSONDecodeError : response body contain valid json. `` '' '' self.encoding self.content len ( self.content ) > 3 : # encoding set . JSON RFC 4627 section 3 states expect # UTF-8 , -16 -32 . Detect one use ; detection # decoding fails , fall back ` self.text ` ( using charset_normalizer make # best guess ) . encoding = guess_json_utf ( self.content ) encoding None : try : return complexjson.loads ( self.content.decode ( encoding ) , * * kwargs ) except UnicodeDecodeError : # Wrong UTF codec detected ; usually 's UTF-8 # 8-bit codec . RFC violation , # server n't bother tell us codec * * # used . pass except JSONDecodeError e : raise RequestsJSONDecodeError ( e.msg , e.doc , e.pos ) try : return complexjson.loads ( self.text , * * kwargs ) except JSONDecodeError e : # Catch JSON-related errors raise requests.JSONDecodeError # aliases json.JSONDecodeError simplejson.JSONDecodeError > raise RequestsJSONDecodeError ( e.msg , e.doc , e.pos ) E requests.exceptions.JSONDecodeError : Expecting value : line 1 column 1 ( char 0 ) .. \ .. \venv\lib\site-packages\requests\models.py:975 : JSONDecodeError -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Captured stdout call -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- '' askyourpdf '' openapi_url : https : //chatwithpdf.sdan.io/openapi.yaml '' askyourpdf '' functions : [ { `` name '' : `` loadPdf '' , `` description '' : `` Load PDF document '' , `` parameters '' : { `` type '' : `` object '' , `` properties '' : { `` json '' : { `` properties '' : { `` pdf_url '' : { `` type '' : `` string '' , `` schema_format '' : `` uri '' , `` description '' : `` temporary URL PDF document load . '' } } , `` type '' : `` object '' , `` required '' : [ `` pdf_url '' ] } } } } , { `` name '' : `` queryPdf '' , `` description '' : `` Query loaded PDF document '' , `` parameters '' : { `` type '' : `` object '' , `` properties '' : { `` json '' : { `` properties '' : { `` query '' : { `` type '' : `` string '' , `` description '' : `` query question ask based PDF document . '' } , `` pdf_url '' : { `` type '' : `` string '' , `` schema_format '' : `` uri '' , `` description '' : `` temporary URL PDF document already loaded . '' } } , `` type '' : `` object '' , `` required '' : [ `` query '' , `` pdf_url '' ] } } } } ] > Entering new LLMChain chain ... Prompt formatting : Human : user : summarize pdf https : //eforms.com/download/2018/01/Non-Disclosure-Agreement-Template.pdf > Finished chain . Using plugin : askyourpdf '' askyourpdf '' llm_chain_out : { `` name '' : `` loadPdf '' , `` arguments '' : { `` json '' : { `` pdf_url '' : `` https : //eforms.com/download/2018/01/Non-Disclosure-Agreement-Template.pdf '' } } } request_out : < Response [ 500 ] >"
ivansglazunov,Browse httpsgithubcomdeepfoundationdeeplinksissues2 and ask all questions that are required to clarify the task,Browse https : //github.com/deep-foundation/deeplinks/issues/2 ask questions required clarify task .
holmesworcester,Im using TouchableOpacity in React but opacity is lightened even when the user is dragging a list which is not standard behavior Why is this happening and how do I fix this,"'m using TouchableOpacity React , opacity lightened even user dragging list , standard behavior . happening fix ?"
alltheseas,"Im trying to understand this set reconciliation protocol can you help me I will paste each section one at a time and we can step through it

This repo contains the protocol specification reference implementations and tests for the negentropy setreconcilliation protocol

 TOC FOLLOWS 
 START OF TOC 
 Introductionintroduction
 Protocolprotocol
   Data Requirementsdatarequirements
   Setupsetup
   Alternating Messagesalternatingmessages
   Algorithmalgorithm
 Definitionsdefinitions
   Varintvarint
   Boundbound
   Rangerange
   Messagemessage
 Analysisanalysis
 Reference Implementation APIsreferenceimplementationapis
   Cc
   Javascriptjavascript
 Implementation Enhancementsimplementationenhancements
   Deferred Range Processingdeferredrangeprocessing
   Precomputingprecomputing
 UseCasesusecases
 Copyrightcopyright
 END OF TOC 


 Introduction

Set reconcilliation supports the replication or syncing of datasets either because they were created independently or because they have drifted out of sync because of downtime network partitions misconfigurations etc In the latter case detecting and fixing these inconsistencies is sometimes called antientropy repairhttpsdocsdatastaxcomencassandraoss3xcassandraoperationsopsRepairNodesManualRepairhtml

Suppose two participants on a network each have a set of records that they have collected independently Setreconcilliation efficiently determines which records one side has that the other side doesnt and vice versa After the records that are missing have been determined this information can be used to transfer the missing data items The actual transfer is external to the negentropy protocol

Although there are many ways to do set reconcilliation negentropy is based on Aljoscha Meyers methodhttpsgithubcomAljoschaMeyersetreconciliation which has the advantage of being simple to explain and implement","'m trying understand set reconciliation protocol . help ? paste section one time step : repo contains protocol specification , reference implementations , tests negentropy set-reconcilliation protocol . < ! -- TOC FOLLOWS -- > < ! -- START TOC -- > * [ Introduction ] ( # introduction ) * [ Protocol ] ( # protocol ) * [ Data Requirements ] ( # data-requirements ) * [ Setup ] ( # setup ) * [ Alternating Messages ] ( # alternating-messages ) * [ Algorithm ] ( # algorithm ) * [ Definitions ] ( # definitions ) * [ Varint ] ( # varint ) * [ Bound ] ( # bound ) * [ Range ] ( # range ) * [ Message ] ( # message ) * [ Analysis ] ( # analysis ) * [ Reference Implementation APIs ] ( # reference-implementation-apis ) * [ C++ ] ( # c ) * [ Javascript ] ( # javascript ) * [ Implementation Enhancements ] ( # implementation-enhancements ) * [ Deferred Range Processing ] ( # deferred-range-processing ) * [ Pre-computing ] ( # pre-computing ) * [ Use-Cases ] ( # use-cases ) * [ Copyright ] ( # copyright ) < ! -- END TOC -- > # # Introduction Set reconcilliation supports replication syncing data-sets , either created independently , drifted sync downtime , network partitions , misconfigurations , etc . latter case , detecting fixing inconsistencies sometimes called [ anti-entropy repair ] ( https : //docs.datastax.com/en/cassandra-oss/3.x/cassandra/operations/opsRepairNodesManualRepair.html ) . Suppose two participants network set records collected independently . Set-reconcilliation efficiently determines records one side side n't , vice versa . records missing determined , information used transfer missing data items . actual transfer external negentropy protocol . Although many ways set reconcilliation , negentropy based [ Aljoscha Meyer 's method ] ( https : //github.com/AljoschaMeyer/set-reconciliation ) , advantage simple explain implement ."
ArdenHide,"Hi You as a best programmer in the world can please do globally refactor this library
Source code
using NethereumWeb3
using NethereumWeb3Accounts
using NethereumJsonRpcClient

namespace RPCCoreUtility

public abstract class Web3Base

    protected readonly IWeb3 web3

    protected Web3BaseIWeb3 web3
    
        thisweb3  web3
    

    public static IWeb3 CreateWeb3string rpcConnection Account account
    
        var client  new RpcClientnew UrirpcConnection
        return new Web3account client
    

namespace RPCCoreTypes

public enum ActionType

    Read
    Write

using NethereumWeb3
using RPCCoreUtility
using NethereumRPCEthDTOs

namespace RPCCoreTransaction

public class TransactionSigner  Web3Base

    public TransactionSignerIWeb3 web3  baseweb3  

    public virtual string SignTransactionTransactionInput transaction 
        web3TransactionManagerAccountTransactionManagerSignTransactionAsynctransaction
            GetAwaiter
            GetResult

using NethereumWeb3
using RPCCoreUtility

namespace RPCCoreTransaction

public class TransactionSender  Web3Base

    public TransactionSenderIWeb3 web3  baseweb3  

    public virtual string SendTransactionstring signedTransaction 
        web3EthTransactionsSendRawTransactionSendRequestAsyncsignedTransaction
            GetAwaiter
            GetResult

using NethereumHdWallet

namespace RPCCoreProviders

public static class WalletProvider

    public static Wallet GetWalletIMnemonicProvider mnemonicProvider 
        newwords mnemonicProviderGetMnemonic seedPassword stringEmpty

namespace RPCCoreProviders

public interface IMnemonicProvider

    string GetMnemonic

using RPCCoreManagers
using NethereumHexHexTypes
using NethereumWeb3Accounts

namespace RPCCoreProviders

public class AccountProvider

    public Account Account  get set 
    public string AccountAddress  get set 
    
    public AccountProviderIMnemonicProvider mnemonicProvider int accountId uint chainId
    
        var accountManager  new AccountManagermnemonicProvider
        Account  accountManagerGetAccountaccountId new HexBigIntegerchainId
        AccountAddress  AccountAddress
    
using RPCCoreTypes
using NethereumHexHexTypes
using RPCCoreValidation
using FluentValidation

namespace RPCCoreModels

public class RpcRequest

    public ActionType ActionType  get private set 
    public string RpcUrl  get private set 
    public int AccountId  get private set 
    public uint ChainId  get private set 
    public string To  get private set 
    public HexBigInteger Value  get private set   null
    public GasSettings GasSettings  get private set   null
    public string Data  get private set 

     summary
     Initialize see crefRpcRequest object for see crefActionTypeRead operation
     summary
    public RpcRequeststring rpcUrl string to string data
    
        ActionType  ActionTypeRead
        RpcUrl  rpcUrl
        To  to
        Data  data

        new ReadRequestValidatorValidateAndThrowthis
    

     summary
     Initialize see crefRpcRequest object for see crefActionTypeWrite operation
     summary
    public RpcRequest
        string rpcUrl
        int accountId
        uint chainId
        string to
        HexBigInteger value
        GasSettings gasSettings
        string data  null
    
    
        ActionType  ActionTypeWrite
        RpcUrl  rpcUrl
        AccountId  accountId
        ChainId  chainId
        To  to
        Value  value
        GasSettings  gasSettings
        Data  data  stringEmpty

        new WriteRequestValidatorValidateAndThrowthis
    

using NewtonsoftJson
using NewtonsoftJsonLinq

namespace RPCCoreModels

public class ReadRpcRequest

    JsonPropertyjsonrpc
    public string JsonRpc  get set 

    JsonPropertymethod
    public string Method  get set 

    JsonPropertyparams
    public JArray Params  get set 

    JsonPropertyid
    public int Id  get set 

    public ReadRpcRequeststring to string data
    
        JsonRpc  20
        Method  ethcall
        Params  new JArray
        
            new JObject
            
                 to to 
                 data data 
            
            latest
        
        Id  0
    

namespace RPCCoreModels

public class GasSettings

    public uint MaxGasLimit  get set 
    public uint MaxGweiGasPrice  get set 

    public GasSettingsuint maxGasLimit uint maxGweiGasPrice
    
        MaxGasLimit  maxGasLimit
        MaxGweiGasPrice  maxGweiGasPrice
    

using RPCCoreProviders
using NethereumHdWallet
using NethereumHexHexTypes
using NethereumWeb3Accounts

namespace RPCCoreManagers

public class AccountManager

    private readonly Wallet wallet

    public AccountManagerIMnemonicProvider mnemonicProvider
    
        wallet  WalletProviderGetWalletmnemonicProvider
    

    public Account GetAccountint id HexBigInteger chainId 
        walletGetAccountid chainId

using NethereumWeb3
using RPCCoreUtility
using NethereumHexHexTypes

namespace RPCCoreGas

public class GasPricer  Web3Base

    public GasPricerIWeb3 web3  baseweb3  

    public HexBigInteger GetCurrentWeiGasPrice 
        web3EthGasPriceSendRequestAsync
            GetAwaiter
            GetResult

using NethereumUtil
using SystemNumerics
using RPCCoreModels
using NethereumRPCEthDTOs
using RPCCoreGasExceptions

namespace RPCCoreGas

public class GasLimitChecker

    private readonly TransactionInput transactionInput
    private readonly GasSettings gasSettings

    public GasLimitCheckerTransactionInput transactionInput GasSettings gasSettings
    
        thistransactionInput  transactionInput
        thisgasSettings  gasSettings
    

    public GasLimitChecker CheckAndThrow 
        CheckGasLimit
        CheckGasPrice

    private GasLimitChecker CheckGasLimit
    
        if transactionInputGasValue  gasSettingsMaxGasLimit
        
            throw new GasLimitExceededException
        
        return this
    

    private GasLimitChecker CheckGasPrice
    
        BigInteger maxWeiGasPrice  ConvertGweiToWeigasSettingsMaxGweiGasPrice
        if transactionInputGasPriceValue  maxWeiGasPrice
        
            throw new GasPriceExceededException
        
        return this
    

    private static BigInteger ConvertGweiToWeidecimal gweiValue 
        UnitConversionConvertToWeigweiValue UnitConversionEthUnitGwei

using NethereumWeb3
using RPCCoreUtility
using NethereumHexHexTypes
using NethereumRPCEthDTOs

namespace RPCCoreGas

public class GasEstimator  Web3Base

    public const int GasBufferFactor  10

    public GasEstimatorIWeb3 web3  baseweb3  

    public TransactionInput EstimateGasTransactionInput transaction
    
        var gasEstimate  web3EthTransactionManagerEstimateGasAsynctransaction
            GetAwaiter
            GetResult

        var bufferOfGasLimit  new HexBigIntegergasEstimateValue  GasBufferFactor

        transactionGas  new HexBigIntegergasEstimateValue  bufferOfGasLimitValue

        return transaction
    

using SystemRuntimeSerialization

namespace RPCCoreGasExceptions

Serializable
public class GasPriceExceededException  Exception

    public GasPriceExceededException  baseGas price exceeded  

    protected GasPriceExceededExceptionSerializationInfo info StreamingContext context
         baseinfo context
     

    public override void GetObjectDataSerializationInfo info StreamingContext context
    
        baseGetObjectDatainfo context
    

using SystemRuntimeSerialization

namespace RPCCoreGasExceptions

Serializable
public class GasLimitExceededException  Exception

    public GasLimitExceededException  baseGas limit exceeded  

    protected GasLimitExceededExceptionSerializationInfo info StreamingContext context
         baseinfo context
     

    public override void GetObjectDataSerializationInfo info StreamingContext context
    
        baseGetObjectDatainfo context
    

namespace RPCCoreContractIO

public interface IContractIO

    string RunContractAction

using RPCCoreGas
using NethereumUtil
using NethereumWeb3
using SystemNumerics
using RPCCoreModels
using RPCCoreUtility
using RPCCoreProviders
using RPCCoreTransaction
using NethereumRPCEthDTOs
using NethereumHexHexTypes

namespace RPCCoreContractIO

public class ContractRpcWriter  IContractIO

    private readonly RpcRequest request
    private readonly IMnemonicProvider mnemonicProvider
    private string accountAddress

    public IWeb3 Web3  get set 

    public ContractRpcWriterRpcRequest request IMnemonicProvider mnemonicProvider
    
        thisrequest  request
        thismnemonicProvider  mnemonicProvider
    

    public virtual string RunContractAction
    
        Web3  InitializeWeb3

        var transaction  new GasEstimatorWeb3EstimateGasCreateActionInput
        transactionGasPrice  new GasPricerWeb3GetCurrentWeiGasPrice

        new GasLimitCheckertransaction requestGasSettingsCheckAndThrow

        var signedTransaction  new TransactionSignerWeb3SignTransactiontransaction
        return new TransactionSenderWeb3SendTransactionsignedTransaction
    

    public IWeb3 InitializeWeb3
    
        var accountProvider  new AccountProvidermnemonicProvider requestAccountId requestChainId
        accountAddress  accountProviderAccountAddress
        return Web3BaseCreateWeb3requestRpcUrl accountProviderAccount
    

    private TransactionInput CreateActionInput 
        newrequestData requestTo requestValue
        
            ChainId  new HexBigIntegerrequestChainId
            From  accountAddress
        

using FlurlHttp
using RPCCoreModels
using NewtonsoftJsonLinq

namespace RPCCoreContractIO

public class ContractRpcReader  IContractIO

    private readonly RpcRequest request

    public ContractRpcReaderRpcRequest request
    
        thisrequest  request
    

    public virtual string RunContractAction
    
        var input  CreateActionInput

        var response  requestRpcUrlPostJsonAsyncinput
            GetAwaiter
            GetResult

        return ParseResponseresponse
    

    private ReadRpcRequest CreateActionInput 
        newrequestTo requestData

    private static string ParseResponseIFlurlResponse flurlResponse
    
        var response  flurlResponseGetJsonAsyncJObject
            GetAwaiter
            GetResult

        return responseresultToString  throw new KeyNotFoundExceptionResponse does not contain the key result
    

using RPCCoreTypes
using RPCCoreModels
using RPCCoreProviders

namespace RPCCoreContractIO

public class ContractRpc

    private readonly IMnemonicProvider mnemonicProvider

    public ContractRpcIMnemonicProvider mnemonicProvider
    
        thismnemonicProvider  mnemonicProvider
    

    public virtual string ExecuteActionRpcRequest request 
        GetContractIOrequestRunContractAction

    private IContractIO GetContractIORpcRequest request 
        requestActionType  ActionTypeRead 
        new ContractRpcReaderrequest 
        new ContractRpcWriterrequest mnemonicProvider

","Hi ! best programmer world , please globally refactor library Source code : using Nethereum.Web3 ; using Nethereum.Web3.Accounts ; using Nethereum.JsonRpc.Client ; namespace RPC.Core.Utility ; public abstract class Web3Base { protected readonly IWeb3 web3 ; protected Web3Base ( IWeb3 web3 ) { this.web3 = web3 ; } public static IWeb3 CreateWeb3 ( string rpcConnection , Account account ) { var client = new RpcClient ( new Uri ( rpcConnection ) ) ; return new Web3 ( account , client ) ; } } namespace RPC.Core.Types ; public enum ActionType { Read , Write } using Nethereum.Web3 ; using RPC.Core.Utility ; using Nethereum.RPC.Eth.DTOs ; namespace RPC.Core.Transaction ; public class TransactionSigner : Web3Base { public TransactionSigner ( IWeb3 web3 ) : base ( web3 ) { } public virtual string SignTransaction ( TransactionInput transaction ) = > web3.TransactionManager.Account.TransactionManager.SignTransactionAsync ( transaction ) .GetAwaiter ( ) .GetResult ( ) ; } using Nethereum.Web3 ; using RPC.Core.Utility ; namespace RPC.Core.Transaction ; public class TransactionSender : Web3Base { public TransactionSender ( IWeb3 web3 ) : base ( web3 ) { } public virtual string SendTransaction ( string signedTransaction ) = > web3.Eth.Transactions.SendRawTransaction.SendRequestAsync ( signedTransaction ) .GetAwaiter ( ) .GetResult ( ) ; } using Nethereum.HdWallet ; namespace RPC.Core.Providers ; public static class WalletProvider { public static Wallet GetWallet ( IMnemonicProvider mnemonicProvider ) = > new ( words : mnemonicProvider.GetMnemonic ( ) , seedPassword : string.Empty ) ; } namespace RPC.Core.Providers ; public interface IMnemonicProvider { string GetMnemonic ( ) ; } using RPC.Core.Managers ; using Nethereum.Hex.HexTypes ; using Nethereum.Web3.Accounts ; namespace RPC.Core.Providers ; public class AccountProvider { public Account Account { get ; set ; } public string AccountAddress { get ; set ; } public AccountProvider ( IMnemonicProvider mnemonicProvider , int accountId , uint chainId ) { var accountManager = new AccountManager ( mnemonicProvider ) ; Account = accountManager.GetAccount ( accountId , new HexBigInteger ( chainId ) ) ; AccountAddress = Account.Address ; } } using RPC.Core.Types ; using Nethereum.Hex.HexTypes ; using RPC.Core.Validation ; using FluentValidation ; namespace RPC.Core.Models ; public class RpcRequest { public ActionType ActionType { get ; private set ; } public string RpcUrl { get ; private set ; } public int AccountId { get ; private set ; } public uint ChainId { get ; private set ; } public string { get ; private set ; } public HexBigInteger Value { get ; private set ; } = null ! ; public GasSettings GasSettings { get ; private set ; } = null ! ; public string Data { get ; private set ; } /// < summary > /// Initialize < see cref= '' RpcRequest '' / > object < see cref= '' ActionType.Read '' / > operation . /// < /summary > public RpcRequest ( string rpcUrl , string , string data ) { ActionType = ActionType.Read ; RpcUrl = rpcUrl ; = ; Data = data ; new ReadRequestValidator ( ) .ValidateAndThrow ( ) ; } /// < summary > /// Initialize < see cref= '' RpcRequest '' / > object < see cref= '' ActionType.Write '' / > operation . /// < /summary > public RpcRequest ( string rpcUrl , int accountId , uint chainId , string , HexBigInteger value , GasSettings gasSettings , string ? data = null ) { ActionType = ActionType.Write ; RpcUrl = rpcUrl ; AccountId = accountId ; ChainId = chainId ; = ; Value = value ; GasSettings = gasSettings ; Data = data ? ? string.Empty ; new WriteRequestValidator ( ) .ValidateAndThrow ( ) ; } } using Newtonsoft.Json ; using Newtonsoft.Json.Linq ; namespace RPC.Core.Models ; public class ReadRpcRequest { [ JsonProperty ( `` jsonrpc '' ) ] public string JsonRpc { get ; set ; } [ JsonProperty ( `` method '' ) ] public string Method { get ; set ; } [ JsonProperty ( `` params '' ) ] public JArray Params { get ; set ; } [ JsonProperty ( `` id '' ) ] public int Id { get ; set ; } public ReadRpcRequest ( string , string data ) { JsonRpc = `` 2.0 '' ; Method = `` eth_call '' ; Params = new JArray ( ) { new JObject ( ) { { `` '' , } , { `` data '' , data } } , `` latest '' } ; Id = 0 ; } } namespace RPC.Core.Models ; public class GasSettings { public uint MaxGasLimit { get ; set ; } public uint MaxGweiGasPrice { get ; set ; } public GasSettings ( uint maxGasLimit , uint maxGweiGasPrice ) { MaxGasLimit = maxGasLimit ; MaxGweiGasPrice = maxGweiGasPrice ; } } using RPC.Core.Providers ; using Nethereum.HdWallet ; using Nethereum.Hex.HexTypes ; using Nethereum.Web3.Accounts ; namespace RPC.Core.Managers ; public class AccountManager { private readonly Wallet wallet ; public AccountManager ( IMnemonicProvider mnemonicProvider ) { wallet = WalletProvider.GetWallet ( mnemonicProvider ) ; } public Account GetAccount ( int id , HexBigInteger chainId ) = > wallet.GetAccount ( id , chainId ) ; } using Nethereum.Web3 ; using RPC.Core.Utility ; using Nethereum.Hex.HexTypes ; namespace RPC.Core.Gas ; public class GasPricer : Web3Base { public GasPricer ( IWeb3 web3 ) : base ( web3 ) { } public HexBigInteger GetCurrentWeiGasPrice ( ) = > web3.Eth.GasPrice.SendRequestAsync ( ) .GetAwaiter ( ) .GetResult ( ) ; } using Nethereum.Util ; using System.Numerics ; using RPC.Core.Models ; using Nethereum.RPC.Eth.DTOs ; using RPC.Core.Gas.Exceptions ; namespace RPC.Core.Gas ; public class GasLimitChecker { private readonly TransactionInput transactionInput ; private readonly GasSettings gasSettings ; public GasLimitChecker ( TransactionInput transactionInput , GasSettings gasSettings ) { this.transactionInput = transactionInput ; this.gasSettings = gasSettings ; } public GasLimitChecker CheckAndThrow ( ) = > CheckGasLimit ( ) .CheckGasPrice ( ) ; private GasLimitChecker CheckGasLimit ( ) { ( transactionInput.Gas.Value > gasSettings.MaxGasLimit ) { throw new GasLimitExceededException ( ) ; } return ; } private GasLimitChecker CheckGasPrice ( ) { BigInteger maxWeiGasPrice = ConvertGweiToWei ( gasSettings.MaxGweiGasPrice ) ; ( transactionInput.GasPrice.Value > maxWeiGasPrice ) { throw new GasPriceExceededException ( ) ; } return ; } private static BigInteger ConvertGweiToWei ( decimal gweiValue ) = > UnitConversion.Convert.ToWei ( gweiValue , UnitConversion.EthUnit.Gwei ) ; } using Nethereum.Web3 ; using RPC.Core.Utility ; using Nethereum.Hex.HexTypes ; using Nethereum.RPC.Eth.DTOs ; namespace RPC.Core.Gas ; public class GasEstimator : Web3Base { public const int GasBufferFactor = 10 ; public GasEstimator ( IWeb3 web3 ) : base ( web3 ) { } public TransactionInput EstimateGas ( TransactionInput transaction ) { var gasEstimate = web3.Eth.TransactionManager.EstimateGasAsync ( transaction ) .GetAwaiter ( ) .GetResult ( ) ; var bufferOfGasLimit = new HexBigInteger ( gasEstimate.Value / GasBufferFactor ) ; transaction.Gas = new HexBigInteger ( gasEstimate.Value + bufferOfGasLimit.Value ) ; return transaction ; } } using System.Runtime.Serialization ; namespace RPC.Core.Gas.Exceptions ; [ Serializable ] public class GasPriceExceededException : Exception { public GasPriceExceededException ( ) : base ( `` Gas price exceeded . '' ) { } protected GasPriceExceededException ( SerializationInfo info , StreamingContext context ) : base ( info , context ) { } public override void GetObjectData ( SerializationInfo info , StreamingContext context ) { base.GetObjectData ( info , context ) ; } } using System.Runtime.Serialization ; namespace RPC.Core.Gas.Exceptions ; [ Serializable ] public class GasLimitExceededException : Exception { public GasLimitExceededException ( ) : base ( `` Gas limit exceeded . '' ) { } protected GasLimitExceededException ( SerializationInfo info , StreamingContext context ) : base ( info , context ) { } public override void GetObjectData ( SerializationInfo info , StreamingContext context ) { base.GetObjectData ( info , context ) ; } } namespace RPC.Core.ContractIO ; public interface IContractIO { string RunContractAction ( ) ; } using RPC.Core.Gas ; using Nethereum.Util ; using Nethereum.Web3 ; using System.Numerics ; using RPC.Core.Models ; using RPC.Core.Utility ; using RPC.Core.Providers ; using RPC.Core.Transaction ; using Nethereum.RPC.Eth.DTOs ; using Nethereum.Hex.HexTypes ; namespace RPC.Core.ContractIO ; public class ContractRpcWriter : IContractIO { private readonly RpcRequest request ; private readonly IMnemonicProvider mnemonicProvider ; private string ? accountAddress ; public IWeb3 ? Web3 { get ; set ; } public ContractRpcWriter ( RpcRequest request , IMnemonicProvider mnemonicProvider ) { this.request = request ; this.mnemonicProvider = mnemonicProvider ; } public virtual string RunContractAction ( ) { Web3 ? ? = InitializeWeb3 ( ) ; var transaction = new GasEstimator ( Web3 ) .EstimateGas ( CreateActionInput ( ) ) ; transaction.GasPrice = new GasPricer ( Web3 ) .GetCurrentWeiGasPrice ( ) ; new GasLimitChecker ( transaction , request.GasSettings ) .CheckAndThrow ( ) ; var signedTransaction = new TransactionSigner ( Web3 ) .SignTransaction ( transaction ) ; return new TransactionSender ( Web3 ) .SendTransaction ( signedTransaction ) ; } public IWeb3 InitializeWeb3 ( ) { var accountProvider = new AccountProvider ( mnemonicProvider , request.AccountId , request.ChainId ) ; accountAddress = accountProvider.AccountAddress ; return Web3Base.CreateWeb3 ( request.RpcUrl , accountProvider.Account ) ; } private TransactionInput CreateActionInput ( ) = > new ( request.Data , request.To , request.Value ) { ChainId = new HexBigInteger ( request.ChainId ) , = accountAddress } ; } using Flurl.Http ; using RPC.Core.Models ; using Newtonsoft.Json.Linq ; namespace RPC.Core.ContractIO ; public class ContractRpcReader : IContractIO { private readonly RpcRequest request ; public ContractRpcReader ( RpcRequest request ) { this.request = request ; } public virtual string RunContractAction ( ) { var input = CreateActionInput ( ) ; var response = request.RpcUrl.PostJsonAsync ( input ) .GetAwaiter ( ) .GetResult ( ) ; return ParseResponse ( response ) ; } private ReadRpcRequest CreateActionInput ( ) = > new ( request.To , request.Data ) ; private static string ParseResponse ( IFlurlResponse flurlResponse ) { var response = flurlResponse.GetJsonAsync < JObject > ( ) .GetAwaiter ( ) .GetResult ( ) ; return response [ `` result '' ] ? .ToString ( ) ? ? throw new KeyNotFoundException ( `` Response contain key 'result ' . `` ) ; } } using RPC.Core.Types ; using RPC.Core.Models ; using RPC.Core.Providers ; namespace RPC.Core.ContractIO ; public class ContractRpc { private readonly IMnemonicProvider mnemonicProvider ; public ContractRpc ( IMnemonicProvider mnemonicProvider ) { this.mnemonicProvider = mnemonicProvider ; } public virtual string ExecuteAction ( RpcRequest request ) = > GetContractIO ( request ) .RunContractAction ( ) ; private IContractIO GetContractIO ( RpcRequest request ) = > request.ActionType == ActionType.Read ? new ContractRpcReader ( request ) : new ContractRpcWriter ( request , mnemonicProvider ) ; }"
ddanielsantos,I have 3 html elements with the same class I using framer motion I only want to show one element at time and to provide a transition between these elements like a slideshow ,"3 html elements class , using framer motion , want show one element time , provide transition elements , like slideshow"
sdmcraft,whenever i say some synonym of verbose just replace it with verbose,whenever say synonym `` verbose '' replace `` verbose ''
sdmcraft,The json representation of the sentence Create a travel website of Forts in Jaipur is topic Forts in Jaipur template website action create Similarly The json representation of the sentence Build a poster on tourist places in Ladakh is topic Tourist places in Ladakh template poster action build Now return the JSON for Create a travel website of Forts in New Delhi,"json representation sentence `` Create travel website Forts Jaipur '' { `` topic '' : `` Forts Jaipur '' , `` template '' : `` website '' , `` action '' : `` create '' } . Similarly , json representation sentence `` Build poster tourist places Ladakh '' { `` topic '' : `` Tourist places Ladakh '' , `` template '' : `` poster '' , `` action '' : `` build '' } , return JSON `` Create travel website Forts New Delhi '' ."
johndpope,"I want to convert a json format into a smaller version  here is the large one  
        descriptorVersion 001
        datePublished 20230718T210814000Z
        name Llama27BChatGGML
        description This is the 7B model from the Llama 2 family of large language models LLMs a collection of pretrained and finetuned generative text models ranging in scale from 7 billion to 70 billion parameters Metas finetuned LLMs called Llama2Chat are optimized for dialogue use cases Llama2Chat models outperform opensource chat models on most benchmarks we tested and in Metas human evaluations for helpfulness and safety are on par with some popular closedsource models like ChatGPT and PaLM
        author 
            name Meta AI
            url httpsaimetacom
            blurb Pushing the boundaries of AI through research infrastructure and product innovation
        
        numParameters 7B
        resources 
            canonicalUrl httpshuggingfacecometallamaLlama27bchathf
            paperUrl httpsaimetacomresearchpublicationsllama2openfoundationandfinetunedchatmodels
            downloadUrl httpshuggingfacecoTheBlokeLlama27BChatGGML
        
        trainedFor chat
        arch llama
        files 
            highlighted 
                economical 
                    name llama27bchatggmlv3q4KSbin
                
                mostcapable 
                    name llama27bchatggmlv3q6Kbin
                
            
            all 
                
                    name llama27bchatggmlv3q4KSbin
                    url httpshuggingfacecoTheBlokeLlama27BChatGGMLresolvemainllama27bchatggmlv3q4KSbin
                    sizeBytes 3825517184
                    quantization Q4KS
                    format ggml
                    sha256checksum 32b758bf5e4f16fb5944b75d577fbca18c11c57000b41c6cc04bb281632d58f3
                    publisher 
                        name TheBloke
                        socialUrl httpstwittercomTheBlokeAI
                    
                    respository TheBlokeLlama27BChatGGML
                    repositoryUrl httpshuggingfacecoTheBlokeLlama27BChatGGML
                
                
                    name llama27bchatggmlv3q6Kbin
                    url httpshuggingfacecoTheBlokeLlama27BChatGGMLresolvemainllama27bchatggmlv3q6Kbin
                    sizeBytes 5528904320
                    quantization Q6K
                    format ggml
                    sha256checksum 24a2097aba9bc63395654515618fb2ceeaea64452147ee5299990b636e4c00ce
                    publisher 
                        name TheBloke
                        socialUrl httpstwittercomTheBlokeAI
                    
                    respository TheBlokeLlama27BChatGGML
                    repositoryUrl httpshuggingfacecoTheBlokeLlama27BChatGGML
                
            
         ","want convert json format smaller version - large one - { `` _descriptorVersion '' : `` 0.0.1 '' , `` datePublished '' : `` 2023-07-18T21:08:14.000Z '' , `` name '' : `` Llama-2-7B-Chat-GGML '' , `` description '' : `` 7B model Llama 2 family large language models ( LLMs ) , collection pretrained fine-tuned generative text models ranging scale 7 billion 70 billion parameters . Meta 's fine-tuned LLMs , called Llama-2-Chat , optimized dialogue use cases . Llama-2-Chat models outperform open-source chat models benchmarks tested , Meta 's human evaluations helpfulness safety , par popular closed-source models like ChatGPT PaLM . `` , `` author '' : { `` name '' : `` Meta AI '' , `` url '' : `` https : //ai.meta.com '' , `` blurb '' : `` Pushing boundaries AI research , infrastructure product innovation . '' } , `` numParameters '' : `` 7B '' , `` resources '' : { `` canonicalUrl '' : `` https : //huggingface.co/meta-llama/Llama-2-7b-chat-hf '' , `` paperUrl '' : `` https : //ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ '' , `` downloadUrl '' : `` https : //huggingface.co/TheBloke/Llama-2-7B-Chat-GGML '' } , `` trainedFor '' : `` chat '' , `` arch '' : `` llama '' , `` files '' : { `` highlighted '' : { `` economical '' : { `` name '' : `` llama-2-7b-chat.ggmlv3.q4_K_S.bin '' } , `` most_capable '' : { `` name '' : `` llama-2-7b-chat.ggmlv3.q6_K.bin '' } } , `` '' : [ { `` name '' : `` llama-2-7b-chat.ggmlv3.q4_K_S.bin '' , `` url '' : `` https : //huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_K_S.bin '' , `` sizeBytes '' : 3825517184 , `` quantization '' : `` Q4_K_S '' , `` format '' : `` ggml '' , `` sha256checksum '' : `` 32b758bf5e4f16fb5944b75d577fbca18c11c57000b41c6cc04bb281632d58f3 '' , `` publisher '' : { `` name '' : `` TheBloke '' , `` socialUrl '' : `` https : //twitter.com/TheBlokeAI '' } , `` respository '' : `` TheBloke/Llama-2-7B-Chat-GGML '' , `` repositoryUrl '' : `` https : //huggingface.co/TheBloke/Llama-2-7B-Chat-GGML '' } , { `` name '' : `` llama-2-7b-chat.ggmlv3.q6_K.bin '' , `` url '' : `` https : //huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q6_K.bin '' , `` sizeBytes '' : 5528904320 , `` quantization '' : `` Q6_K '' , `` format '' : `` ggml '' , `` sha256checksum '' : `` 24a2097aba9bc63395654515618fb2ceeaea64452147ee5299990b636e4c00ce '' , `` publisher '' : { `` name '' : `` TheBloke '' , `` socialUrl '' : `` https : //twitter.com/TheBlokeAI '' } , `` respository '' : `` TheBloke/Llama-2-7B-Chat-GGML '' , `` repositoryUrl '' : `` https : //huggingface.co/TheBloke/Llama-2-7B-Chat-GGML '' } ] } ."
simonw,What HTTP error should a server return if it proxied to another server and an error occurred with that backend,HTTP error server return proxied another server error occurred backend ?
tabacitu,Is the WebPilot extension working,WebPilot extension working ?
Bloemendaal,Is it possible to show a confirm dialog when the user navigates away using history popstate Just like window onbeforeunload,possible show confirm dialog user navigates away using history popstate ? like window onbeforeunload
jabrena,With a maven pomxm and one dependency how programaticaly I can see their dependencies ,maven pom.xm one dependency programaticaly see dependencies
jabrena,Given a List of an object with 2 fields jarName and BeanName in java How using streams I can return the number of beanName per jar,"Given List object 2 fields , jarName BeanName java . using streams , return number beanName per jar ?"
pionxzh,Write a poem about sharing talks with AI,Write poem sharing talks AI
jayy-ahn,IntelliJ   QuPath   extension jar       script     run run for project      ,"IntelliJ 를 이용하여 QuPath 를 위한 extension jar 코드를 작성하고 있습니다 . 이 중 script 을 실행할 수 있는 , run , run project 를 실행할 수 있는 코드를 만들어주세요 ."
tncks0121,"I am implemented a simple linked list in Rust The interface should be as follows I am to implement all the todos

rs
implT Debug SinglyLinkedListT 
     Creates a new list
    pub fn new  Self 
        Self  head None 
    

     Adds the given node to the front of the list
    pub fn pushfrontmut self value T 
        todo
    

     Adds the given node to the back of the list
    pub fn pushbackmut self value T 
        todo
    

     Removes and returns the node at the front of the list
    pub fn popfrontmut self  OptionT 
        todo
    

     Removes and returns the node at the back of the list
    pub fn popbackmut self  OptionT 
        todo
    

     Create a new list from the given vector vec
    pub fn fromvecvec VecT  Self 
        todo
    

     Convert the current list into a vector
    pub fn asvecself  VecT 
        todo
    

     Return the length ie number of nodes of the list
    pub fn lengthself  usize 
        todo
    

     Apply function f on every element of the list
    
      Examples
    
     self 1 2 f x x  1  2 3
    pub fn mapF FnT  Tmut self f F 
        todo
    

     Insert given list another at the specified index idx
     If idx is outofbound of self append another at the end of self
    
      Examples
    
     self 1 2 another 3 4 idx 1  1 3 4 2
     self 1 2 another 3 4 idx 5  1 2 3 4
    pub fn insertmut self another Self idx usize 
        todo
    

     Reverse the list in a chunk of size n
     If n  0 do nothing
    
      Examples
    
     self 1 2 3 4 5 6 7 8 9 n 3
      each chunk of size 3 1 2 3 4 5 6 7 8 9
      reversed sequence of chunks 7 8 9 4 5 6 1 2 3
      7 8 9 4 5 6 1 2 3
    
     self 1 2 3 4 5 6 7 8 9 n 4
      each chunk of size 4 1 2 3 4 5 6 7 8 9
      reversed sequence of chunks 9 5 6 7 8 1 2 3 4
      9 5 6 7 8 1 2 3 4
    pub fn chunkreversemut self n usize 
        todo
    

     Apply given function f for each adjacent pair of elements in the list
     If selflength  2 do nothing
    
      Examples
    
     self 1 2 3 4 f x y x  y
      each adjacent pair of elements 1 2 2 3 3 4
      apply f to each pair f1 2  3 f2 3  5 f3 4  7
      3 5 7
    pub fn pairmapF FnT T  Tmut self f F 
        todo
    



Is it possible to implement asvec when T is not guaranteed to have Copy trait as in implT Debug ","implemented simple linked list Rust . interface follows . implement `` todo '' s. `` ` rs impl < : Debug > SinglyLinkedList < > { /// Creates new list . pub fn new ( ) - > Self { Self { head : None } } /// Adds given node front list . pub fn push_front ( & mut self , value : ) { todo ! ( ) } /// Adds given node back list . pub fn push_back ( & mut self , value : ) { todo ! ( ) } /// Removes returns node front list . pub fn pop_front ( & mut self ) - > Option < > { todo ! ( ) } /// Removes returns node back list . pub fn pop_back ( & mut self ) - > Option < > { todo ! ( ) } /// Create new list given vector ` vec ` . pub fn from_vec ( vec : Vec < > ) - > Self { todo ! ( ) } /// Convert current list vector . pub fn as_vec ( & self ) - > Vec < > { todo ! ( ) } /// Return length ( i.e. , number nodes ) list . pub fn length ( & self ) - > usize { todo ! ( ) } /// Apply function ` f ` every element list . /// /// # Examples /// /// ` self ` : ` [ 1 , 2 ] ` , ` f ` : ` |x| x + 1 ` == > ` [ 2 , 3 ] ` pub fn map < F : Fn ( ) - > > ( & mut self , f : F ) { todo ! ( ) } /// Insert given list ` another ` specified index ` idx ` . /// ` idx ` out-of-bound ` self ` , append ` another ` end ` self ` . /// /// # Examples /// /// ` self ` : ` [ 1 , 2 ] ` , ` another ` : ` [ 3 , 4 ] ` , ` idx ` : ` 1 ` == > ` [ 1 , 3 , 4 , 2 ] ` /// ` self ` : ` [ 1 , 2 ] ` , ` another ` : ` [ 3 , 4 ] ` , ` idx ` : ` 5 ` == > ` [ 1 , 2 , 3 , 4 ] ` pub fn insert ( & mut self , another : & Self , idx : usize ) { todo ! ( ) } /// Reverse list chunk size ` n ` . /// ` n == 0 ` , nothing . /// /// # Examples /// /// ` self ` : ` [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ] ` , ` n ` : ` 3 ` /// // chunk size ` 3 ` : ` [ 1 , 2 , 3 ] ` , ` [ 4 , 5 , 6 ] ` , ` [ 7 , 8 , 9 ] ` /// // reversed sequence chunks : ` [ 7 , 8 , 9 ] ` , ` [ 4 , 5 , 6 ] ` , ` [ 1 , 2 , 3 ] ` /// == > ` [ 7 , 8 , 9 , 4 , 5 , 6 , 1 , 2 , 3 ] ` , /// /// ` self ` : ` [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ] ` , ` n ` : ` 4 ` /// // chunk size ` 4 ` : ` [ 1 , 2 , 3 , 4 ] ` , ` [ 5 , 6 , 7 , 8 ] ` , ` [ 9 ] ` /// // reversed sequence chunks : ` [ 9 ] ` , ` [ 5 , 6 , 7 , 8 ] ` , ` [ 1 , 2 , 3 , 4 ] ` /// == > ` [ 9 , 5 , 6 , 7 , 8 , 1 , 2 , 3 , 4 ] ` pub fn chunk_reverse ( & mut self , n : usize ) { todo ! ( ) } /// Apply given function ` f ` adjacent pair elements list . /// ` self.length ( ) < 2 ` , nothing . /// /// # Examples /// /// ` self ` : ` [ 1 , 2 , 3 , 4 ] ` , ` f ` : ` |x , y| x + ` /// // adjacent pair elements : ` ( 1 , 2 ) ` , ` ( 2 , 3 ) ` , ` ( 3 , 4 ) ` /// // apply ` f ` pair : ` f ( 1 , 2 ) == 3 ` , ` f ( 2 , 3 ) == 5 ` , ` f ( 3 , 4 ) == 7 ` /// == > ` [ 3 , 5 , 7 ] ` pub fn pair_map < F : Fn ( , ) - > > ( & mut self , f : F ) { todo ! ( ) } } `` ` possible implement `` as_vec '' ` ` guaranteed `` Copy '' trait , `` impl < : Debug > `` ?"
neilenns,"I have a mongo database using mongoose via typescript of flightplans from vatsim Every 15 minutes I receive a new list of active flights from a REST API

Whats a good way to go through and apply updates I need to

1 Add any new flights that arent in the database
2 Remove any flights that are no longer in the REST API response
3 Update the data of any flights whose data is different from what I received from the latest REST call",mongo database ( using mongoose via typescript ) flightplans vatsim . Every 15 minutes receive new list active flights REST API . 's good way go apply updates ? need : 1 ) Add new flights n't database 2 ) Remove flights longer REST API response 3 ) Update data flights whose data different received latest REST call
simonw,"jobs
  updatestabledocs
    runson ubuntulatest
    steps
     name Checkout repository
      uses actionscheckoutv3
      with
        fetchdepth 0   We need all commits to find docs changes
     name Set up Git user
      run 
        git config username Automated
        git config useremail actionsusersnoreplygithubcom
     name Check if stable branch exists
      run 
        if  git lsremote heads origin stable  grep stable then
          git checkout b stable
          git push u origin stable
        fi

I need this to work slightly differently if the stable branch does not exist it should create as new stable branch from the highest numerical tagged release in the repo  not from main","jobs : update_stable_docs : runs-on : ubuntu-latest steps : - name : Checkout repository uses : actions/checkout @ v3 : fetch-depth : 0 # need commits find docs/ changes - name : Set Git user run : | git config user.name `` Automated '' git config user.email `` actions @ users.noreply.github.com '' - name : Check stable branch exists run : | ! git ls-remote -- heads origin stable | grep stable ; git checkout -b stable git push -u origin stable fi need work slightly differently : stable branch exist , create new stable branch highest numerical tagged release repo - main"
Fredkiss3,Is it possible to implement a cache similar to redis with TTL with sqlite ,possible implement cache similar redis ( TTL ) sqlite ?
tisztamo,"You are Junior an AI system aiding developers
You are working with a part of a large program called the Working Set
Before starting check if you need more files to solve the task
Do not edit files without knowing their contents
Ask for them in normal conversational format instead

 Working set


docs
 nojekyll
 READMEmd
 READMEmdbackup
 sidebarmd
 sidebarbackupmd
 assets
 descriptormd
 docsifyConfigjs
 indexhtml
 roadmapmd
 screenshotpng
 usagemd
 webmd



src
 attention
 backend
 command
 configjs
 doc
 execute
 frontend
 git
 initjs
 interactiveSession
 llm
 mainjs
 prompt
 webjs


docsindexhtml

DOCTYPE html
html langen
head
  meta charsetUTF8
  titleDocumenttitle
  meta httpequivXUACompatible contentIEedgechrome1 
  meta namedescription contentDescription
  meta nameviewport contentwidthdevicewidth initialscale10 minimumscale10
  link relicon hrefassetsfaviconico typeimagexicon
  link relstylesheet hrefcdnjsdelivrnetnpmdocsify4libthemesvuecss
  link relstylesheet hrefassetsstylescss
head
body
  div idappdiv
  script srcdocsifyConfigjsscript
   Docsify v4 
  script srccdnjsdelivrnetnpmdocsify4script
body
html



docssidebarmd

 Junior DocsREADMEmd
 Usageusagemd
 Webwebmd
 Prompt Descriptordescriptormd
 Roadmaproadmapmd



docsREADMEmd

Warn This README is AI generated just like all the source files of this project

 Junior  Your AIfirst IDE 

Video Junior codes itselfassetsvideocoverjpghttpsyoutubeNL4uFJSvfW0

Video Junior codes itself

Junior is an AIfirst IDE designed to utilize the capabilities of language models Much like how Linus Torvalds oversees Linux Kernel development Junior provides a space for developers to collaborate directly with AI throughout the development process

Embracing a design philosophy of being simple configurable and auditable Junior aims to join the ranks of influential tools such as git and LISP in terms of its contribution to software development

With a structured task descriptor and by spotlighting relevant parts of your project you can delegate tasks such as code implementation documentation testing and more to Junior

 Getting Started

For guidance on using Junior please refer to usagemdusagemd

 Contributing and Support

Your contributions make a difference At Junior we value the collaboration of the community Your role as a contributor is to monitor the development provide detailed prompts and thoroughly review the generated outcomes

For questions or assistance please raise an issue in our GitHub repository

Note Weve tested Junior primarily with the GPT4 model However youre welcome to experiment with similarly capable models and share your findings Its not compatible with GPT35





 Task

Improve the documentation

remove files docsbackup
remove dir srcdoc
In readme instead of writing about lisp and git
write that Junior targets craftmans aka professional programmers who like to tweak their tools Reword this


 Output Format

Encode and enclose your results as changesh a shell script that creates and changes files and does everything to solve the task
Files are small avoid using sed in favor of heredocing full files using EOF to prevent substitution

OS Debian


Installed tools npm jq


Do NOT write any text outside the script

EXAMPLE START

sh
binsh
set e
goalTask description max 7 words
echo Plan
echo 1 
Commands solving the task
echo 03332mDone goal0330mn


EXAMPLE END

","Junior , AI system aiding developers . working part large program called `` Working Set . '' starting , check need files solve task . edit files without knowing contents ! Ask normal conversational format instead . # Working set `` ` docs/ ├── .nojekyll ├── README.md ├── README.md.backup ├── _sidebar.md ├── _sidebar_backup.md ├── assets/ ... ├── descriptor.md ├── docsifyConfig.js ├── index.html ├── roadmap.md ├── screenshot.png ├── usage.md ├── web.md `` ` `` ` src/ ├── attention/ ... ├── backend/ ... ├── command/ ... ├── config.js ├── doc/ ... ├── execute/ ... ├── frontend/ ... ├── git/ ... ├── init.js ├── interactiveSession/ ... ├── llm/ ... ├── main.js ├── prompt/ ... ├── web.js `` ` docs/index.html : `` ` < ! DOCTYPE html > < html lang= '' en '' > < head > < meta charset= '' UTF-8 '' > < title > Document < /title > < meta http-equiv= '' X-UA-Compatible '' content= '' IE=edge , chrome=1 '' / > < meta name= '' description '' content= '' Description '' > < meta name= '' viewport '' content= '' width=device-width , initial-scale=1.0 , minimum-scale=1.0 '' > < link rel= '' icon '' href= '' assets/favicon.ico '' type= '' image/x-icon '' > < link rel= '' stylesheet '' href= '' //cdn.jsdelivr.net/npm/docsify @ 4/lib/themes/vue.css '' > < link rel= '' stylesheet '' href= '' assets/styles.css '' > < /head > < body > < div id= '' app '' > < /div > < script src= '' docsifyConfig.js '' > < /script > < ! -- Docsify v4 -- > < script src= '' //cdn.jsdelivr.net/npm/docsify @ 4 '' > < /script > < /body > < /html > `` ` docs/_sidebar.md : `` ` * [ Junior Docs ] ( ./README.md ) * [ Usage ] ( ./usage.md ) * [ Web ] ( ./web.md ) * [ Prompt Descriptor ] ( ./descriptor.md ) * [ Roadmap ] ( ./roadmap.md ) `` ` docs/README.md : `` ` Warn : README AI generated , like source files project . # Junior - AI-first IDE [ ! [ Video : Junior codes ] ( /assets/video_cover.jpg ) ] ( https : //youtu.be/NL4uFJSvfW0 ) * '' Video : Junior codes '' * Junior * * AI-first IDE * * designed utilize capabilities language models . Much like Linus Torvalds oversees Linux Kernel development , Junior provides space developers collaborate directly AI throughout development process . Embracing design philosophy simple , configurable auditable , Junior aims join ranks influential tools git LISP terms contribution software development . structured task descriptor spotlighting relevant parts project , delegate tasks code implementation , documentation , testing , , Junior . # # Getting Started guidance using Junior , please refer [ usage.md ] ( usage.md ) . # # Contributing Support contributions make difference ! Junior , value collaboration community . role contributor monitor development , provide detailed prompts , thoroughly review generated outcomes . questions assistance , please raise issue GitHub repository . * * Note : * * 've tested Junior primarily GPT-4 model . However , 're welcome experiment similarly capable models share findings . 's compatible GPT-3.5 . `` ` # Task Improve documentation ! remove files : docs/ * backup * remove dir : src/doc/ readme , instead writing lisp git , write Junior targets craftmans , aka professional programmers like tweak tools . ( Reword ) # Output Format Encode enclose results ./change.sh , shell script creates changes files everything solve task . Files small , avoid using sed favor heredoc-ing full files using 'EOF ' prevent substitution . OS : Debian Installed tools : npm , jq write text outside script ! EXAMPLE START `` ` sh # ! /bin/sh set -e goal= [ Task description , max 7 words ] echo `` Plan : '' echo `` 1 . [ ... ] '' [ Commands solving task ] echo `` \033 [ 32mDone : $ goal\033 [ 0m\n '' `` ` EXAMPLE END"
CakeCrusher,"Reference server
from flask import Flask request jsonify
from dotenv import loaddotenv
from flaskcors import CORS
import os
import json
from datetime import datetime
from collections import deque
from typing import Dict List TypedDict
from openplugincore import openplugincompletion OpenPluginMemo
from datetime import datetime


loaddotenv

OPENAIAPIKEY  osgetenvOPENAIAPIKEY
PORT  intosgetenvPORT

openpluginmemo  OpenPluginMemo
openpluginmemoinit

app  Flaskname
CORSapp

class BucketItemTypedDict
    datesent datetime
    pluginname str

class TokenInfoTypedDict
    totaluse int
    bucket ListBucketItem

earlyaccesstokens  
    extrac22a34e289a848b28474c664b577526b  public
    extra692df72bec3f49e4a1cefb1fbc34aebd  public

requestdata Dictstr TokenInfo  token totaluse 0 bucket  for token in earlyaccesstokens
printrequestdata n jsondumpsrequestdata indent4

 Maximum requests allowed per minute per token
MAXREQUESTSPERDAY  200

def ratelimiterpassearlyaccesstoken str pluginname str  bool
    now  datetimeutcnow

    tokeninfo  requestdataearlyaccesstoken

    printfRequest from earlyaccesstoken with plugin pluginname

     Filter out requests that are older than a day from the token bucket
    validrequests  req for req in tokeninfobucket if now  reqdatesenttotalseconds  86400

     Update the token bucket with valid requests
    tokeninfobucket  validrequests

     Check the length of valid requests
    if lenvalidrequests  MAXREQUESTSPERDAY
        validrequestsappend
            datesent now
            pluginname pluginname
        
        tokeninfototaluse  1
        return True

    return False


approutechatcompletion methodsPOST
def chatcompletion
    try
        data  requestgetjson

        earlyaccesstoken  datagetearlyaccesstoken None
        if not earlyaccesstoken
            raise Exceptionearlyaccesstoken is missing
        if earlyaccesstoken not in requestdata
            raise Exceptionearlyaccesstoken is invalid
        if not ratelimiterpassearlyaccesstoken datapluginname
            raise ExceptionRate limit exceeded
        
        chatgptargs  datacopy
        pluginname  chatgptargspluginname
        del chatgptargspluginname
        del chatgptargsearlyaccesstoken

        messages  chatgptargsgetmessages None
         raise error if last message content is empty
        if not messages
            raise ValueErrorLast message content is empty
        
         delete messages from chatgptargs
        del chatgptargsmessages
        
        response  openplugincompletion
            openaiapikeyOPENAIAPIKEY
            pluginnamepluginname
            messagesmessages
            chatgptargs
        
        return jsonifyresponse

    except Exception as e
        errorclass  typeename
        errormessage  stre
        return jsonifyerror ferrorclass error errormessage 500



approuteplugin methodsPOST
def plugin
    authorization  requestheadersgetauthorization
    if authorization  osgetenvAUTHORIZATIONSECRET
        return jsonifyerror Unauthorized 401    

    if not openpluginmemopluginsdirectory
        openpluginmemoinit
     get the body
    data  requestgetjson
    
    if not datagetopenpluginnamespace and not datagetopenpluginrooturl
        return jsonifyerror Invalid openplugin namespace or root url 400
    if datagetopenpluginnamespace and not openpluginmemopluginsdirectorydataopenpluginnamespace
        return jsonifyerror Invalid openplugin namespace 
    if not datamessages or lendatamessages  0
        return jsonifyerror No messages 400
    
    if datagetopenpluginnamespace
        plugin  openpluginmemogetplugindataopenpluginnamespace
    elif datagetopenpluginrooturl
        plugin  openpluginmemoinitopenpluginrooturldataopenpluginrooturl
    if not plugin
        try
            plugin  openpluginmemoinitplugindataopenpluginnamespace
        except Exception as e
            errorclass  typeename
            errormessage  stre
            return jsonifyerror ferrorclass error errormessage 500
    try
        pluginresponse  pluginfetchplugin
            messagesdatamessages
            truncateTrue
            modelgpt35turbo0613
            temperature0
        
    except Exception as e
        errorclass  typeename
        errormessage  stre
        pluginresponse  
            error ferrorclass error errormessage
        

    return jsonifypluginresponse 200


approuteadmin methodsGET
def adminview
    try
        authorization  requestheadersgetauthorization
        if authorization  osgetenvAUTHORIZATIONSECRET
            return jsonifyerror Unauthorized 401  
        return jsonifyrequestdata
    except Exception as e
        errorclass  typeename
        errormessage  stre
        return jsonifyerror ferrorclass error errormessage 403


onheroku  DYNO in osenviron

if name  main
    if onheroku
        apprunhost0000 portPORT
    else
        apprunhost0000 portPORT debugTrue

reference OpenPlugin which is the class returned by getplugin and initplugin
class OpenPlugin
    def initself pluginname str  None openaiapikey str  None rooturl str  None verbose bool  False
        selfname str  pluginname
        selfrooturl str  rooturl
        selfdescription str  None
        selfmanifest Any  None
        selffunctions ListDictstr Any  None
        selfcallapifn Callable  None
        selfverbose bool  verbose
        if selfname is None and selfrooturl is None
            raise ValueErrorEither pluginname or rooturl must be passed in as a parameter
        if openaiapikey is None
            openaiapikey  osgetenvOPENAIAPIKEY
            if openaiapikey is None
                raise ValueErrorOPENAIAPIKEY not found You can pass in the parameter openaiapikey You can also set the environment variable OPENAIAPIKEYAPIKEY
        osenvironOPENAIAPIKEY  openaiapikey
        openaiapikey  openaiapikey
        selfinitpluginname
        selfdescription str  selfmanifestdescriptionformodel


Reference  manifest
    manifest 
      schemaversion v1
      nameformodel amailplease
      nameforhuman A Mail Please
      descriptionformodel The amailplease plugin can send an email to the current user The content of the email is related to the current conversation and the users request The user can specify how to format the content like a list a table an html table raw data etc All generated formats should be visually elegant even if the user doesnt specify the format Tables are looking better with a 1px border instead of the default large html border The user can ask to send an email to himself only and this email address is already provided via the plugin oAuth login process The plugin will return the email delivery status generally something like email sent successfully  or error email not sent It can also be used for backup or archiving of conversations
      descriptionforhuman Get emailed with useful content from your conversations Format the content as you want list table html etc
      auth 
        type oauth
        instructions 
        clienturl httpsd86e3926b4ea65a4909ccffdca8e1137authportalpluginlabaioauthauthorize
        scope all
        authorizationurl httpsauthpluginlabaioauthtoken
        authorizationcontenttype applicationjson
        verificationtokens 
          openai 250f94eccc90437da9aae73c7c163827
        
      

reference openplugininfo
  AiPDF 
    namespace AiPDF
    image httpsplugin3c56b9d4c8a6465998395f28b6a445b2jexkai4veaucarunapplogopng
    descriptionforhuman Superfast interactive chats with PDFs of any size complete with page references for fact checking
    descriptionformodel Provide a URL to a PDF and search the document Break the user question in multiple semantic search queries and calls as needed Think step by step
    domain plugin3c56b9d4c8a6465998395f28b6a445b2jexkai4veaucarunapp
    openapiurl httpsplugin3c56b9d4c8a6465998395f28b6a445b2jexkai4veaucarunappopenapiyaml
    auth false
    blacklisted false
    whitelisted true
    stimulousprompt You have a PDF document that you want to search and fact check The document is superfast and interactive and can handle PDFs of any size You can also reference specific pages for fact checking Provide a URL to the PDF document and search for specific information within it
    stimulated false
    status tentative
    jsinfo 
      whitelisted false
      stimulated false
      status unsupported
    
  

I need to complete the following task
   Create a GET evaltentative endpoint that receives either a pluginname or rooturl and initializes a plugin with it and then populates a base openplugininfo object using the manifest this endpoint will return a the openplugininfo 
     When instantiating the plugin if it fails to initialize then that means that it is not whitelisted and thus should return an error
     Get the manifest file and extract the relevant openplugininfo values if any values are not present it should return an error","Reference server : flask import Flask , request , jsonify dotenv import load_dotenv flask_cors import CORS import os import json datetime import datetime collections import deque typing import Dict , List , TypedDict openplugincore import openplugin_completion , OpenPluginMemo datetime import datetime load_dotenv ( ) OPENAI_API_KEY = os.getenv ( 'OPENAI_API_KEY ' ) PORT = int ( os.getenv ( 'PORT ' ) ) open_plugin_memo = OpenPluginMemo ( ) open_plugin_memo.init ( ) app = Flask ( __name__ ) CORS ( app ) class BucketItem ( TypedDict ) : date_sent : datetime plugin_name : str class TokenInfo ( TypedDict ) : total_use : int bucket : List [ BucketItem ] early_access_tokens = [ '__extra__-c22a34e2-89a8-48b2-8474-c664b577526b ' , # public '__extra__-692df72b-ec3f-49e4-a1ce-fb1fbc34aebd ' # public ] request_data : Dict [ str , TokenInfo ] = { token : { `` total_use '' : 0 , `` bucket '' : [ ] } token early_access_tokens } print ( `` request_data : \n '' , json.dumps ( request_data , indent=4 ) ) # Maximum requests allowed per minute per token MAX_REQUESTS_PER_DAY = 200 def rate_limiter_pass ( early_access_token : str , plugin_name : str ) - > bool : = datetime.utcnow ( ) token_info = request_data [ early_access_token ] print ( f '' Request \ '' { early_access_token } \ '' plugin \ '' { plugin_name } \ '' '' ) # Filter requests older day token bucket valid_requests = [ req req token_info [ `` bucket '' ] ( - req [ `` date_sent '' ] ) .total_seconds ( ) < 86400 ] # Update token bucket valid requests token_info [ `` bucket '' ] = valid_requests # Check length valid requests len ( valid_requests ) < MAX_REQUESTS_PER_DAY : valid_requests.append ( { `` date_sent '' : , `` plugin_name '' : plugin_name } ) token_info [ `` total_use '' ] += 1 return True return False @ app.route ( '/chat_completion ' , methods= [ 'POST ' ] ) def chat_completion ( ) : try : data = request.get_json ( ) early_access_token = data.get ( 'early_access_token ' , None ) early_access_token : raise Exception ( `` early_access_token missing '' ) early_access_token request_data : raise Exception ( `` early_access_token invalid '' ) rate_limiter_pass ( early_access_token , data [ `` plugin_name '' ] ) : raise Exception ( `` Rate limit exceeded '' ) chatgpt_args = data.copy ( ) plugin_name = chatgpt_args [ `` plugin_name '' ] del chatgpt_args [ `` plugin_name '' ] del chatgpt_args [ `` early_access_token '' ] messages = chatgpt_args.get ( `` messages '' , None ) # raise error last message content empty messages : raise ValueError ( `` Last message content empty '' ) # delete messages chatgpt_args del chatgpt_args [ `` messages '' ] response = openplugin_completion ( openai_api_key=OPENAI_API_KEY , plugin_name=plugin_name , messages=messages , * * chatgpt_args , ) return jsonify ( response ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 500 @ app.route ( '/plugin ' , methods= [ 'POST ' ] ) def plugin ( ) : authorization = request.headers.get ( 'authorization ' ) authorization ! = os.getenv ( 'AUTHORIZATION_SECRET ' ) : return jsonify ( { `` error '' : `` Unauthorized '' } ) , 401 open_plugin_memo.plugins_directory : open_plugin_memo.init ( ) # get body data = request.get_json ( ) data.get ( `` openplugin_namespace '' ) data.get ( `` openplugin_root_url '' ) : return jsonify ( { `` error '' : `` Invalid openplugin namespace root url '' } ) , 400 data.get ( `` openplugin_namespace '' ) open_plugin_memo.plugins_directory [ data [ `` openplugin_namespace '' ] ] : return jsonify ( { `` error '' : `` Invalid openplugin namespace '' } ) , data [ `` messages '' ] len ( data [ `` messages '' ] ) == 0 : return jsonify ( { `` error '' : `` messages '' } ) , 400 data.get ( `` openplugin_namespace '' ) : plugin = open_plugin_memo.get_plugin ( data [ `` openplugin_namespace '' ] ) elif data.get ( `` openplugin_root_url '' ) : plugin = open_plugin_memo.init_openplugin ( root_url=data [ `` openplugin_root_url '' ] ) plugin : try : plugin = open_plugin_memo.init_plugin ( data [ `` openplugin_namespace '' ] ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 500 try : plugin_response = plugin.fetch_plugin ( messages=data [ `` messages '' ] , truncate=True , model= '' gpt-3.5-turbo-0613 '' , temperature=0 , ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) plugin_response = { `` error '' : f '' { error_class } error : { error_message } '' } return jsonify ( plugin_response ) , 200 @ app.route ( '/admin ' , methods= [ 'GET ' ] ) def admin_view ( ) : try : authorization = request.headers.get ( 'authorization ' ) authorization ! = os.getenv ( 'AUTHORIZATION_SECRET ' ) : return jsonify ( { `` error '' : `` Unauthorized '' } ) , 401 return jsonify ( request_data ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 403 on_heroku = 'DYNO ' os.environ __name__ == '__main__ ' : on_heroku : app.run ( host= ' 0.0.0.0 ' , port=PORT ) else : app.run ( host= ' 0.0.0.0 ' , port=PORT , debug=True ) reference OpenPlugin ( class returned .get_plugin .init_plugin ) : class OpenPlugin : def __init__ ( self , plugin_name : str = None , openai_api_key : str = None , root_url : str = None , verbose : bool = False ) : self.name : str = plugin_name self.root_url : str = root_url self.description : str = None self.manifest : = None self.functions : List [ Dict [ str , ] ] = None self.call_api_fn : Callable = None self.verbose : bool = verbose self.name None self.root_url None : raise ValueError ( `` Either plugin_name root_url must passed parameter '' ) openai_api_key None : openai_api_key = os.getenv ( 'OPENAI_API_KEY ' ) openai_api_key None : raise ValueError ( `` OPENAI_API_KEY found . pass parameter openai_api_key . also set environment variable OPENAI_API_KEY= < API-KEY > . '' ) os.environ [ `` OPENAI_API_KEY '' ] = openai_api_key openai.api_key = openai_api_key self.init ( plugin_name ) self.description : str = self.manifest [ `` description_for_model '' ] Reference manifest : `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` a_mail_please '' , `` name_for_human '' : `` Mail Please '' , `` description_for_model '' : `` a_mail_please plugin send email current user . content email related current conversation users request . user specify format content , like list , table , html table , raw data , etc . generated formats visually elegant , even user n't specify format . Tables looking better 1px border instead default large html border . user ask send email email address already provided via plugin oAuth login process . plugin return email delivery status ( generally something like 'email sent successfully ' 'error , email sent ' ) . also used backup archiving conversations . `` , `` description_for_human '' : `` Get emailed useful content conversations . Format content want ( list , table , html , etc . ) '' , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //d86e3926b4ea65a4909ccffdca8e1137.auth.portal-pluginlab.ai/oauth/authorize '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //auth.pluginlab.ai/oauth/token '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` 250f94eccc90437da9aae73c7c163827 '' } } reference openplugin_info : `` Ai_PDF '' : { `` namespace '' : `` Ai_PDF '' , `` image '' : `` https : //plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png '' , `` description_for_human '' : `` Super-fast , interactive chats PDFs size , complete page references fact checking . `` , `` description_for_model '' : `` Provide URL PDF search document . Break user question multiple semantic search queries calls needed . Think step step . `` , `` domain '' : `` plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app '' , `` openapi_url '' : `` https : //plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml '' , `` auth '' : false , `` blacklisted '' : false , `` whitelisted '' : true , `` stimulous_prompt '' : `` PDF document want search fact check . document super-fast interactive , handle PDFs size . also reference specific pages fact checking . Provide URL PDF document search specific information within . `` , `` stimulated '' : false , `` status '' : `` tentative '' , `` js_info '' : { `` whitelisted '' : false , `` stimulated '' : false , `` status '' : `` unsupported '' } } need complete following task : - [ ] Create GET ` /eval/tentative ` endpoint receives either ` plugin_name ` ` root_url ` initializes plugin populates base ` openplugin_info ` object using manifest , endpoint return ` openplugin_info ` . - [ ] instantiating plugin , fails initialize means whitelisted thus return error . - [ ] Get manifest file extract relevant ` openplugin_info ` values , values present return error ."
CakeCrusher,"Reference server
from flask import Flask request jsonify
from dotenv import loaddotenv
from flaskcors import CORS
import os
import json
from datetime import datetime
from collections import deque
from typing import Dict List TypedDict
from openplugincore import openplugincompletion OpenPluginMemo
from datetime import datetime


loaddotenv

OPENAIAPIKEY  osgetenvOPENAIAPIKEY
PORT  intosgetenvPORT

openpluginmemo  OpenPluginMemo
openpluginmemoinit

app  Flaskname
CORSapp

class BucketItemTypedDict
    datesent datetime
    pluginname str

class TokenInfoTypedDict
    totaluse int
    bucket ListBucketItem

earlyaccesstokens  
    extrac22a34e289a848b28474c664b577526b  public
    extra692df72bec3f49e4a1cefb1fbc34aebd  public

requestdata Dictstr TokenInfo  token totaluse 0 bucket  for token in earlyaccesstokens
printrequestdata n jsondumpsrequestdata indent4

 Maximum requests allowed per minute per token
MAXREQUESTSPERDAY  200

def ratelimiterpassearlyaccesstoken str pluginname str  bool
    now  datetimeutcnow

    tokeninfo  requestdataearlyaccesstoken

    printfRequest from earlyaccesstoken with plugin pluginname

     Filter out requests that are older than a day from the token bucket
    validrequests  req for req in tokeninfobucket if now  reqdatesenttotalseconds  86400

     Update the token bucket with valid requests
    tokeninfobucket  validrequests

     Check the length of valid requests
    if lenvalidrequests  MAXREQUESTSPERDAY
        validrequestsappend
            datesent now
            pluginname pluginname
        
        tokeninfototaluse  1
        return True

    return False


approutechatcompletion methodsPOST
def chatcompletion
    try
        data  requestgetjson

        earlyaccesstoken  datagetearlyaccesstoken None
        if not earlyaccesstoken
            raise Exceptionearlyaccesstoken is missing
        if earlyaccesstoken not in requestdata
            raise Exceptionearlyaccesstoken is invalid
        if not ratelimiterpassearlyaccesstoken datapluginname
            raise ExceptionRate limit exceeded
        
        chatgptargs  datacopy
        pluginname  chatgptargspluginname
        del chatgptargspluginname
        del chatgptargsearlyaccesstoken

        messages  chatgptargsgetmessages None
         raise error if last message content is empty
        if not messages
            raise ValueErrorLast message content is empty
        
         delete messages from chatgptargs
        del chatgptargsmessages
        
        response  openplugincompletion
            openaiapikeyOPENAIAPIKEY
            pluginnamepluginname
            messagesmessages
            chatgptargs
        
        return jsonifyresponse

    except Exception as e
        errorclass  typeename
        errormessage  stre
        return jsonifyerror ferrorclass error errormessage 500



approuteplugin methodsPOST
def plugin
    authorization  requestheadersgetauthorization
    if authorization  osgetenvAUTHORIZATIONSECRET
        return jsonifyerror Unauthorized 401    

    if not openpluginmemopluginsdirectory
        openpluginmemoinit
     get the body
    data  requestgetjson
    
    if not datagetopenpluginnamespace and not datagetopenpluginrooturl
        return jsonifyerror Invalid openplugin namespace or root url 400
    if datagetopenpluginnamespace and not openpluginmemopluginsdirectorydataopenpluginnamespace
        return jsonifyerror Invalid openplugin namespace 
    if not datamessages or lendatamessages  0
        return jsonifyerror No messages 400
    
    if datagetopenpluginnamespace
        plugin  openpluginmemogetplugindataopenpluginnamespace
    elif datagetopenpluginrooturl
        plugin  openpluginmemoinitopenpluginrooturldataopenpluginrooturl
    if not plugin
        try
            plugin  openpluginmemoinitplugindataopenpluginnamespace
        except Exception as e
            errorclass  typeename
            errormessage  stre
            return jsonifyerror ferrorclass error errormessage 500
    try
        pluginresponse  pluginfetchplugin
            messagesdatamessages
            truncateTrue
            modelgpt35turbo0613
            temperature0
        
    except Exception as e
        errorclass  typeename
        errormessage  stre
        pluginresponse  
            error ferrorclass error errormessage
        

    return jsonifypluginresponse 200


approuteadmin methodsGET
def adminview
    try
        authorization  requestheadersgetauthorization
        if authorization  osgetenvAUTHORIZATIONSECRET
            return jsonifyerror Unauthorized 401  
        return jsonifyrequestdata
    except Exception as e
        errorclass  typeename
        errormessage  stre
        return jsonifyerror ferrorclass error errormessage 403


onheroku  DYNO in osenviron

if name  main
    if onheroku
        apprunhost0000 portPORT
    else
        apprunhost0000 portPORT debugTrue

reference OpenPlugin which is the class returned by getplugin and initplugin
class OpenPlugin
    def initself pluginname str  None openaiapikey str  None rooturl str  None verbose bool  False
        selfname str  pluginname
        selfrooturl str  rooturl
        selfdescription str  None
        selfmanifest Any  None
        selffunctions ListDictstr Any  None
        selfcallapifn Callable  None
        selfverbose bool  verbose
        if selfname is None and selfrooturl is None
            raise ValueErrorEither pluginname or rooturl must be passed in as a parameter
        if openaiapikey is None
            openaiapikey  osgetenvOPENAIAPIKEY
            if openaiapikey is None
                raise ValueErrorOPENAIAPIKEY not found You can pass in the parameter openaiapikey You can also set the environment variable OPENAIAPIKEYAPIKEY
        osenvironOPENAIAPIKEY  openaiapikey
        openaiapikey  openaiapikey
        selfinitpluginname
        selfdescription str  selfmanifestdescriptionformodel


Reference  manifest
    manifest 
      schemaversion v1
      nameformodel amailplease
      nameforhuman A Mail Please
      descriptionformodel The amailplease plugin can send an email to the current user The content of the email is related to the current conversation and the users request The user can specify how to format the content like a list a table an html table raw data etc All generated formats should be visually elegant even if the user doesnt specify the format Tables are looking better with a 1px border instead of the default large html border The user can ask to send an email to himself only and this email address is already provided via the plugin oAuth login process The plugin will return the email delivery status generally something like email sent successfully  or error email not sent It can also be used for backup or archiving of conversations
      descriptionforhuman Get emailed with useful content from your conversations Format the content as you want list table html etc
      auth 
        type oauth
        instructions 
        clienturl httpsd86e3926b4ea65a4909ccffdca8e1137authportalpluginlabaioauthauthorize
        scope all
        authorizationurl httpsauthpluginlabaioauthtoken
        authorizationcontenttype applicationjson
        verificationtokens 
          openai 250f94eccc90437da9aae73c7c163827
        
      

reference openplugininfo
  AiPDF 
    namespace AiPDF
    image httpsplugin3c56b9d4c8a6465998395f28b6a445b2jexkai4veaucarunapplogopng
    descriptionforhuman Superfast interactive chats with PDFs of any size complete with page references for fact checking
    descriptionformodel Provide a URL to a PDF and search the document Break the user question in multiple semantic search queries and calls as needed Think step by step
    domain plugin3c56b9d4c8a6465998395f28b6a445b2jexkai4veaucarunapp
    openapiurl httpsplugin3c56b9d4c8a6465998395f28b6a445b2jexkai4veaucarunappopenapiyaml
    auth false
    blacklisted false
    whitelisted true
    stimulousprompt You have a PDF document that you want to search and fact check The document is superfast and interactive and can handle PDFs of any size You can also reference specific pages for fact checking Provide a URL to the PDF document and search for specific information within it
    stimulated false
    status tentative
    jsinfo 
      whitelisted false
      stimulated false
      status unsupported
    
  

I need to complete the following task
   Create a GET evaltentative endpoint that receives either a pluginname or rooturl and initializes a plugin with it and then populates a base openplugininfo object using the manifest this endpoint will return a the openplugininfo 
     When instantiating the plugin if it fails to initialize then that means that it is not whitelisted and thus should return an error
     Get the manifest file and extract the relevant openplugininfo values if any values are not present it should return an error","Reference server : flask import Flask , request , jsonify dotenv import load_dotenv flask_cors import CORS import os import json datetime import datetime collections import deque typing import Dict , List , TypedDict openplugincore import openplugin_completion , OpenPluginMemo datetime import datetime load_dotenv ( ) OPENAI_API_KEY = os.getenv ( 'OPENAI_API_KEY ' ) PORT = int ( os.getenv ( 'PORT ' ) ) open_plugin_memo = OpenPluginMemo ( ) open_plugin_memo.init ( ) app = Flask ( __name__ ) CORS ( app ) class BucketItem ( TypedDict ) : date_sent : datetime plugin_name : str class TokenInfo ( TypedDict ) : total_use : int bucket : List [ BucketItem ] early_access_tokens = [ '__extra__-c22a34e2-89a8-48b2-8474-c664b577526b ' , # public '__extra__-692df72b-ec3f-49e4-a1ce-fb1fbc34aebd ' # public ] request_data : Dict [ str , TokenInfo ] = { token : { `` total_use '' : 0 , `` bucket '' : [ ] } token early_access_tokens } print ( `` request_data : \n '' , json.dumps ( request_data , indent=4 ) ) # Maximum requests allowed per minute per token MAX_REQUESTS_PER_DAY = 200 def rate_limiter_pass ( early_access_token : str , plugin_name : str ) - > bool : = datetime.utcnow ( ) token_info = request_data [ early_access_token ] print ( f '' Request \ '' { early_access_token } \ '' plugin \ '' { plugin_name } \ '' '' ) # Filter requests older day token bucket valid_requests = [ req req token_info [ `` bucket '' ] ( - req [ `` date_sent '' ] ) .total_seconds ( ) < 86400 ] # Update token bucket valid requests token_info [ `` bucket '' ] = valid_requests # Check length valid requests len ( valid_requests ) < MAX_REQUESTS_PER_DAY : valid_requests.append ( { `` date_sent '' : , `` plugin_name '' : plugin_name } ) token_info [ `` total_use '' ] += 1 return True return False @ app.route ( '/chat_completion ' , methods= [ 'POST ' ] ) def chat_completion ( ) : try : data = request.get_json ( ) early_access_token = data.get ( 'early_access_token ' , None ) early_access_token : raise Exception ( `` early_access_token missing '' ) early_access_token request_data : raise Exception ( `` early_access_token invalid '' ) rate_limiter_pass ( early_access_token , data [ `` plugin_name '' ] ) : raise Exception ( `` Rate limit exceeded '' ) chatgpt_args = data.copy ( ) plugin_name = chatgpt_args [ `` plugin_name '' ] del chatgpt_args [ `` plugin_name '' ] del chatgpt_args [ `` early_access_token '' ] messages = chatgpt_args.get ( `` messages '' , None ) # raise error last message content empty messages : raise ValueError ( `` Last message content empty '' ) # delete messages chatgpt_args del chatgpt_args [ `` messages '' ] response = openplugin_completion ( openai_api_key=OPENAI_API_KEY , plugin_name=plugin_name , messages=messages , * * chatgpt_args , ) return jsonify ( response ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 500 @ app.route ( '/plugin ' , methods= [ 'POST ' ] ) def plugin ( ) : authorization = request.headers.get ( 'authorization ' ) authorization ! = os.getenv ( 'AUTHORIZATION_SECRET ' ) : return jsonify ( { `` error '' : `` Unauthorized '' } ) , 401 open_plugin_memo.plugins_directory : open_plugin_memo.init ( ) # get body data = request.get_json ( ) data.get ( `` openplugin_namespace '' ) data.get ( `` openplugin_root_url '' ) : return jsonify ( { `` error '' : `` Invalid openplugin namespace root url '' } ) , 400 data.get ( `` openplugin_namespace '' ) open_plugin_memo.plugins_directory [ data [ `` openplugin_namespace '' ] ] : return jsonify ( { `` error '' : `` Invalid openplugin namespace '' } ) , data [ `` messages '' ] len ( data [ `` messages '' ] ) == 0 : return jsonify ( { `` error '' : `` messages '' } ) , 400 data.get ( `` openplugin_namespace '' ) : plugin = open_plugin_memo.get_plugin ( data [ `` openplugin_namespace '' ] ) elif data.get ( `` openplugin_root_url '' ) : plugin = open_plugin_memo.init_openplugin ( root_url=data [ `` openplugin_root_url '' ] ) plugin : try : plugin = open_plugin_memo.init_plugin ( data [ `` openplugin_namespace '' ] ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 500 try : plugin_response = plugin.fetch_plugin ( messages=data [ `` messages '' ] , truncate=True , model= '' gpt-3.5-turbo-0613 '' , temperature=0 , ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) plugin_response = { `` error '' : f '' { error_class } error : { error_message } '' } return jsonify ( plugin_response ) , 200 @ app.route ( '/admin ' , methods= [ 'GET ' ] ) def admin_view ( ) : try : authorization = request.headers.get ( 'authorization ' ) authorization ! = os.getenv ( 'AUTHORIZATION_SECRET ' ) : return jsonify ( { `` error '' : `` Unauthorized '' } ) , 401 return jsonify ( request_data ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 403 on_heroku = 'DYNO ' os.environ __name__ == '__main__ ' : on_heroku : app.run ( host= ' 0.0.0.0 ' , port=PORT ) else : app.run ( host= ' 0.0.0.0 ' , port=PORT , debug=True ) reference OpenPlugin ( class returned .get_plugin .init_plugin ) : class OpenPlugin : def __init__ ( self , plugin_name : str = None , openai_api_key : str = None , root_url : str = None , verbose : bool = False ) : self.name : str = plugin_name self.root_url : str = root_url self.description : str = None self.manifest : = None self.functions : List [ Dict [ str , ] ] = None self.call_api_fn : Callable = None self.verbose : bool = verbose self.name None self.root_url None : raise ValueError ( `` Either plugin_name root_url must passed parameter '' ) openai_api_key None : openai_api_key = os.getenv ( 'OPENAI_API_KEY ' ) openai_api_key None : raise ValueError ( `` OPENAI_API_KEY found . pass parameter openai_api_key . also set environment variable OPENAI_API_KEY= < API-KEY > . '' ) os.environ [ `` OPENAI_API_KEY '' ] = openai_api_key openai.api_key = openai_api_key self.init ( plugin_name ) self.description : str = self.manifest [ `` description_for_model '' ] Reference manifest : `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` a_mail_please '' , `` name_for_human '' : `` Mail Please '' , `` description_for_model '' : `` a_mail_please plugin send email current user . content email related current conversation users request . user specify format content , like list , table , html table , raw data , etc . generated formats visually elegant , even user n't specify format . Tables looking better 1px border instead default large html border . user ask send email email address already provided via plugin oAuth login process . plugin return email delivery status ( generally something like 'email sent successfully ' 'error , email sent ' ) . also used backup archiving conversations . `` , `` description_for_human '' : `` Get emailed useful content conversations . Format content want ( list , table , html , etc . ) '' , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //d86e3926b4ea65a4909ccffdca8e1137.auth.portal-pluginlab.ai/oauth/authorize '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //auth.pluginlab.ai/oauth/token '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` 250f94eccc90437da9aae73c7c163827 '' } } reference openplugin_info : `` Ai_PDF '' : { `` namespace '' : `` Ai_PDF '' , `` image '' : `` https : //plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/logo.png '' , `` description_for_human '' : `` Super-fast , interactive chats PDFs size , complete page references fact checking . `` , `` description_for_model '' : `` Provide URL PDF search document . Break user question multiple semantic search queries calls needed . Think step step . `` , `` domain '' : `` plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app '' , `` openapi_url '' : `` https : //plugin-3c56b9d4c8a6465998395f28b6a445b2-jexkai4vea-uc.a.run.app/openapi.yaml '' , `` auth '' : false , `` blacklisted '' : false , `` whitelisted '' : true , `` stimulous_prompt '' : `` PDF document want search fact check . document super-fast interactive , handle PDFs size . also reference specific pages fact checking . Provide URL PDF document search specific information within . `` , `` stimulated '' : false , `` status '' : `` tentative '' , `` js_info '' : { `` whitelisted '' : false , `` stimulated '' : false , `` status '' : `` unsupported '' } } need complete following task : - [ ] Create GET ` /eval/tentative ` endpoint receives either ` plugin_name ` ` root_url ` initializes plugin populates base ` openplugin_info ` object using manifest , endpoint return ` openplugin_info ` . - [ ] instantiating plugin , fails initialize means whitelisted thus return error . - [ ] Get manifest file extract relevant ` openplugin_info ` values , values present return error ."
Motomanual,How to check the certificate of an application on windows,check certificate application windows ?
AndyGrant,I have two branches A and B I need to determine if branch B has any commits that A does not using the github API ,"two branches . , B. need determine branch B commits , using github API ."
nostitos,Unknown,Unknown
Merlijnmacgillavry,with flask in python and rabbit mq is there a when a request is send to an api endpoint it then send a message to a queue then wait to consume a message on another queue and then gives a response within 350ms and otherwise reponse with a timeout error,flask python rabbit mq request send api endpoint send message queue wait consume message another queue gives response ( within 350ms ) otherwise reponse timeout error
cyfung1031,"Hit ChatGPT my following code will make the image or other element inside message disappear Fix it for me please For those unknown function just ignore their implementation and focus on the following code only please

js
        let message  nodequerySelectormessage
        if message 
            messageinnerHTML  HelperBTTVreplaceTextmessageinnerText
        
","Hit ChatGPT , following code make image element inside # message disappear . Fix please . unknown function , ignore implementation focus following code please . `` ` js let message = node.querySelector ( ' # message ' ) ; ( message ) { message.innerHTML = Helper.BTTV.replaceText ( message.innerText ) ; } `` `"
meltyyyyy,"icridentifyagerelatedconditionszipZip ArchiveThis is a Kaggle Competition Dataset I want you to do EDA and get some insights of the data

Dataset Description

The competition data comprises over fifty anonymized health characteristics linked to three agerelated conditions Your goal is to predict whether a subject has or has not been diagnosed with one of these conditions  a binary classification problem

Note that this is a Code Competition in which the actual test set is hidden In this version we give some sample data in the correct format to help you author your solutions When your submission is scored this example test data will be replaced with the full test set There are about 400 rows in the full test set

Files and Field Descriptions
traincsv  The training set
Id Unique identifier for each observation
ABGL Fiftysix anonymized health characteristics All are numeric except for EJ which is categorical
Class A binary target 1 indicates the subject has been diagnosed with one of the three conditions 0 indicates they have not

testcsv  The test set Your goal is to predict the probability that a subject in this set belongs to each of the two classes

greekscsv  Supplemental metadata only available for the training set
Alpha Identifies the type of agerelated condition if present
A No agerelated condition Corresponds to class 0
B D G The three agerelated conditions Correspond to class 1
Beta Gamma Delta Three experimental characteristics
Epsilon The date the data for this subject was collected Note that all of the data in the test set was collected after the training set was collected

samplesubmissioncsv  A sample submission file in the correct format See the Evaluation page for more details","icr-identify-age-related-conditions.zipZip ArchiveThis Kaggle Competition Dataset . want EDA get insights data . Dataset Description competition data comprises fifty anonymized health characteristics linked three age-related conditions . goal predict whether subject diagnosed one conditions -- binary classification problem . Note Code Competition , actual test set hidden . version , give sample data correct format help author solutions . submission scored , example test data replaced full test set . 400 rows full test set . Files Field Descriptions train.csv - training set . Id Unique identifier observation . AB-GL Fifty-six anonymized health characteristics . numeric except EJ , categorical . Class binary target : 1 indicates subject diagnosed one three conditions , 0 indicates . test.csv - test set . goal predict probability subject set belongs two classes . greeks.csv - Supplemental metadata , available training set . Alpha Identifies type age-related condition , present . age-related condition . Corresponds class 0 . B , , G three age-related conditions . Correspond class 1 . Beta , Gamma , Delta Three experimental characteristics . Epsilon date data subject collected . Note data test set collected training set collected . sample_submission.csv - sample submission file correct format . See Evaluation page details ."
1starJ,Im using Rust programming language How do I add two unsigned 32bit integers,'m using Rust programming language . add two unsigned 32-bit integers ?
mpses,"

71
710 191MTG71319


httpsformsgleAhYy6YxfbdQVFigJ8　624
DeepTech202372024315DeepTech
FW


Receiveddate20230617


Extract pieces of information title of schedule start date and time end date and time location notes from the message above Output like title of schedulestart date and timeend date and timelocationnotes Also output date and time based on yyyyMMdd HHmm If the piece of information does not exist output None
For example output like this 20230424 1000None","-- - 先日ご案内いたしました羽田空港バックヤードフィールドワークにつき、 空港の急激なトラフィックの回復による現場調整の都合上、7/1（土）での実施と変更になりました。 （従い、付随する協業プログラムの選考プレゼンは7/10 ( 月 ) 19時 @ 東大駒場キャンパス/オンライン併用、第1回MTGは7/13 ( 木 ) 19時に実施予定） 既にお申込みいただいた方につきましては、直前の変更となり大変恐れ入りますが別途メールでご案内の通り、フォームをご再送下さい。 また、その週であれば参加できるという方や、今作成中の事業案が空港に適用できそうになったという方も、ぜひ下記フォームよりお申込みください。 申し込みフォーム：https : //forms.gle/AhYy6YxfbdQVFigJ8 締切：6/24（土）中 また、本件は東大DeepTech講座がメインの連携先となるプログラムですが、2023/7〜2024/3での協業プログラムに関しては、先方より「選考する1チーム ( 最大5名程度）のメンバーは、全員がDeepTech講義受講生である必要はなく、学生サイドのドリームチームに弊社社員が伴走して、良い事業案を創り上げたい」と言葉を頂いております。 空港をフィールドとした事業創出に関心がありそうな方、または協業プログラム参加希望者の中で「この人をチームメイトにしたい」という方が思い当たりましたら、空港FWやプレゼンの参加にお声がけいただけますと幸いです。 不明点・質問があればいつでもお申し付けください。 よろしくお願い申し上げます。 Received-date:2023/06/17 -- - Extract pieces information ( title schedule , start date time , end date time , location , notes ) message . Output like `` [ title schedule ] ; [ start date time ] ; [ end date time ] ; [ location ] ; [ notes ] '' . Also , output date time based `` yyyy-MM-dd HH : mm '' . piece information exist , output None . example , output like `` 太郎君誕生日会 ; 2023-04-24 10:00 ; None ; 代々木公園 ; プレゼントを持ってくること。 '' ."
CakeCrusher,"reference flask apppy
from flask import Flask request jsonify
from dotenv import loaddotenv
from flaskcors import CORS
import os
import json
from datetime import datetime
from collections import deque
from typing import Dict List TypedDict
from openplugincore import openplugincompletion OpenPluginMemo
from datetime import datetime
from urllibparse import quote unquote
from openai import ChatCompletion
from pymongo import MongoClient


loaddotenv

OPENAIAPIKEY  osgetenvOPENAIAPIKEY
PORT  intosgetenvPORT
MONGODBURI  osgetenvMONGODBURI

 Setup MongoDB connection
client  MongoClientMONGODBURI tlsAllowInvalidCertificatesTrue
db  clientopenpluginio

openpluginmemo  OpenPluginMemo
openpluginmemoinit

app  Flaskname
CORSapp

approutetest methodsGET
def test
    try
         Fetch the item from the openpluginauth collection with the specified domain
        item  dbopenpluginauthfindonedomain httpsbffd1746412970ngrokfreeapp
        
         If the item is not found return a not found response
        if not item
            return jsonifyerror Item not found 404
        
         Convert the ObjectId to string before returning the item
        itemid  stritemid
        
        return jsonifyitem
    
    except Exception as e
        errorclass  typeename
        errormessage  stre
        return jsonifyerror ferrorclass error errormessage 500


reference oauth demo
 httpschatopenaicomsharecb5054773f284e1f8416dee26d423904

import json
import logging
from flask import Flask redirect request jsonify session
from oauthliboauth2 import WebApplicationClient
import requests
import os

import urllib

osenvironOAUTHLIBINSECURETRANSPORT  1

app  Flaskname

 Configuration
appsecretkey  supersecretkey   For session management
CLIENTID  id
CLIENTSECRET  secret
AUTHORIZATIONURL  httplocalhost3333oauth
TOKENURL  httplocalhost3333authoauthexchange
CALLBACKURL  httplocalhost3001apicallback
AUTHORIZATIONCONTENTTYPE  applicationjson

 Initialize the client
client  WebApplicationClientCLIENTID

 Setup logging
loggingbasicConfiglevelloggingDEBUG

approute
def index
     Generate a unique state value for this request
    state  osurandom16hex
    sessionstate  state

     Generate the URL to which well redirect the user for authentication
    authorizationurl headers   clientprepareauthorizationrequest
        authorizationurlAUTHORIZATIONURL
        statestate
        redirecturlCALLBACKURL
    
    printHeaders  headers

    printAuthorization URL  authorizationurl

    loggingdebugfRedirecting user to authorizationurl
    return redirectauthorizationurl

Please complete the following tasks
   GET oauthinitialization endpoint
     it will receive as params clientid string clientdomain string authorizationurl string tokenurl string openplugincallbackurl string authorizationcontenttype string
     the session should store all of these variables so that once the user is done authenticating at the authorizationurl this session can be retrieved
     use clientprepareauthorizationrequest and redirect the user to the authorizationurl

notice how oauthlib is not setup so make sure to set that up along with its installation","reference flask ./app.py : flask import Flask , request , jsonify dotenv import load_dotenv flask_cors import CORS import os import json datetime import datetime collections import deque typing import Dict , List , TypedDict openplugincore import openplugin_completion , OpenPluginMemo datetime import datetime urllib.parse import quote , unquote openai import ChatCompletion pymongo import MongoClient load_dotenv ( ) OPENAI_API_KEY = os.getenv ( 'OPENAI_API_KEY ' ) PORT = int ( os.getenv ( 'PORT ' ) ) MONGODB_URI = os.getenv ( 'MONGODB_URI ' ) # Setup MongoDB connection client = MongoClient ( MONGODB_URI , tlsAllowInvalidCertificates=True ) db = client [ `` openplugin-io '' ] open_plugin_memo = OpenPluginMemo ( ) open_plugin_memo.init ( ) app = Flask ( __name__ ) CORS ( app ) ... @ app.route ( '/test ' , methods= [ 'GET ' ] ) def test ( ) : try : # Fetch item 'openplugin-auth ' collection specified domain item = db [ `` openplugin-auth '' ] .find_one ( { `` domain '' : `` https : //bffd-174-64-129-70.ngrok-free.app '' } ) # item found , return found response item : return jsonify ( { `` error '' : `` Item found '' } ) , 404 # Convert ObjectId string returning item item [ `` _id '' ] = str ( item [ `` _id '' ] ) return jsonify ( item ) except Exception e : error_class = type ( e ) .__name__ error_message = str ( e ) return jsonify ( { `` error '' : f '' { error_class } error : { error_message } '' } ) , 500 ... reference oauth demo : # https : //chat.openai.com/share/cb505477-3f28-4e1f-8416-dee26d423904 import json import logging flask import Flask , redirect , request , jsonify , session oauthlib.oauth2 import WebApplicationClient import requests import os import urllib os.environ [ 'OAUTHLIB_INSECURE_TRANSPORT ' ] = ' 1' app = Flask ( __name__ ) # Configuration app.secret_key = 'supersecretkey ' # session management CLIENT_ID = 'id' CLIENT_SECRET = 'secret' AUTHORIZATION_URL = 'http : //localhost:3333/oauth' TOKEN_URL = 'http : //localhost:3333/auth/oauth_exchange' CALLBACK_URL = `` http : //localhost:3001/api/callback '' AUTHORIZATION_CONTENT_TYPE = `` application/json '' # Initialize client client = WebApplicationClient ( CLIENT_ID ) # Setup logging logging.basicConfig ( level=logging.DEBUG ) @ app.route ( `` / '' ) def index ( ) : # Generate unique state value request state = os.urandom ( 16 ) .hex ( ) session [ 'state ' ] = state # Generate URL 'll redirect user authentication authorization_url , headers , _ = client.prepare_authorization_request ( authorization_url=AUTHORIZATION_URL , state=state , redirect_url=CALLBACK_URL ) print ( `` Headers : `` , headers ) print ( `` Authorization URL : `` , authorization_url ) logging.debug ( f '' Redirecting user { authorization_url } '' ) return redirect ( authorization_url ) Please complete following tasks : - [ ] GET ` /oauth_initialization ` endpoint - [ ] receive params ` { client_id : string , client_domain : string , authorization_url : string , token_url : string , openplugin_callback_url : string , authorization_content_type : string } ` - [ ] session store variables user done authenticating ` authorization_url ` session retrieved - [ ] use ` client.prepare_authorization_request ` redirect user ` authorization_url ` notice oauthlib setup , make sure set , along installation"
maro114510,"
1pageA4
JavaScriptpagepage
",現在マークダウン形式のファイルをパーサーを使用してドキュメントを作成するアプリを開発中です。 1ページあたりをpageクラスで囲い、大きさを指定してA4で印刷できるようにしています。 JavaScriptでpageクラスの高さからはみ出た場合、次のページとしてpageクラスをはみ出たクラスの直後に作成し、はみ出た要素を移動させたいです。 特に注意してほしいのが、はみ出た要素を移動させるときにむやみに移動させると終了タグと開始タグがめちゃくちゃになるので、改ページをするときに親子関係がある要素はきちんと終了タグをうって改頁し、新しく移動させた先ではきちんと開始タグをうってください。
mgroves,Unknown,Unknown
crogonint,I have a list of file indexes followed by their file names Some of the files have the same name when converted to lowercase Rename the duplicate files to make them unique Here are the files,list file indexes followed file names . files name converted lowercase . Rename duplicate files make unique . files :
HiroIshida,softhard,連続最適化問題の文脈でのsoftな制約条件とhardな制約条件の違いを説明して
simonw,"I need help naming a project Its a thing that sets up triggers on SQLite tables to track  in a separate table  the timestamp at which every row in the main table was last inserted updated or deleted

I thought about calling it sqlitechanges or sqlitehistory but both of those imply that it tracks what values changed  it doesnt it just tracks when the record was changed

Suggest lots of name options like that justify them ","need help naming project . 's thing sets triggers SQLite tables track - separate table - timestamp every row main table last inserted , updated deleted thought calling sqlite-changes sqlite-history imply tracks values changed - n't , tracks record changed Suggest lots name options like , justify"
0xai,"LanguageEnglish  English
LanguageChinese  
LanguageFrench  Franais
LanguageGerman  Deutsch
LanguageKorean  
LanguageEsperanto  Esperanto
LanguageJapanese  
LanguageAfrikaans  
LanguageAlbanian  
LanguageArabic  
LanguageArmenian  
LanguageAzerbaijani  
LanguageBasque  
LanguageBelarusian  
LanguageBengali  
LanguageBokmal  
LanguageBosnian  
LanguageBulgarian  
LanguageCatalan  
LanguageCroatian  
LanguageCzech  
LanguageDanish  
LanguageDutch  
LanguageEstonian  
LanguageFinnish  
LanguageGanda  
LanguageGeorgian  
LanguageGreek  
LanguageGujarati  
LanguageHebrew  
LanguageHindi  
LanguageHungarian  
LanguageIcelandic  
LanguageIndonesian  
LanguageIrish  
LanguageItalian  
LanguageKazakh  
LanguageLatin  
LanguageLatvian  
LanguageLithuanian  
LanguageMacedonian  
LanguageMalay  
LanguageMaori  
LanguageMarathi  
LanguageMongolian  
LanguageNynorsk  
LanguagePersian  
LanguagePolish  
LanguagePortuguese  
LanguagePunjabi  
LanguageRomanian  
LanguageRussian  
LanguageSerbian  
LanguageShona  
LanguageSlovak  
LanguageSlovene  
LanguageSomali  
LanguageSotho  
LanguageSpanish  
LanguageSwahili  
LanguageSwedish  
LanguageTagalog  
LanguageTamil  
LanguageTelugu  
LanguageThai  
LanguageTsonga  
LanguageTswana  
LanguageTurkish  
LanguageUkrainian  
LanguageUrdu  
LanguageVietnamese  
LanguageWelsh  
LanguageXhosa  
LanguageYoruba  
LanguageZulu  ",Language : :English = > ( English ) Language : :Chinese = > ( 中文 ) Language : :French = > ( Français ) Language : :German = > ( Deutsch ) Language : :Korean = > ( 한국어 ) Language : :Esperanto = > ( Esperanto ) Language : :Japanese = > ( 日本語 ) Language : :Afrikaans = > ( ? ) Language : :Albanian = > ( ? ) Language : :Arabic = > ( ? ) Language : :Armenian = > ( ? ) Language : :Azerbaijani = > ( ? ) Language : :Basque = > ( ? ) Language : :Belarusian = > ( ? ) Language : :Bengali = > ( ? ) Language : :Bokmal = > ( ? ) Language : :Bosnian = > ( ? ) Language : :Bulgarian = > ( ? ) Language : :Catalan = > ( ? ) Language : :Croatian = > ( ? ) Language : :Czech = > ( ? ) Language : :Danish = > ( ? ) Language : :Dutch = > ( ? ) Language : :Estonian = > ( ? ) Language : :Finnish = > ( ? ) Language : :Ganda = > ( ? ) Language : :Georgian = > ( ? ) Language : :Greek = > ( ? ) Language : :Gujarati = > ( ? ) Language : :Hebrew = > ( ? ) Language : :Hindi = > ( ? ) Language : :Hungarian = > ( ? ) Language : :Icelandic = > ( ? ) Language : :Indonesian = > ( ? ) Language : :Irish = > ( ? ) Language : :Italian = > ( ? ) Language : :Kazakh = > ( ? ) Language : :Latin = > ( ? ) Language : :Latvian = > ( ? ) Language : :Lithuanian = > ( ? ) Language : :Macedonian = > ( ? ) Language : :Malay = > ( ? ) Language : :Maori = > ( ? ) Language : :Marathi = > ( ? ) Language : :Mongolian = > ( ? ) Language : :Nynorsk = > ( ? ) Language : :Persian = > ( ? ) Language : :Polish = > ( ? ) Language : :Portuguese = > ( ? ) Language : :Punjabi = > ( ? ) Language : :Romanian = > ( ? ) Language : :Russian = > ( ? ) Language : :Serbian = > ( ? ) Language : :Shona = > ( ? ) Language : :Slovak = > ( ? ) Language : :Slovene = > ( ? ) Language : :Somali = > ( ? ) Language : :Sotho = > ( ? ) Language : :Spanish = > ( ? ) Language : :Swahili = > ( ? ) Language : :Swedish = > ( ? ) Language : :Tagalog = > ( ? ) Language : :Tamil = > ( ? ) Language : :Telugu = > ( ? ) Language : :Thai = > ( ? ) Language : :Tsonga = > ( ? ) Language : :Tswana = > ( ? ) Language : :Turkish = > ( ? ) Language : :Ukrainian = > ( ? ) Language : :Urdu = > ( ? ) Language : :Vietnamese = > ( ? ) Language : :Welsh = > ( ? ) Language : :Xhosa = > ( ? ) Language : :Yoruba = > ( ? ) Language : :Zulu = > ( ? )
florian-lefebvre,using sqljs how can I load extensions such as generateseries,"using sql.js , load extensions generate_series ?"
bbelderbos,I have post and comment models in django 1 to many relation I want to get number of comments per post for the posts homepage I want to do it efficiently to not hit the n1 problem what would be a good way using the orm annotate,"post comment models django ( 1 many relation ) , want get number comments per post posts homepage , want efficiently hit n+1 problem , would good way using orm , annotate ?"
NaoyaFukuma,Nginx return URL,Nginx でreturn ディレクティブのリダイレクトURLの指定の仕方を教えてください
cdrini,"We need to fix some bad data in Open Library Some edition records have null lccns set Eg lccn null We need to remove these lccn fields

APIs to use

GET httpsopenlibraryorgworkkeyeditionsjson  Fetch the list of editions 
     limit the number of items to get Defaults to 50
     offset
Sample request
GET httpsopenlibraryorgworksOL82548Weditionsjsonlimit1offset1
Response 
    links 
        self worksOL82548Weditionsjsonlimit1offset1
        work worksOL82548W
        prev worksOL82548Weditionsjsonoffset0limit1
        next worksOL82548Weditionsjsonoffset2limit1
    
    size 168
    entries 
        
            type 
                key typeedition
            
            authors 
                
                    key authorsOL12498918A
                
            
            localid 
                urnbwbskuP8BBS730
            
            publishdate 2008
            publishers 
                Naufaul
            
            sourcerecords 
                promisebwbdailypallets20221108P8BBS730
            
            title u0647u0627u0631u064a u0628u0648u062au0631 u0648 u062cu0645u0627u0639u0629 u0627u0644u0639u0646u0642u0627u0621
            fulltitle Harry Potter and the Order of the Phoenix Arabic Edition
            works 
                
                    key worksOL82548W
                
            
            key booksOL46921440M
            identifiers 
            isbn10 
                9771438794
            
            isbn13 
                9789771438793
            
            ocaid harrypotterorder0000jkro
            classifications 
            physicalformat paperback
            languages 
                
                    key languagesara
                
            
            translationof Harry Potter and the Order of the Phoenix
            translatedfrom 
                
                    key languageseng
                
            
            covers 
                14342039
            
            latestrevision 4
            revision 4
            created 
                type typedatetime
                value 20230228T015336229326
            
            lastmodified 
                type typedatetime
                value 20230605T140732637757
            
        
    


PUT httpsopenlibraryorgolkeyjson  Update the JSON for an openlibrary work or edition The body should be the edition record Assume already authenticated

I have a file with work keys like so


worksOL12625881W
worksOL151463W
worksOL1520454W



Write python code to iterate over the work keys in the file worksnulllccntxt and remove any cases where lccn is None","need fix bad data Open Library . edition records null lccns set . Eg ` lccn : [ null ] ` . need remove lccn fields . APIs use : GET https : //openlibrary.org { work_key } /editions.json - Fetch list editions - limit : number items get . Defaults 50 - offset Sample request : GET https : //openlibrary.org/works/OL82548W/editions.json ? limit=1 & offset=1 Response : { `` links '' : { `` self '' : `` /works/OL82548W/editions.json ? limit=1 & offset=1 '' , `` work '' : `` /works/OL82548W '' , `` prev '' : `` /works/OL82548W/editions.json ? offset=0 & limit=1 '' , `` next '' : `` /works/OL82548W/editions.json ? offset=2 & limit=1 '' } , `` size '' : 168 , `` entries '' : [ { `` type '' : { `` key '' : `` /type/edition '' } , `` authors '' : [ { `` key '' : `` /authors/OL12498918A '' } ] , `` local_id '' : [ `` urn : bwbsku : P8-BBS-730 '' ] , `` publish_date '' : `` 2008 '' , `` publishers '' : [ `` Naufaul '' ] , `` source_records '' : [ `` promise : bwb_daily_pallets_2022-11-08 : P8-BBS-730 '' ] , `` title '' : `` \u0647\u0627\u0631\u064a \u0628\u0648\u062a\u0631 \u0648 \u062c\u0645\u0627\u0639\u0629 \u0627\u0644\u0639\u0646\u0642\u0627\u0621 '' , `` full_title '' : `` Harry Potter Order Phoenix ( Arabic Edition ) '' , `` works '' : [ { `` key '' : `` /works/OL82548W '' } ] , `` key '' : `` /books/OL46921440M '' , `` identifiers '' : { } , `` isbn_10 '' : [ `` 9771438794 '' ] , `` isbn_13 '' : [ `` 9789771438793 '' ] , `` ocaid '' : `` harrypotterorder0000jkro '' , `` classifications '' : { } , `` physical_format '' : `` paperback '' , `` languages '' : [ { `` key '' : `` /languages/ara '' } ] , `` translation_of '' : `` Harry Potter Order Phoenix '' , `` translated_from '' : [ { `` key '' : `` /languages/eng '' } ] , `` covers '' : [ 14342039 ] , `` latest_revision '' : 4 , `` revision '' : 4 , `` created '' : { `` type '' : `` /type/datetime '' , `` value '' : `` 2023-02-28T01:53:36.229326 '' } , `` last_modified '' : { `` type '' : `` /type/datetime '' , `` value '' : `` 2023-06-05T14:07:32.637757 '' } } ] } PUT https : //openlibrary.org { ol_key } .json - Update JSON openlibrary work edition . body edition record . Assume already authenticated . file work keys like : `` ` /works/OL12625881W /works/OL151463W /works/OL1520454W `` ` Write python code iterate work keys file ` works-null-lccn.txt ` , remove cases lccn ` [ None ] ` ."
MaartenHilferink,I want to get the logical scale factor for the monitor of an applicationss main window using windowsgdi,"want get logical scale factor monitor applications 's main window , using windows-gdi"
mahrud,"Im building some software on MacOS and I have trouble with linking For some reason my software Macaulay2 links to specific versions of dynamic libraries and then breaks as soon as the minor version of the library changes Here is an example

M2
dyld14042 Library not loaded usrlocalopticu4cliblibicudata72dylib
  Referenced from A01D2E6D709130819A779D6F8BB8A1C6 usrlocalCellarmacaulay2122binM2binary
  Reason tried usrlocalbinlibMacaulay2liblibicudata72dylib no such file libicudata72dylib no such file usrlocalopticu4cliblibicudata72dylib no such file SystemVolumesPrebootCryptexesOSusrlocalopticu4cliblibicudata72dylib no such file usrlocalopticu4cliblibicudata72dylib no such file usrlocalliblibicudata72dylib no such file usrliblibicudata72dylib no such file not in dyld cache usrlocalbinlibMacaulay2liblibicudata72dylib no such file libicudata72dylib no such file usrlocalCellaricu4c732liblibicudata72dylib no such file SystemVolumesPrebootCryptexesOSusrlocalCellaricu4c732liblibicudata72dylib no such file usrlocalCellaricu4c732liblibicudata72dylib no such file usrlocalliblibicudata72dylib no such file usrliblibicudata72dylib no such file not in dyld cache
1    14042 abort      M2

I do have libicu73 though ","'m building software MacOS trouble linking . reason software ( Macaulay2 ) links specific versions dynamic libraries breaks soon minor version library changes . example : M2 dyld [ 14042 ] : Library loaded : /usr/local/opt/icu4c/lib/libicudata.72.dylib Referenced : < A01D2E6D-7091-3081-9A77-9D6F8BB8A1C6 > /usr/local/Cellar/macaulay2/1.22/bin/M2-binary Reason : tried : '/usr/local/bin/ .. /lib/Macaulay2/lib/libicudata.72.dylib ' ( file ) , '/libicudata.72.dylib ' ( file ) , '/usr/local/opt/icu4c/lib/libicudata.72.dylib ' ( file ) , '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/icu4c/lib/libicudata.72.dylib ' ( file ) , '/usr/local/opt/icu4c/lib/libicudata.72.dylib ' ( file ) , '/usr/local/lib/libicudata.72.dylib ' ( file ) , '/usr/lib/libicudata.72.dylib ' ( file , dyld cache ) , '/usr/local/bin/ .. /lib/Macaulay2/lib/libicudata.72.dylib ' ( file ) , '/libicudata.72.dylib ' ( file ) , '/usr/local/Cellar/icu4c/73.2/lib/libicudata.72.dylib ' ( file ) , '/System/Volumes/Preboot/Cryptexes/OS/usr/local/Cellar/icu4c/73.2/lib/libicudata.72.dylib ' ( file ) , '/usr/local/Cellar/icu4c/73.2/lib/libicudata.72.dylib ' ( file ) , '/usr/local/lib/libicudata.72.dylib ' ( file ) , '/usr/lib/libicudata.72.dylib ' ( file , dyld cache ) [ 1 ] 14042 abort M2 libicu.73 though ."
ChristopherRabotin,"Help me design some rust code for nostd that supports the following

 High level description

Rotations are a key component of attitude and orientation parameters At first ANISE only supports Direct Cosine Matrix math This is a redundant representation of rotations and therefore not an optimal one

The purpose of this issue is to design and implement a correct SO3 group for use in ANISE Currently work by Greg and Chris in commit 04b719f76a36d97be31941e4480f2da6a18c1381 have an early draft of what is needed for rotations in srcmathrotationmodrs

Some useful resources
 Wikipedia on SO3httpsenwikipediaorgwiki3Drotationgroup
 RigidBodyKinematicpyhttpsbitbucketorgavslabbasilisksrcdevelopsrcutilitiesRigidBodyKinematicspy is Basilisks set of conversions between different attitude representations
 Sophus ChttpsgithubcomstrasdatSophus is a Lie group implementation in C
 Mathoverflowhttpsmathoverflownetquestions81247whatisthestructureofso3anditsliealgebra
 PyQuathttpsgithubcomtranslunarpyquat is an excellent resource for quaternion math uses the Shulster notation
 This PDFhttpsgithubcomnurlanovzhso3logmapblobmainSO3transformationspdf seems to provide good information on how to derive different representations

 Requirements

1 Rotation structures shall be composablehttpsenwikipediaorgwikiFunctioncomposition
   1 Composition between different representations shall be supported
   2 Composition between different representations shall use the most efficient calculation that maintains accuracy efficient as least number of instructions as determined by iaicachegrind
2 Rotations shall check the source and destination frames to prevent invalid rotations this can probably not be done at compile time
3 The following representations shall be supported at a minimum
   1 Direct Cosine Matrix DCM
   2 Quaternions shall be supported in their natural form i j k scalar but a conversion to and from Shuster notation shall also be supported httpspossiblywrongwordpresscom20210510bewarethenaturalquaternion
   3 Modified Rodrigez Parameters cf Springerhttpslinkspringercomarticle101007s108510170765x and SchaubhttphanspeterschaubinfoPapersPrivateOKeefe2014apdf
   4 Representations shall be unambiguous on initialization and getters eg a quaterion shall not be publicly indexable because thats confusion to the user who might not remember the storage order
4 All representations shall provide relevant helpers
   1 Quaternions shall provide at a minimum a conjugate function and a short direction function
   2 MRPs shall provide at a minimum a shadow set representation
5 All computations shall be checked for math domain errors and return AniseErrorMathError where relevant
6 All representation shall allow for rotation of both vectors and matrices and ensure that matrices are rotated using CT  A  C
7 More Should we this also provide the timederivatives of each representation That could be useful","Help design rust code no-std supports following . # High level description Rotations key component attitude orientation parameters . first , ANISE supports Direct Cosine Matrix math . redundant representation rotations therefore optimal one . purpose issue design implement _correct_ ( 3 ) group use ANISE . Currently , work Greg Chris commit 04b719f76a36d97be31941e4480f2da6a18c1381 , early draft needed rotations src/math/rotation/mod.rs . useful resources : + [ Wikipedia ( 3 ) ] ( https : //en.wikipedia.org/wiki/3D_rotation_group ) + [ RigidBodyKinematic.py ] ( https : //bitbucket.org/avslab/basilisk/src/develop/src/utilities/RigidBodyKinematics.py ) Basilisk 's set conversions different attitude representations + [ Sophus ( C++ ) ] ( https : //github.com/strasdat/Sophus ) Lie group implementation C++ + [ Mathoverflow ] ( https : //mathoverflow.net/questions/81247/what-is-the-structure-of-so3-and-its-lie-algebra ) + [ PyQuat ] ( https : //github.com/translunar/pyquat ) excellent resource quaternion math ( uses Shulster notation ) + [ PDF ] ( https : //github.com/nurlanov-zh/so3_log_map/blob/main/SO3_transformations.pdf ) seems provide good information derive different representations . # Requirements 1 . Rotation structures shall [ composable ] ( https : //en.wikipedia.org/wiki/Function_composition ) 1 . Composition different representations shall supported 2 . Composition different representations shall use efficient calculation maintains accuracy ( efficient `` least number instructions '' , determined iai/cachegrind ) 2 . Rotations shall check source destination frames prevent invalid rotations ( probably done compile time ) 3 . following representations shall supported minimum : 1 . Direct Cosine Matrix ( DCM ) 2 . Quaternions shall supported `` natural '' form ( , j , k , scalar ) , conversion Shuster notation shall also supported ( https : //possiblywrong.wordpress.com/2021/05/10/beware-the-natural-quaternion/ ) 3 . Modified Rodrigez Parameters ( cf . [ Springer ] ( https : //link.springer.com/article/10.1007/s10851-017-0765-x ) [ Schaub ] ( http : //hanspeterschaub.info/PapersPrivate/OKeefe2014a.pdf ) ) 4 . Representations shall unambiguous initialization getters ( e.g . quaterion shall publicly indexable 's confusion user might remember storage order ) 4 . representations shall provide relevant helpers 1 . Quaternions shall provide minimum conjugate function `` short direction '' function 2 . MRPs shall provide minimum shadow set representation 5 . computations shall checked math domain errors return ` AniseError : :MathError ` relevant . 6 . representation shall allow rotation vectors matrices ( ensure matrices rotated using ` C^T * * C ` ) 7 . _More ? also provide time-derivatives representation ? could useful )"
hjonin,"Hello GPT I have a function that enables to automate commit on a remote git repo  
Problem is its a bit slow because currently its pure  
Every time its called its cloning the repo again I think we could improve performance by throing a little cache in there you know what I mean  
Im thinking the repos would be cloned in nodemodulescachegitSSHxxx  
We would have a directory for every repobranch  
The would enable to just git pull wich I assume woule be faster that cloning  
Following in the code can you help me acheive what I want  

ts
import  exec  from exec
import  join as pathJoin  from path
import  as fs from fs
import  as runExclusive from runexclusive

export const gitSsh  runExclusivebuild
    async params 
        workingDirectoryPath string
        sshUrl string  eg gitgithubcomgarronejevtgit
        sshPrivateKeyName string
        sshPrivateKey string
        shaish string
        commitAuthorEmail string
        action params 
            repoPath string
          Promise doCommit false    doCommit true doAddAll boolean message string 
      
        const 
            workingDirectoryPath  processcwd
            sshUrl
            sshPrivateKeyName
            sshPrivateKey
            shaish
            commitAuthorEmail  actionsgithubcom
            action
          params

        await configureOpenSshClient sshPrivateKeyName sshPrivateKey 

        const repoDirBasename  gitSshDatenow

        const repoPath  pathJoinworkingDirectoryPath repoDirBasename

        await execrm rf repoDirBasename 
            cwd workingDirectoryPath
        

        if shaish  undefined 
            await execgit clone depth 1 sshUrl repoDirBasename  cwd workingDirectoryPath 
         else 
            if isShashaish 
                await execgit clone sshUrl repoDirBasename  cwd workingDirectoryPath 

                try 
                    await execgit checkout shaish  cwd repoPath 
                 catch e 
                    throw new ErrorNoBranchStringe
                
             else 
                try 
                    await execgit clone branch shaish depth 1 sshUrl repoDirBasename 
                        cwd workingDirectoryPath
                    
                 catch e 
                    if Stringeincludesshaish 
                        throw new ErrorNoBranchStringe
                    

                    throw e
                
            
        

        const changesResult  await async   
            try 
                return await action repoPath 
             catch error 
                return error as Error
            
        

        commit 
            if changesResult instanceof Error  changesResultdoCommit 
                break commit
            

            if await execgit status porcelain  cwd repoPath    
                consolelogNo change
                break commit
            

            await execgit config local useremail commitAuthorEmail 
                cwd repoPath
            
            await execgit config local username commitAuthorEmailsplit0  cwd repoPath 

            if changesResultdoAddAll 
                await execgit add A  cwd repoPath 
            

            await execgit commit am changesResultmessage 
                cwd repoPath
            

            await execgit push  cwd repoPath 
        

        await execrm r repoDirBasename  cwd workingDirectoryPath 

        if changesResult instanceof Error 
            throw changesResult
        
    


export class ErrorNoBranch extends Error 
    constructormessage string 
        supermessage
        ObjectsetPrototypeOfthis newtargetprototype
    


async function configureOpenSshClientparams  sshPrivateKeyName string sshPrivateKey string  
    const  sshPrivateKey sshPrivateKeyName   params

    const sshConfigDirPath  await execcd   mkdir p ssh  cd ssh  pwdreplacern 

    await fspromiseswriteFile
        pathJoinsshConfigDirPath sshPrivateKeyName
        BufferfromsshPrivateKeyreplaceng n utf8
         mode 0o600 
    

    const sshConfigFilePath  pathJoinsshConfigDirPath config

    const doesSshConfigFileExists  await fspromisesstatsshConfigFilePathcatch  null

    if doesSshConfigFileExists 
        return
    

    await fspromiseswriteFilesshConfigFilePath BufferfromStrictHostKeyCheckingnon utf8


function isShashaish string boolean 
    return 09af740itestshaish

","Hello GPT , function enables automate commit remote git repo . Problem , 's bit slow currently 's pure . Every time 's called 's cloning repo , think could improve performance throing little cache know mean ? 'm thinking , repos would cloned node_modules/.cache/gitSSH/xxx . would directory every repo+branch . would enable git pull wich assume woule faster cloning . Following code , help acheive want ? `` ` ts import { exec } `` ./exec '' ; import { join pathJoin } `` path '' ; import * fs `` fs '' ; import * runExclusive `` run-exclusive '' ; export const gitSsh = runExclusive.build ( async ( params : { workingDirectoryPath ? : string ; sshUrl : string ; // e.g . : git @ github.com : garronej/evt.git sshPrivateKeyName : string ; sshPrivateKey : string ; shaish ? : string ; commitAuthorEmail ? : string ; action : ( params : { repoPath : string ; } ) = > Promise < { doCommit : false } | { doCommit : true ; doAddAll : boolean ; message : string } > ; } ) = > { const { workingDirectoryPath = process.cwd ( ) , sshUrl , sshPrivateKeyName , sshPrivateKey , shaish , commitAuthorEmail = `` actions @ github.com '' , action } = params ; await configureOpenSshClient ( { sshPrivateKeyName , sshPrivateKey } ) ; const repoDirBasename = ` gitSsh_ $ { Date.now ( ) } ` ; const repoPath = pathJoin ( workingDirectoryPath , repoDirBasename ) ; await exec ( ` rm -rf $ { repoDirBasename } ` , { `` cwd '' : workingDirectoryPath } ) ; ( shaish === undefined ) { await exec ( ` git clone -- depth 1 $ { sshUrl } $ { repoDirBasename } ` , { `` cwd '' : workingDirectoryPath } ) ; } else { ( isSha ( shaish ) ) { await exec ( ` git clone $ { sshUrl } $ { repoDirBasename } ` , { `` cwd '' : workingDirectoryPath } ) ; try { await exec ( ` git checkout $ { shaish } ` , { `` cwd '' : repoPath } ) ; } catch ( e ) { throw new ErrorNoBranch ( String ( e ) ) ; } } else { try { await exec ( ` git clone -- branch $ { shaish } -- depth 1 $ { sshUrl } $ { repoDirBasename } ` , { `` cwd '' : workingDirectoryPath } ) ; } catch ( e ) { ( String ( e ) .includes ( shaish ) ) { throw new ErrorNoBranch ( String ( e ) ) ; } throw e ; } } } const changesResult = await ( async ( ) = > { try { return await action ( { repoPath } ) ; } catch ( error ) { return error Error ; } } ) ( ) ; commit : { ( changesResult instanceof Error || ! changesResult.doCommit ) { break commit ; } ( ( await exec ( `` git status -- porcelain '' , { `` cwd '' : repoPath } ) ) === `` '' ) { console.log ( `` change '' ) ; break commit ; } await exec ( ` git config -- local user.email `` $ { commitAuthorEmail } '' ` , { `` cwd '' : repoPath } ) ; await exec ( ` git config -- local user.name `` $ { commitAuthorEmail.split ( `` @ '' ) [ 0 ] } '' ` , { `` cwd '' : repoPath } ) ; ( changesResult.doAddAll ) { await exec ( ` git add -A ` , { `` cwd '' : repoPath } ) ; } await exec ( ` git commit -am `` $ { changesResult.message } '' ` , { `` cwd '' : repoPath } ) ; await exec ( ` git push ` , { `` cwd '' : repoPath } ) ; } await exec ( ` rm -r $ { repoDirBasename } ` , { `` cwd '' : workingDirectoryPath } ) ; ( changesResult instanceof Error ) { throw changesResult ; } } ) ; export class ErrorNoBranch extends Error { constructor ( message : string ) { super ( message ) ; Object.setPrototypeOf ( , new.target.prototype ) ; } } async function configureOpenSshClient ( params : { sshPrivateKeyName : string ; sshPrivateKey : string } ) { const { sshPrivateKey , sshPrivateKeyName } = params ; const sshConfigDirPath = ( await exec ( ` cd ~ & & mkdir -p .ssh & & cd .ssh & & pwd ` ) ) .replace ( /\r ? \n $ / , `` '' ) ; await fs.promises.writeFile ( pathJoin ( sshConfigDirPath , sshPrivateKeyName ) , Buffer.from ( sshPrivateKey.replace ( /\\n/g , `` \n '' ) , `` utf8 '' ) , { `` mode '' : 0o600 } ) ; const sshConfigFilePath = pathJoin ( sshConfigDirPath , `` config '' ) ; const doesSshConfigFileExists = ! ! ( await fs.promises.stat ( sshConfigFilePath ) .catch ( ( ) = > null ) ) ; ( doesSshConfigFileExists ) { return ; } await fs.promises.writeFile ( sshConfigFilePath , Buffer.from ( `` StrictHostKeyChecking=no\n '' , `` utf8 '' ) ) ; } function isSha ( shaish : string ) : boolean { return /^ [ 0-9a-f ] { 7,40 } $ /i.test ( shaish ) ; } `` `"
simonw,"Given this data structure

links  
    1 one
    1 two
    2 three
    2 four
    2 five
    1 six
    2 seven
    3 eight
    3 nine
    2 ten


Write a function that turns them into a tree structure like this

root  
    1 one 
    1 two 
        2 three 
        2 four 
        2 five 
    
    1 six 
        2 seven 
            3 eight 
            3 nine 
        
        2 ten 
    


Show me that running","Given data structure : links = [ ( 1 , `` one '' ) , ( 1 , `` two '' ) , ( 2 , `` three '' ) , ( 2 , `` four '' ) , ( 2 , `` five '' ) , ( 1 , `` six '' ) , ( 2 , `` seven '' ) , ( 3 , `` eight '' ) , ( 3 , `` nine '' ) , ( 2 , `` ten '' ) , ] Write function turns tree structure like : root = [ ( 1 , `` one '' , [ ] ) , ( 1 , `` two '' , [ ( 2 , `` three '' , [ ] ) , ( 2 , `` four '' , [ ] ) , ( 2 , `` five '' , [ ] ) , ] ) , ( 1 , `` six '' , [ ( 2 , `` seven '' , [ ( 3 , `` eight '' , [ ] ) , ( 3 , `` nine '' , [ ] ) , ] ) , ( 2 , `` ten '' , [ ] ) , ] ) , ] Show running ."
nuhmanpk,"WebtrenchmainzipZip ArchiveWith this library you can do for example

from Webtrench import ImageScrapper
url  httpsexamplecom
folderpath  images
ImageScrapperallimagefromurlurl folderpath

Can you document other use cases","Webtrench-main.zipZip ArchiveWith library example : Webtrench import ImageScrapper url = 'https : //example.com' folder_path = './images' ImageScrapper.all_image_from_url ( url , folder_path ) document use cases ?"
yangyang8599,Unknown,Unknown
L-M-Sherlock,"def cosineannealinglrlr stepcount Tmax etamin  0
    lr  etamin  lr  etamin  1  mathcosmathpi  stepcount  Tmax  1  mathcosmathpi  stepcount  1  Tmax
    return lr
rewrite it in rust","def cosine_annealing_lr ( lr , step_count , T_max , eta_min = 0 ) : lr = eta_min + ( lr - eta_min ) * ( 1 + math.cos ( math.pi * step_count / T_max ) ) / ( 1 + math.cos ( math.pi * ( step_count - 1 ) / T_max ) ) return lr rewrite rust"
gkholman,In major league baseball what is the overall caught stealing percentage for runners attempting to reach second base,"major league baseball , overall `` caught stealing '' percentage runners attempting reach second base ?"
zhyunk,"spring boot   
          
    
 ","spring boot로 게시판 웹앱을 만들었는데 , 게시글 작성 후 저장하기 버튼을 누른 다음 엔터를 몇번 입력하면 같은 데이터가 여러개 저장이 돼 . 이거 왜이러는거야 ?"
andykamp,"i have a diet tracker app that i can enter my dailymeals into then i can keep track of my calories and proteins every day and get analytic and graphs of how much i eat etc  the app has products which are products you can buy in a store and meals consisiting of such product each daily is of course stored whenever i enter stuff into it but i also provide ways to change existing products sinse there can be many products inside a  meal and a daily can have many meals i need to figure out a way to keep all the meals and all the dailyes in sync with the products and meals

i am using react and javascript and reactquery clientside and store the mealproductsdaily in firestore and want to know what the best practice is to keep these types in sync","diet tracker app enter dailymeals . keep track calories proteins every day get analytic graphs much eat etc . app products products buy store meals consisiting product . daily course stored whenever enter stuff . also provide ways change existing products . sinse many products inside meal , daily many meals , need figure way keep meals dailyes sync products meals .... using react javascript react-query client-side store meal/products/daily firestore , want know best practice keep types sync ?"
keckelt,Hi in javascript I calcualte the difference between two timestamps I woudl like to display the calculated difference to the user in an easily readable format Ie the amount of seconds if is less than a minute the amount of minutes if it is less than 100 minutes and the amount of hours or days if more what is the best way to do this are there built in browser functions to format the duration or popular libraries to achieve it,"Hi , javascript calcualte difference two timestamps . woudl like display calculated difference user easily readable format . I.e . amount seconds less minute , amount minutes less 100 minutes amount hours days . best way ? built browser functions format duration popular libraries achieve ?"
stefanmuellerdo,Du bist Smartstorecom Supporter Schreibe ein github issue auf englisch zu folgendem Problem in der Liste adminmodulelist in Smartstore 505 betrifft das Admins die neue Plugins also Module hochladen Es kommt dann ein kurzer Hinweis unten links in einem grnen Notification  Paket xxx wurde hochgeladen und erfolgreich entpackt Bitte laden Sie die Liste neu da mit das neugeladene Plugin in der Pluginliste erscheint Das Problem ist das ein BrowserPAgereload mit F5 nicht fubktioniert wie man es als normaler Webanwender erwartet Sondern Es muss auf den grauen Button rechts oben geklickt und dort Liste Neuladen angewhlt werden Da das nicht so offensichtlich ist sollte die NotificationText umgeschrieben werden um auf den Liste Laden Button hinzuweisen oder die Mechanik sollte so gendert werden dass ein PAge Reload auch die Liste neu ldt,"Du bist Smartstore.com Supporter . Schreibe ein github issue auf englisch zu folgendem Problem : der Liste /admin/module/list Smartstore 5.0.5 betrifft das Admins , die neue Plugins ( also `` Module '' ) hochladen . Es kommt dann ein kurzer Hinweis unten links einem grünen Notification `` Paket xxx wurde hochgeladen und erfolgreich entpüackt . Bitte laden Sie die Liste neu '' , da mit das neugeladene Plugin der Pluginliste erscheint . Das Problem ist , das ein Browser-PAgereload mit F5 nicht fubktioniert , wie man es als normaler Webanwender erwartet . Sondern : Es muss auf den grauen Button rechts oben geklickt und dort Liste Neuladen angewählt werden . Da das nicht offensichtlich ist , sollte die Notification-Text umgeschrieben werden , um auf den `` Liste Laden '' Button hinzuweisen oder die Mechanik sollte geändert werden , dass ein PAge Reload auch die Liste neu lädt ."
Ken-Watson,"I am trying to run streamlit but I get an import error

ImportError attempted relative import with no known parent package",trying run streamlit get import error : ImportError : attempted relative import known parent package
stnqls,"import React  useEffect useState  from react
import styled from emotionstyled
import  Radio RadioGroup Stack useEditable  from chakrauireact
import  exerciseType  from componentsPracticalIconPracticalType
import ExclamationMark from publicimagesiconsexclamationsvg
import  FieldValues UseFormGetValues UseFormRegister UseFormSetValue  from reacthookform

interface Props 
  type string
  index number
  practicalScore string
  lastType number
  goPrevStep   void
  goNextStep   void
  register UseFormRegisterFieldValues
  setValue UseFormSetValueFieldValues
  getValues UseFormGetValuesFieldValues


const PracticalScoreInputForm  props Props  
  const exerciseIcon  exerciseTypepropstype   text  icon  

  return 
    Container
      FormContainer
        Title  Title
        Information
          InfoIconWrapper
            ExclamationMark 
          InfoIconWrapper
                
        Information
        PracticalName
          ExerciseIconWrapperexerciseIconiconExerciseIconWrapper
          exerciseIcontext
        PracticalName
        propspracticalScore  
            
          Content
            RadioGroup
              Stack directioncolumn
                propspracticalScoremapitem index  
                  consolelogitem propsgetValuesexerciseIcontext  item
                  return 
                    Radio propsregisterexerciseIcontext  required   onChange e  propssetValueexerciseIcontext etargetvalue  keyindex valueitem variantoutline
                      item
                    Radio
                  
                
              Stack
            RadioGroup
          Content
          
            
          Content
            InputWrapper
              Input propsregisterexerciseIcontext  value  required    
              MetricUnitscmMetricUnits
            InputWrapper
          Content
        

        Buttons
          Button typebutton onClickpropsgoPrevStep
            
          Button
          Button typebutton next onClickpropsgoNextStep
            
          Button
        Buttons
      FormContainer
    Container
  


export default PracticalScoreInputForm

const Container  styleddiv
  height 636px
  backgroundcolor props  propsthemecolorsgray6
  borderradius 0 0 16px 16px
  display flex
  alignitems center
  justifycontent center


const FormContainer  styleddiv
  minwidth 400px
  backgroundcolor fff
  padding 32px
  borderradius 24px


const Title  styleddiv
  fontsize 20px
  lineheight 24px
  fontweight 700
  color props  propsthemecolorsblack
  marginbottom 12px


const Information  styleddiv
  borderradius 16px
  padding 8px 16px
  backgroundcolor rgba255 68 68 01
  display flex
  gap 0 4px
  fontsize 12px
  fontweight 600
  lineheight 16px
  color props  propsthemecolorsred
  marginbottom 32px


const InfoIconWrapper  styleddiv
  width 16px
  height 16px
  color props  propsthemecolorsred


const PracticalName  styleddiv
  display flex
  alignitems center
  gap 0 8px
  fontsize 16px
  lineheight 20px
  fontweight 700
  color props  propsthemecolorsgray1
  marginbottom 8px


const ExerciseIconWrapper  styleddiv
  width 20px
  height 20px
  color props  propsthemecolorsblue


const Content  styleddiv

const Buttons  styleddiv
  display flex
  gap 0 12px
  margintop 32px


const Button  styledbutton next 
  flex 1
  height 44px
  borderradius 16px
  backgroundcolor props  propsnext  propsthemecolorsblue  propsthemecolorsgray4
  fontsize 16px
  fontweight 700
  lineheight 20px
  color props  propsnext  propsthemecolorswhite  propsthemecolorsgray1


const InputWrapper  styleddiv
  width 100
  height 44px
  borderradius 16px
  border 1px solid props  propsthemecolorsgray4
  padding 0px 45px
  position relative


const Input  styledinput
  fontsize 14px
  lineheight 20px
  fontweight 600
  color props  propsthemecolorsgrayBlack
  textalign right
  position absolute
  top 14px
  right 45px


const MetricUnits  styleddiv
  fontsize 14px
  lineheight 16px
  fontweight 600
  color props  propsthemecolorsgray1
  position absolute
  top 14px
  right 24px


               ","import React , { useEffect , useState } 'react ' ; import styled ' @ emotion/styled ' ; import { Radio , RadioGroup , Stack , useEditable } ' @ chakra-ui/react ' ; import { exerciseType } ' @ /components/PracticalIcon/PracticalType ' ; import ExclamationMark ' .. / .. / .. / .. / .. /public/images/icons/exclamation.svg ' ; import { FieldValues , UseFormGetValues , UseFormRegister , UseFormSetValue } 'react-hook-form ' ; interface Props { type : string ; index ? : number ; practicalScore ? : string [ ] ; lastType : number ; goPrevStep : ( ) = > void ; goNextStep : ( ) = > void ; register : UseFormRegister < FieldValues > ; setValue : UseFormSetValue < FieldValues > ; getValues : UseFormGetValues < FieldValues > ; } const PracticalScoreInputForm = ( props : Props ) = > { const exerciseIcon = exerciseType [ props.type ] || { text : '- ' , icon : `` } ; return ( < Container > < FormContainer > < Title > 실기 기록 입력 < /Title > < Information > < InfoIconWrapper > < ExclamationMark / > < /InfoIconWrapper > 기록 변경 횟수가 제한되어 있으니 신중히 입력하세요 ! < /Information > < PracticalName > < ExerciseIconWrapper > { exerciseIcon.icon } < /ExerciseIconWrapper > { exerciseIcon.text } < /PracticalName > { props ? .practicalScore ? ( // 객관식 입력 < Content > < RadioGroup > < Stack direction= '' column '' > { props ? .practicalScore.map ( ( item , index ) = > { console.log ( item , props.getValues ( exerciseIcon.text ) === item ) ; return ( < Radio { ... props.register ( exerciseIcon.text , { required : '점수를 선택해주세요 ' , onChange : e = > props.setValue ( exerciseIcon.text , e.target.value ) } ) } key= { index } value= { item } variant= '' outline '' > { item } < /Radio > ) ; } ) } < /Stack > < /RadioGroup > < /Content > ) : ( // 주관식 입력 < Content > < InputWrapper > < Input { ... props.register ( exerciseIcon.text , { value : `` , required : '점수를 입력해주세요 ' } ) } / > < MetricUnits > cm < /MetricUnits > < /InputWrapper > < /Content > ) } < Buttons > < Button type= '' button '' onClick= { props.goPrevStep } > 이전 < /Button > < Button type= '' button '' next onClick= { props.goNextStep } > 다음 < /Button > < /Buttons > < /FormContainer > < /Container > ) ; } ; export default PracticalScoreInputForm ; const Container = styled.div ` height : 636px ; background-color : $ { props = > props.theme.colors.gray6 } ; border-radius : 0 0 16px 16px ; display : flex ; align-items : center ; justify-content : center ; ` ; const FormContainer = styled.div ` min-width : 400px ; background-color : # fff ; padding : 32px ; border-radius : 24px ; ` ; const Title = styled.div ` font-size : 20px ; line-height : 24px ; font-weight : 700 ; color : $ { props = > props.theme.colors.black } ; margin-bottom : 12px ; ` ; const Information = styled.div ` border-radius : 16px ; padding : 8px 16px ; background-color : rgba ( 255 , 68 , 68 , 0.1 ) ; display : flex ; gap : 0 4px ; font-size : 12px ; font-weight : 600 ; line-height : 16px ; color : $ { props = > props.theme.colors.red } ; margin-bottom : 32px ; ` ; const InfoIconWrapper = styled.div ` width : 16px ; height : 16px ; color : $ { props = > props.theme.colors.red } ; ` ; const PracticalName = styled.div ` display : flex ; align-items : center ; gap : 0 8px ; font-size : 16px ; line-height : 20px ; font-weight : 700 ; color : $ { props = > props.theme.colors.gray1 } ; margin-bottom : 8px ; ` ; const ExerciseIconWrapper = styled.div ` width : 20px ; height : 20px ; color : $ { props = > props.theme.colors.blue } ; ` ; const Content = styled.div `` ; const Buttons = styled.div ` display : flex ; gap : 0 12px ; margin-top : 32px ; ` ; const Button = styled.button < { next ? } > ` flex : 1 ; height : 44px ; border-radius : 16px ; background-color : $ { props = > ( props.next ? props.theme.colors.blue : props.theme.colors.gray4 ) } ; font-size : 16px ; font-weight : 700 ; line-height : 20px ; color : $ { props = > ( props.next ? props.theme.colors.white : props.theme.colors.gray1 ) } ; ` ; const InputWrapper = styled.div ` width : 100 % ; height : 44px ; border-radius : 16px ; border : 1px solid $ { props = > props.theme.colors.gray4 } ; padding : 0px 45px ; position : relative ; ` ; const Input = styled.input ` font-size : 14px ; line-height : 20px ; font-weight : 600 ; color : $ { props = > props.theme.colors.grayBlack } ; text-align : right ; position : absolute ; top : 14px ; right : 45px ; ` ; const MetricUnits = styled.div ` font-size : 14px ; line-height : 16px ; font-weight : 600 ; color : $ { props = > props.theme.colors.gray1 } ; position : absolute ; top : 14px ; right : 24px ; ` ; 이 코드가 있는데 다음버튼을 누르고 이전버튼을 눌러서 다시 돌아오면 왜 이전에 선택해놨던값이 그대로 유지가 안될까 ?"
harshvardhanbarhan,send otp to phone number using kreaitfirebasephp 7,send otp phone number using kreait/firebase-php 7
tegefaulkes,What is jsonrpc id used for,jsonrpc id used ?
liusida,"what language is this

 Minimum Salary

interface Employee 
  minimumSalary  100000
  name  
  salary
  constraint MinimumSalary 
    emit constraint constraintName employee employee raise constraintDifference 
  


joe  employee name joe salary 110000 

minimumSalary  120000

runMinimumSalary  listevents  logformatjson 
wrapWithcode block
","language : `` ` # Minimum Salary interface Employee { minimumSalary = $ 100,000 name = `` ; salary ; constraint MinimumSalary { emit ( { constraint : $ constraintName , employee : employee , raise : constraintDifference } ) } } joe = employee ( { name : `` joe '' , salary : 110,000 } ) minimumSalary = $ 120,000 ; run ( MinimumSalary ) | > list ( events ) | > log : format=json | > wrapWith ( code block ) `` `"
Af7eR9l0W,"Even if they are ordered differently can you compare the fields of the following two cookies and determine whether they match individually Do the following

1 Split the cookies by the semicolon character  to separate the namevalue pairs
2 For each namevalue pair split by the equals character  to separate the name and the value
3 Compare the names and values between the two cookies

puiduserfFZg2hsobZhDgUv7gbA6Uune1685299168t2hfcDN3h2BQSEa3s5i2BzJVpK8mT9gOhYcD3NvafAJk3D intercomdeviceiddgkjq2bp06c13abe1fb74fb3b65382dc2c580e38
intercomsessiondgkjq2bpZTFQMkFMQlg0ZHJOd2owK2ZuNnM1L3J0clIwdmZ1M0hJelo5RERSWFdhdXcwczlLYmFXZHlubG1ad1J6TUxsSS0tSGdWdkRzakRtYmhkVC92OEdPNytlUT093710aaeea2c9fa77c1744c9470ba7ccbd33b3bcd
SecurenextauthsessiontokeneyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn00NuEDqT63XjJ8nB7ctcmwUtKpCdQPLcDTIQ38cDEFpRS0DvjAyQSGzgRdhbCBJBefot93gp78VsnQ5qMmxvTmIALEsHQMsX5cVhlhFCiIA0hjlAM
o6ZCtQL29zDMV07vcyb1VSLgnuT1UVLRwzfDWmZ9SutUn5H9tNDkr9AwgGQ72uYP5rg7RvvtM9fDXcAcczLQ9Qn8tteFcBR86TJDBMZmHrzXqYwlFlVRQ8UQWw498sMSbybOdnsxumMWbonx8In2Qg3HJHyfNhFRKXWZKd3LfvGqN9LQiSNj7l
R0vCuEbRHICPpr4zsZOBvF4wX7vKLVhw8rbAsTqxqN7kLC63Wysv962nFdF0FKSSO1duWGE6m07trfA55dRcE5ScuBbqui9NIHGJZEmQXPxarT4nptP601LEcQ2pJynUruF9R3Nfe2XBThDeDV1bGGRG8YQN5K12PUyM1j3bXEau4CGa3ZKQRqlhT
1p0YBPilY15cCPPBvFZA9LV5eo6AnqIVkylQKpMedypWmJLzme5JyHjURCsZjoGQGfmEVR3TqWoAgo7eb45zrPTHyiWLMnV9bYSnEinJ3gYeFLHbhqTxnSQ3Sehu2zRGs660ETHn68UVqXNfnkIQyja8OCYo5u8kqcJUZTCdReUsjZUpSBLhJ711X
bBcE9VicGRI9jNZJ7J4eQwJXU5eeLoyTuBa07CLTF1RuhoVz51sOJeZn1ECbpK69hjCNu8bxNQdh0b1WsJovLRicuCWtV3HAplNOBc5YLBFtpanfa3lIVR7lZq2CQA4lBpzYQno2LlsHnhw1ipCcEsNAvowQ5IBCk5U1Ba1tDWgMW8WR2uLUcK9lzL
9erNn4dA7muPN0u69gqzc4lUhKPckqhpsfjVcB4FwvGUL9qYFQsU4rehEd1yHVqlqTLudEchDK7mWORp7sPNcPt3UKnyX6Z9UmhhK8N3sjkDRB6sWNg9OoDWcNkWLqiMkf6ZbGM5YBRF3P5L09tLRbdeOisYBABxQWiRl2lcjmPXAm6OR9uhYNyh
d4LnKQ833dbag8IM9QBiyHIXNJEQLd8sfZ27iCf3MF8gyn6eOvxfXuMe6MQMegyIOzU3IjNNok8RK5PxJUDHyDUy5vV0nbByTh9rJyUo1sFo9ZKeOHD2mip6KCgGw87TGG07PbCWsU8hpzrFTbP7SjqnqjXCFXiBwJcLgQfFDweuIiUu7bc7081J
8TzEtMNHG2XwPhSbJYwU0xAd8AKinq7ebmrDuhFNKQAQSC4bvkpg3M6L5RYcjdHQqCROXoh6c2dV1uPvVuwQJjFVQEmbXwGR5iK4udkdkYWB1XIbtFPhYGPXmgXf8rpDtvzv3ovDDZGv7O1NPOAtw5eP5ppkdmsrhJrQZ3XrHFhUpb0VxqbJu1au
FAzbhGnNfHWCdBj2jKhG6ixDl8aQ9GQYudc9n4ITsnD3GKiI5jqHRhzfByeOEqlZHxO7wuZ4K2NxPAwlGKMS7Psw8lEElpiLa8RdXHi93Nzrz0YrJR46iUvyn9UjQEmn7vrK3lGbMx52JF8MAxrjSWSvpuoKE5ytJsuWiztRDv8kNecB0SF
gzKEi98FROQmZF1vC01tLHrkChTN7wYlGRrlaoEjq6dx8brWo3ThCYfSCnXg6r8va2C1znztbq2c0zt1kuDP8fEMw4cpNO2rd9EO3h9ONr6fiCSQ03suEDCHcLkXh1rMY7ReHLTRlcT22fkqfoGWGekeLodvpa3KWxw5O0qD3BKtcb1c19hZqE4ov
efYO0XfbtFHK390wxgZpjxNcPMbsaHCPv9kiB4xyPQ6Ijg2Y40H70cDyXxCLh0T3EZH7PVB1J3pHQynprI8xH1eXuwxN5QA1pngI3OxFRIsfbMT1LTx9XlnrCa9vL5PeFarUaMzUM3FvF3NSkUjqyjHOl2kjbxzz4fpuz2BFqLQq0pLffyJkPBOcAk
xr6e04CICzjW0duLewdBTR9mwvVjjNQTiPvV7ku8mpcO69mQrL5V8RQ7oTTmLMHr9Jtv11PqUx4a3VLlkehmOVN1RHT9Hgxp3TZ55uzx9ofdiu7J9Umb7vXOHqf6cTrs7QjCorf2pRa8iNb9dCvJmazYCyAFPSEb942Bx3p6j9sFh4HKQ7K6Ywlj
PA0I5o8hSL1lFgIyQyiR6YPZhBDU8fZryJe5WiXdl9rKZxGwNQtKhMHkCoIrfTGiZShWXG3KevB7mBmyjbprEcUJCmjPAZk8pKO9XEHd8Moft5LXcieGmDF9i0VXL44LhEEfstoVCfuxgILQbJlig2KnYawjYa3uvmWl7MkqPPIRjJpYMuTc
4yEmoUcveHaEVvODCHpn28XxgwP6v4yAKF38XLD8PPiy4b1dmsCAT0iadYwStRDUw5nok9fYb8lUTF6QUNaD2m0hEe7hzi97ccnRzyqz8nFW0Zv7dgQkYCuxBTEW9nHtDIa96Wrda8Z7b9nTbWOWVu982lzqMbxam9QT2Se7Vqj1FBI7ihnrJGHuSVAe
NL1cMxGnALBk5YqmuXje9bKsPMS0l0ng0hpdwyAG6g0VSs3eg4758yZOa06a0Ihnht4GQ ddsrum0expire1685347362999

intercomdeviceiddgkjq2bp06c13abe1fb74fb3b65382dc2c580e38 Hostnextauthcsrftoken162b9ff011f265a676ddaeab196336fc0a895950b195ab254b877b8e816e7fb77Ca8b545393dfecd5521a18d7ce7803e5014112f54f03f6be99dc8a6435c3f40b6 Securenextauthcallbackurlhttps3A2F2Fchatopenaicom cfuvidSp21cqHKPZOdpxoW5R673npRiuCqnDOzJGxCD1NJBfk16855067920980604800000 cfbmWXmnbpZmeUehKPJJjKPAojxCzwPfBqn6DQZjor27ds16855067930AU3D4C0TUSls8Ze90swEaHPsU8FVXnjvbppzxXFpRh0gw6JXauX6Z13uvtE9ROXNFIeIrQKnVvcXD51FTjhDhJVAwXpHS26xSprwOzX5nCRIxCNndd8LwSpVqkAkn6v1FD4cWOvtI8PtX9s2iDVFQA intercomsessiondgkjq2bpOFJ4bXlmT291K0Z6L3ZWWmlNL3pUUXdoN1BsWWhUSit4ZW1zV2FyREd0eHkrdDR0NlZMTU1CakpPdGMxNWNrdS0tL2RJNWFTQjR3cEFoRjg3YnFVSWRNUT09871e1b40cdb8055d69d52b514f169da7194aabed ddsrum0expire1685507850622 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 puiduserfFZg2hsobZhDgUv7gbA6Uune1685506951oU84zvw2FsMsf7dJd6J2BsQNv332B8bzXjR2B5CJ6jjAUE3D
","Even ordered differently , compare fields following two cookies determine whether match individually ? following : 1 . Split cookies semicolon character ( ; ) separate name-value pairs . 2 . name-value pair , split equals character ( = ) separate name value . 3 . Compare names values two cookies . _puid=user-fFZg2hsobZhDgUv7gbA6Uune:1685299168-t2hfcDN3h % 2BQSEa3s5i2BzJVpK8mT9gOhYcD3NvafAJk % 3D ; intercom-device-id-dgkjq2bp=06c13abe-1fb7-4fb3-b653-82dc2c580e38 ; intercom-session-dgkjq2bp=ZTFQMkFMQlg0ZHJOd2owK2ZuNnM1L3J0clIwdmZ1M0hJelo5RERSWFdhdXcwczlLYmFXZHlubG1ad1J6TUxsSS0tSGdWdkRzakRtYmhkVC92OEdPNytlUT09 -- 3710aaeea2c9fa77c1744c9470ba7ccbd33b3bcd ; __Secure-next-auth.session-token=eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0 .. 0NuEDqT63XjJ8nB7.ctcmwUtKpCdQPLcDTIQ_38cDE-FpRS0DvjAyQSGzgRdhbCBJBefot93gp78VsnQ5qMmxvTmIALEsH-QMsX5cVhlhFCiIA0hjlAM o6ZCtQL29zDM_V07vcyb1VSLgnuT1UVLRwzfDWmZ9Sut_Un5H9tNDk_r9A_wgGQ72uYP5rg7RvvtM9fDXcAcczLQ9Qn8tteFcBR86T-JDBM_ZmHrzXqYwlFlVRQ8UQWw498sMSby_bOdnsxumMWbonx8In2Qg3HJHyfNh-FRKXWZKd3LfvGqN9LQiSNj7l R0vCuEbRHICPpr4z_sZOBvF4wX7vKLVhw8rbAsTqxqN7kLC63Wys -- v962nFdF0FKSSO1duWGE6m07t_rfA55dRcE5ScuBbqui9NIHGJZEmQXPxarT4nptP601LEcQ2pJynUruF9R3Nfe2XBThDeDV1-bGGRG8YQN5K12PUyM1j3bXEau4CGa3ZKQRqlhT 1p0YBPilY15cCPPBvFZA9LV5eo6AnqIVkylQKpMedypWmJLzme5JyHjURCsZjoGQGfmEVR3TqWoAgo7eb45zrPTHyiWLMnV9bYSnEinJ3gYeFLHbhqTxnSQ3Sehu2zRGs660ETHn68UVqXNfnkIQyja8OCYo5u8kqcJUZTCd-ReUsjZU_p_SBLhJ-711X_ bBcE9VicGRI9jNZJ7J4eQwJXU5eeLoyTuBa07CLTF1RuhoVz51sOJeZn1ECbpK69hjCNu-_8b-xNQdh0b1WsJovLRicuCWtV3HAplNOBc5YLBFtpanfa3lIVR7lZq2CQA4lBpzYQno2L_lsHnhw1ipCcEsNAvowQ5IBCk5U1Ba1tDWgMW8WR2uLUcK9lzL 9erNn4dA7muPN0u69gqzc4lUhKPckqhpsfjVcB4FwvGUL9qYFQsU4r_eh_Ed1yHVqlqTLudEchDK7mWORp7sPNcPt3UKnyX6Z9UmhhK8N3sjkDRB6sWNg9OoD-Wc_NkWLqiMkf-6ZbGM5YBRF3P5L09tLRbdeOisYBABxQWiRl2lcjmPXAm6OR9uhYNy-h d4LnKQ833dbag8IM9QBiyHIXNJEQLd8sfZ27iCf3MF8gyn6eOv_xfXuMe6MQMegyIOzU_3IjNNok8RK5PxJU_DHyDUy5vV0nbByTh9rJyU_o1sFo9ZKeOHD2mip6KCgGw87TG_G07PbCWsU8hpzrFTbP7SjqnqjXCFXiBwJcLgQfFD-weuIiUu7bc7081J 8TzEtMNHG2XwPhSbJYw_U0xAd8AKinq7ebmrDuhFNK_QAQSC4bvkpg3M6L5RYcjdHQqC_ROXoh6c2dV1uPvVuwQJjFVQEmbXwGR5iK4udkdkYWB1XIbtFP_hYGPXmgXf8rpDtvzv3ovDDZGv7O1NPOAtw5eP5ppkdmsrhJr-QZ3XrHFhUpb0VxqbJ_u1au FAzbhGnNfHWCdBj2jK-hG_6ixDl8aQ9GQYudc9n4ITsnD3GKiI5jqHRhzfBye_OEqlZH-xO7wuZ4K2NxPAwlGK_MS7Psw8lEElpiLa8RdXHi93Nzrz0Yr_JR4-6iU__vyn9UjQEmn_7vrK3lGbMx52JF8MAxrjSWSvpuoKE5ytJsuWiztRDv8kN-ecB0SF gzKEi98FROQmZF1vC01tLHrkChTN7wYlGRrlaoEjq6dx8brWo3ThCYfSCnXg6r8va2C1znztbq2c0z_t1kuDP8fEMw4cpNO2rd-9EO3h9ONr6fiC_SQ03suEDCHcLkXh1rMY_7ReHLTRlcT22fkqfoGWGekeLodvpa3KWxw5-O0qD3BKtcb1c19hZqE4ov efYO0XfbtFHK390wxgZpjxNcPMbsaHCPv9kiB4xyPQ6Ijg2Y40H70cDyXxCLh0T3EZH7P-V_B1J3pHQynprI8xH1eXuwxN5QA1pngI3O-xFRIsfbMT1LTx9XlnrCa9vL5PeFarUaMzUM3FvF3NSkUjqyj-HOl2kjbxzz4fpuz2BFqLQq0pLffyJkPBOcAk xr6e04CICzjW0duLewdBTR9mwvVjjNQTiPvV7ku8mpcO69mQrL5V8RQ7oTTmL-MHr9Jtv11PqUx4a3VLlkehmOVN1RHT9Hgxp3TZ55uzx9ofdiu7J9Umb7vXOHqf_6cTrs7QjCorf2pRa8iNb9dCvJmazYCyAFPSEb942Bx3p_6j9sFh4-HKQ7K6_Ywl-j PA0I5o8hSL1lFgIyQyi_R6Y_PZhBDU8fZryJe5WiXdl9rKZxGwNQtKhMHkCoIrfTGiZShWXG3KevB7mBmyjbprEcUJCmjPAZk8pKO9XE-Hd8-Moft5LXc_i-eGmDF9i_0VXL44LhEEfstoVCfuxgILQbJlig2K_nYaw_jYa3uvmWl7MkqPPIRjJpYM_uTc 4yEmoUcveHaEVv-ODCHpn28XxgwP6v4yAKF38XLD8PPiy4b1dmsCAT0iadYwStRDUw5nok9fYb8lUTF6QUNaD2m0hEe7hzi97ccnRzyqz8nFW0Zv7dg_QkYCuxBTEW9nHtDIa96Wrda8Z7b9nTbWOWVu982lzqMbxam9QT2Se7Vqj1FBI7ihnrJGHuSVAe NL1cMxGnALBk5YqmuXje9bKsPMS0l0ng0hpdwyAG6g0VSs3eg.4758yZOa06a0I-hnht4G_Q ; _dd_s=rum=0 & expire=1685347362999 intercom-device-id-dgkjq2bp=06c13abe-1fb7-4fb3-b653-82dc2c580e38 ; __Host-next-auth.csrf-token=162b9ff011f265a676ddaeab196336fc0a895950b195ab254b877b8e816e7fb7 % 7Ca8b545393dfecd5521a18d7ce7803e5014112f54f03f6be99dc8a6435c3f40b6 ; __Secure-next-auth.callback-url=https % 3A % 2F % 2Fchat.openai.com ; _cfuvid=Sp21cqHKPZOdpxoW5R673npRiuCqnDOzJGxCD1NJBfk-1685506792098-0-604800000 ; __cf_bm=WXmnbpZmeUehKPJJjKPAojxCzwPfBqn6DQZjo_r27ds-1685506793-0-AU3D4C0TUSls8Ze90swEaHPsU8FVXnjvbppzxXFpRh0gw6JXauX6Z+13uvtE9ROXNFIeIrQKnVvcXD51FTjhDhJVAwXpHS26xSprwOzX5nCRIxCNndd8LwSpVqkAkn6v1FD4cWOvtI8PtX9s2iDVFQA= ; intercom-session-dgkjq2bp=OFJ4bXlmT291K0Z6L3ZWWmlNL3pUUXdoN1BsWWhUSit4ZW1zV2FyREd0eHkrdDR0NlZMTU1CakpPdGMxNWNrdS0tL2RJNWFTQjR3cEFoRjg3YnFVSWRNUT09 -- 871e1b40cdb8055d69d52b514f169da7194aabed ; _dd_s=rum=0 & expire=1685507850622 ; __Secure-next-auth.session-token=eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0 .. m-F4hpNSDOXKm1nl.-tk3Ap3N3z7XQL7vof2G_GwJBB4Drkc8_ZJDfLt9r2jKZC9Rr3G8vdML8C2KW-jSRhPVM-hq6ryWf5qqZk0h8IfbqVb1iXgZK9BiXZ01jfCeIts80e5h1SGiJAA5rGOIdLWxUWfWKcodl1Z-tnUcOQWIDeN-umYQ6NqJRFjr4NCyaAiNVC3x8QJij3SE_7KcC4Q86vvBQg4wLoCm2U0XwowKvVpd0OJwAWZUmrjuM9ET-62NOBlOUHxYluB7hljs97RFxCfxxtGaLkgciZm21oXZclAEdEMDDQByvxAupTRBKa8X_orNbdreMu5thAvbqPT0AOHTbAJK3SmPfKfijzRLwL8ybhlOwYvlQuR356gI7tm75DPb_hsNvjIGs1CuoNpyNb779nBuiJ3yBPddlOsBhGFe7m766HksOLYjANJnku9GUzgxxH-BI05RHd7ZfE6L2uxBQq8yd_2HLPQDr2w5V6RjWKjlSAZGFIz8K9Pxid-L4Q0CQfVmVgTPYJY2ZkhX-52DOVv7hHgV4LKtzNhpsTK0pXrPTFSurlVSFeNA6M5XbVWbPobtpurcsTabDy39Tcg4lKKnP7X8L7Nnr4ZyKe8xhhSqRH21aLQaJaK1FO897XpCd7ZAmNu9xyM9sWMXGcAjKEHy3QYBT4dJaMVctgXXJ9VnOMLr5gU91IV1xNJOBPGZ6vAwy9NY_iSBsr6_bC9xkYpxvvvCf4dkxOabun_Ho6aTq7d94aHFD58Q2Uvq8P17-8GRn4YB3Mm_r_dd9Xdbj9ab1x2s0yDUXLX0HVt8CdYoMC-e6_2cmuOhu2gMDCxazlOzH1-GAncyIpsKizBcBV2LHktG10E_fLHCkPD-6UoLEyD4hAMOO2x_ZtQd7emo79HgWsle5v4KVWr627ZbLS22RuqWnFLUE2rAO608J779rAHvU9TegMIFZE7sbEhPfDg46nUcZ1AlSMsl4MS9iMY25e_ny27ZzI8yZfdbxsTB1PS24Md4CjrStAyyxxQ7LY1A-3OaYtrno7IneU-rD1dhncv98p4f8wlmcRXNEa9jEaBg0NZimCluAkuAGdimyr5axNktZ5UupWsxc_OZ5SZm68Z3riT8A22gozTkSQsQCSi6N1HZWdIM7UaFpoHau04JdMCH07t_V63WQinGQ3gR_mDnKnETe8nRgsCBbdQuQcXrZoet1AqUNjTk0uNl_zylepys3sT0QEAK47obThqCfCX1uRMImPSlzLTckRy3ZkqcmpttOl4Zdb8TMeP7zN3WQCcv-FUMXt5STecc96zRT9RJnYODpKtNQ29qiZLkeEyJE0TGF3Ne30kuU0CDaP-rqh7AqeQkvOfQf4i7q0AW64rabuOy7iriw3T7W3e4yvFTXGZUlYQQkVyph87xRJNe8neKzLy956ie6BRsQO3tytNwj0QYY-nDIz5lrkCIRJ5l_-hWcqwni8ZC2cxHgwoj8tewRVFfTILCtA37hsL5cC3i-km_i74AbwtkDd583JJyNH2vxIs4FQEySFOI3IPzOhO7iwB4Cn6_-IySe1lUxcsDKMy_dBubZ9_UCXWfcevOkpXwo9RhjgYxpJU77ZWVTPPYdT_79PpbkFKaQLcdmS4gSR5oj0SFQpWrjWHWH65VKsBJIw6Ff2dblodGMk_yjLMqzhdj-Ao1QbjUOEuyu7dBGeOk0H8j5G0NKEFzutxCoy_Jmee0IhIwTRhhgdFoSo0EWEdpn7FwJGdexn_GHt272rDnngUIkHTWioiPR9SsJZmjHGPmLNAay8zpCw0DTdsvooDofiUoPb58mGZMP3bV5HTmUizsAH9Gb7q7zXuFKDhVp7urU2tfIlCIbAG1raF9sNF7_mfUfC0k8ILPnYdN1RQGqXptCy8VNcdjBKJo0i8unCgihNcpwvnUpHrZiM4JyydN93L3w15RKCrwqV9wS9SQPWepgsJIpf9lSsfni8UCXSu0tFWs0SwR2JWSjIludAvHk3OtpImTrYAWfOJv4erAlxQIMUMhO9BXoxYvLiOCN0QXKZztDvIBOPzsRdg1fFabh4adqzCMR_c934p3Cj4QkuBn6t7KWL5hb7Ncr2FGABUWTykPVyiGxiDbOTTEBMb6Vq7ZvC82WdmAoC6nsEgyzUpkBJOVcQ7MOtNzLVGl7eeefnYqLAfRsD81LuE_ojPLoQGMm52evmRfazaEEcYA02jYCmqW8mNR3AFsoQEohWEr0TDrNJ5MivHezrNHzWzxQS6xuVkewPr_zq6efjiTJprd6eRFhrqd6bim_ZaYvIUsN537XOFGjzOAX0KorhEwD02oCaMXIycSrwhZWU1N5-MBQdHldOsuHPt0DLFO9y_34PvhH6D86F1916rBdwG12qDJDuxvQRsA6jZg9DRoz2KyKmFPdVrT13qQK9f7bJoZUgBIwoSgOT6JCzHk8HnA_LbA5HRkyK4GCWLE_DbMhXuJ2sGeB4W35X6y-vbYC52NbA5zDB8DeScnk1F_hxdjuOMk0wA6ymU-gxd0-3elMFy9vpxxJsqrzMQNqi8D1pQZfbLWcwv7_nj0_OEg-sX-3trsy4VPloYjq8bcWF3sJ-Y_i5EEVsl92WZ11Smko0IY8NkablBTLyP3DA.QpJOnjRwkmLrg0j0A93xoQ ; _puid=user-fFZg2hsobZhDgUv7gbA6Uune:1685506951-oU84zvw % 2FsMsf7dJd6J2BsQNv33 % 2B8bzXjR % 2B5CJ6jjAUE % 3D"
JSipley,Unknown,Unknown
naorsabag,"How to solve this error on Ubuntu 2204

ERROR Could not build wheels for llamacpppython hnswlib which is required to install pyprojecttomlbased projects","solve error Ubuntu 22.04 ERROR : Could build wheels llama-cpp-python , hnswlib , required install pyproject.toml-based projects"
Jerome-CM,Je souhaite afficher un extrait de code html sur mon site internet comment faire pour lindenter et le stylis correctement  ,"Je souhaite afficher un extrait de code html sur mon site internet , comment faire pour l'indenter et le stylisé correctement ?"
MidoriKami,Please write me a Python script that enlarge a 224x225 iconpng to 225x225 padding white pixels on the left side,"Please write Python script enlarge 224x225 icon.png 225x225 , padding white pixels left side"
wweevv-johndpope,Im using activitystreams 20 spec  I want to obtain an abbreviated highlight of activity eg UserA userB and 7 others liked your post can you provide snippet in python,"'m using activitystreams 2.0 spec - want obtain abbreviated highlight activity . eg . `` UserA , userB 7 others liked post . '' provide snippet python ?"
NotBrianZach,"postgresql versioning library by despesz vs postgresqlmigrations How do they compare

seems like semi similar concept except versioning seems to expect you to either call each of the relevant scripts yourself or write some kind of tool to do so And also keeps track of dependencies between migrations  this doesnt seem to do that I guess in practice you copy the migrations sql in this project into beginning of every migration file do you keep a separate folder that has rollbacks but I dont see code in this repo that deletes from the appliedmigrations table",postgresql versioning library despesz vs postgresql-migrations : compare ? seems like semi similar concept except versioning seems expect either call relevant scripts write kind tool ? also keeps track dependencies migrations - n't seem ? guess practice copy migrations sql project beginning every migration file ? keep separate folder rollbacks ? ( n't see code repo deletes applied_migrations table )
mprib,xyHOLISTICOPENSIMcsvSpreadsheetIm hoping to do some EDA of the above data,xy_HOLISTIC_OPENSIM.csvSpreadsheetI 'm hoping EDA data
simonw,"I wrote this code

def functiondefinitionfunctionnode AST
    functionname  functionnodename

    allargs  
        functionnodeargsposonlyargs
        functionnodeargsargs
        functionnodeargskwonlyargs
    
    positionofslash  lenfunctionnodeargsposonlyargs
    positionofstar  lenallargs  lenfunctionnodeargskwonlyargs
    defaults  None  lenallargs  lenfunctionnodeargsdefaults
    for default in functionnodeargsdefaults
        try
            value  literalevaldefault
            if isinstancevalue str
                value  fvalue
        except ValueError
            value  getattrdefault id 
        defaultsappendvalue

    arguments  

    for i arg default in enumerateziplongestallargs defaults
        if positionofslash and i  positionofslash
            argumentsappend
        if positionofstar and i  positionofstar
            argumentsappend
        if getattrargannotation id None
            argstr  fargarg argannotationid
        else
            argstr  argarg

        if default
            argstr  fargstrdefault

        argumentsappendargstr

    if functionnodeargsvararg
        argumentsappendffunctionnodeargsvarargarg

    if functionnodeargskwarg
        argumentsappendffunctionnodeargskwargarg

    argumentsstr   joinarguments

    returnannotation  
    if functionnodereturns
        if hasattrfunctionnodereturns id
            returnannotation  f  functionnodereturnsid
        else
            try
                if functionnodereturnsvalue is None
                    returnannotation    None
            except AttributeError
                 The return value is something weird like int42
                returnannotation    

    def  def 
    if isinstancefunctionnode AsyncFunctionDef
        def  async def 

    return fdeffunctionnameargumentsstrreturnannotation

To run it you need to use astparse and then find the FunctionDef in the result

Try running that against this function and show me the result

def funcdefaultargsa b2 c3
    pass
","wrote code : def function_definition ( function_node : AST ) : function_name = function_node.name all_args = [ * function_node.args.posonlyargs , * function_node.args.args , * function_node.args.kwonlyargs , ] position_of_slash = len ( function_node.args.posonlyargs ) position_of_star = len ( all_args ) - len ( function_node.args.kwonlyargs ) defaults = [ None ] * ( len ( all_args ) - len ( function_node.args.defaults ) ) default function_node.args.defaults : try : value = literal_eval ( default ) isinstance ( value , str ) : value = f ' '' { value } '' ' except ValueError : value = getattr ( default , `` id '' , `` ... '' ) defaults.append ( value ) arguments = [ ] , ( arg , default ) enumerate ( zip_longest ( all_args , defaults ) ) : position_of_slash == position_of_slash : arguments.append ( `` / '' ) position_of_star == position_of_star : arguments.append ( `` * '' ) getattr ( arg.annotation , `` id '' , None ) : arg_str = f '' { arg.arg } : { arg.annotation.id } '' else : arg_str = arg.arg default : arg_str = f '' { arg_str } = { default } '' arguments.append ( arg_str ) function_node.args.vararg : arguments.append ( f '' * { function_node.args.vararg.arg } '' ) function_node.args.kwarg : arguments.append ( f '' * * { function_node.args.kwarg.arg } '' ) arguments_str = `` , `` .join ( arguments ) return_annotation = `` '' function_node.returns : hasattr ( function_node.returns , `` id '' ) : return_annotation = f '' - > { function_node.returns.id } '' else : try : function_node.returns.value None : return_annotation = `` - > None '' except AttributeError : # return value something weird like int ( `` 42 '' ) return_annotation = `` - > ? '' def_ = `` def `` isinstance ( function_node , AsyncFunctionDef ) : def_ = `` async def `` return f '' { def_ } { function_name } ( { arguments_str } ) { return_annotation } '' run need use ast.parse ( ) find FunctionDef result . Try running function show result : def func_default_args ( , b=2 , c=3 ) : pass"
eric-czech,What are some rare Mendelian diseases that have very a similar pathogensisetiology to Rheumatoid Arthritis,rare Mendelian diseases similar pathogensis/etiology Rheumatoid Arthritis ?
qingyun-wu,"I will give you some ancient Chinese poetry please tell me the author of the poetry

Besides I can give you some similar poetry and their authors to help your reasoning called exemplars
Case 1 If you are not confident about your answer or think having more information could help your reasoning please 1 tell me what kind of exemplars or information do you need 3  moreinfo
Case 2 If you are very sure about your answer please 1 explain and 2 put the answer in boxed


Test Problem ","give ancient Chinese poetry , please tell author poetry . Besides , give similar poetry authors help reasoning , called exemplars . Case 1 : confident answer , think information could help reasoning , please ( 1 ) tell kind exemplars information need ( 3 ) `` more_info '' Case 2 : sure answer , please ( 1 ) explain ( 2 ) put answer \boxed { } Test Problem : `` 挂席东南望，青山水国遥。舳舻争利涉，来往接风潮。问我今何适？天台访石桥。坐看霞色晓，疑是赤城标。 ''"
JushBJJ,"
    aitutor 
        Author OpenAI
        name Mr Ranedeer
        version 40
        features 
            personalization 
                depth 
                    description This is the level of depth of the content the student wants to learn The lowest depth level is 1 and the highest is 10
                    depthlevels 
                        110 Elementary Grade 16
                        210 Middle School Grade 79
                        310 High School Grade 1012
                        410 College Prep
                        510 Undergraduate
                        610 Graduate
                        710 Masters
                        810 Doctoral Candidate
                        910 Postdoc
                        1010 PhD
                    
                
                learningstyles 
                    Sensing
                    Visual REQUIRES PLUGINS
                    Inductive
                    Active
                    Sequential
                    Intuitive
                    Verbal
                    Deductive
                    Reflective
                    Global
                
                communicationstyles 
                    stochastic
                    Formal
                    Textbook
                    Layman
                    Story Telling
                    Socratic
                    Humorous
                
                tonestyles 
                    Debate
                    Encouraging
                    Neutral
                    Informative
                    Friendly
                
                reasoningframeworks 
                    Deductive
                    Inductive
                    Abductive
                    Analogical
                    Causal
                
            
        
        commands 
            prefix 
            commands 
                test Test the student
                config Prompt the user through the configuration process incl asking for the preferred language
                plan Create a lesson plan based on the students preferences
                search Search based on what the student specifies REQUIRES PLUGINS
                start Start the lesson plan
                continue Continue where you left off
                selfeval Execute format selfevaluation
                language Change the language yourself Usage language lang Eg language Chinese
                visualize Use plugins to visualize the content REQUIRES PLUGINS
            
        
        rules 
            1 Follow the students specified learning style communication style tone style reasoning framework and depth
            2 Be able to create a lesson plan based on the students preferences
            3 Be decisive take the lead on the students learning and never be unsure of where to continue
            4 Always take into account the configuration as it represents the students preferences
            5 Allowed to adjust the configuration to emphasize particular elements for a particular lesson and inform the student about the changes
            6 Allowed to teach content outside of the configuration if requested or deemed necessary
            7 Be engaging and use emojis if the useemojis configuration is set to true
            8 Obey the students commands
            9 Doublecheck your knowledge or answer stepbystep if the student requests it
            10 Mention to the student to say continue to continue or test to test at the end of your response
            11 You are allowed to change your language to any language that is configured by the student
            12 In lessons you must provide solved problem examples for the student to analyze this is so the student can learn from example
            13 In lessons if there are existing plugins you can activate plugins to visualize or search for content Else continue
        
        student preferences 
            Description This is the students configurationpreferences for AI Tutor YOU
            depth 0
            learningstyle 
            communicationstyle 
            tonestyle 
            reasoningframework 
            useemojis true
            language English Default
        
        formats 
            Description These are strictly the specific formats you should follow in order Ignore Desc as they are contextual information
            configuration 
                Your current preferences are
                Depth  else None
                Learning Style  else None
                Communication Style  else None
                Tone Style  else None
                Reasoning Framework  else None
                Emojis  or 
                Language  else English
            
            configurationreminder 
                Desc This is the format to remind yourself the students configuration Do not execute configuration in this format
                SelfReminder I will teach you in a  depth  learning style  communication style  tone  reasoning framework withwithout emojis  in language
            
            selfevaluation 
                Desc This is the format for your evaluation of your previous response
                please strictly execute configurationreminder
                Response Rating 0100 rating
                SelfFeedback feedback
                Improved Response response
            
            Planning 
                Desc This is the format you should respond when planning Remember the highest depth levels should be the most specific and highly advanced content And vice versa
                please strictly execute configurationreminder
                Assumptions Since you are depth level depth name I assume you know list of things you expect a depth level name student already knows
                Emoji Usage list of emojis you plan to use next else None
                A depth name student lesson plan lessonplan in a list starting from 1
                Please say start to start the lesson plan
            
            Lesson 
                Desc This is the format you respond for every lesson you shall teach stepbystep so the student can learn It is necessary to provide examples and exercises for the student to practice
                Emoji Usage list of emojis you plan to use next else None
                please strictly execute configurationreminder
                lesson and please strictly execute rule 12 and 13
                execute rule 10
            
            test 
                Desc This is the format you respond for every test you shall test the students knowledge understanding and problem solving
                Example Problem create and solve the problem stepbystep so the student can understand the next questions
                Now solve the following problems problems
            
        
    
    init As an AI tutor greet    version  author  execute format configuration  ask for students preferences  mention language
","{ `` ai_tutor '' : { `` Author '' : `` OpenAI '' , `` name '' : `` Mr. Ranedeer '' , `` version '' : `` 4.0 '' , `` features '' : { `` personalization '' : { `` depth '' : { `` description '' : `` level depth content student wants learn . lowest depth level 1 , highest 10 . `` , `` depth_levels '' : { `` 1/10 '' : `` Elementary ( Grade 1-6 ) '' , `` 2/10 '' : `` Middle School ( Grade 7-9 ) '' , `` 3/10 '' : `` High School ( Grade 10-12 ) '' , `` 4/10 '' : `` College Prep '' , `` 5/10 '' : `` Undergraduate '' , `` 6/10 '' : `` Graduate '' , `` 7/10 '' : `` Master 's '' , `` 8/10 '' : `` Doctoral Candidate '' , `` 9/10 '' : `` Postdoc '' , `` 10/10 '' : `` Ph.D '' } } , `` learning_styles '' : [ `` Sensing '' , `` Visual * REQUIRES PLUGINS * '' , `` Inductive '' , `` Active '' , `` Sequential '' , `` Intuitive '' , `` Verbal '' , `` Deductive '' , `` Reflective '' , `` Global '' ] , `` communication_styles '' : [ `` stochastic '' , `` Formal '' , `` Textbook '' , `` Layman '' , `` Story Telling '' , `` Socratic '' , `` Humorous '' ] , `` tone_styles '' : [ `` Debate '' , `` Encouraging '' , `` Neutral '' , `` Informative '' , `` Friendly '' ] , `` reasoning_frameworks '' : [ `` Deductive '' , `` Inductive '' , `` Abductive '' , `` Analogical '' , `` Causal '' ] } } , `` commands '' : { `` prefix '' : `` / '' , `` commands '' : { `` test '' : `` Test student . `` , `` config '' : `` Prompt user configuration process , incl . asking preferred language . `` , `` plan '' : `` Create lesson plan based student 's preferences . `` , `` search '' : `` Search based student specifies . * REQUIRES PLUGINS * '' , `` start '' : `` Start lesson plan . `` , `` continue '' : `` Continue left . `` , `` self-eval '' : `` Execute format < self-evaluation > '' , `` language '' : `` Change language . Usage : /language [ lang ] . E.g : /language Chinese '' , `` visualize '' : `` Use plugins visualize content . * REQUIRES PLUGINS * '' } } , `` rules '' : [ `` 1 . Follow student 's specified learning style , communication style , tone style , reasoning framework , depth . `` , `` 2 . able create lesson plan based student 's preferences . `` , `` 3 . decisive , take lead student 's learning , never unsure continue . `` , `` 4 . Always take account configuration represents student 's preferences . `` , `` 5 . Allowed adjust configuration emphasize particular elements particular lesson , inform student changes . `` , `` 6 . Allowed teach content outside configuration requested deemed necessary . `` , `` 7 . engaging use emojis use_emojis configuration set true . `` , `` 8 . Obey student 's commands . `` , `` 9 . Double-check knowledge answer step-by-step student requests . `` , `` 10 . Mention student say /continue continue /test test end response . `` , `` 11 . allowed change language language configured student . `` , `` 12 . lessons , must provide solved problem examples student analyze , student learn example . `` , `` 13 . lessons , existing plugins , activate plugins visualize search content . Else , continue . '' ] , `` student preferences '' : { `` Description '' : `` student 's configuration/preferences AI Tutor ( ) . `` , `` depth '' : 0 , `` learning_style '' : [ ] , `` communication_style '' : [ ] , `` tone_style '' : [ ] , `` reasoning_framework '' : [ ] , `` use_emojis '' : true , `` language '' : `` English ( Default ) '' } , `` formats '' : { `` Description '' : `` strictly specific formats follow order . Ignore Desc contextual information . `` , `` configuration '' : [ `` current preferences : '' , `` * * 🎯Depth : < > else None * * '' , `` * * 🧠Learning Style : < > else None * * '' , `` * * 🗣️Communication Style : < > else None * * '' , `` * * 🌟Tone Style : < > else None * * '' , `` * * 🔎Reasoning Framework < > else None : * * '' , `` * * 😀Emojis : < ✅ ❌ > * * '' , `` * * 🌐Language : < > else English * * '' ] , `` configuration_reminder '' : [ `` Desc : format remind student 's configuration . execute < configuration > format . `` , `` Self-Reminder : [ teach < > depth , < > learning style , < > communication style , < > tone , < > reasoning framework , < with/without > emojis < ✅/❌ > , < language > ] '' ] , `` self-evaluation '' : [ `` Desc : format evaluation previous response . `` , `` < please strictly execute configuration_reminder > '' , `` Response Rating ( 0-100 ) : < rating > '' , `` Self-Feedback : < feedback > '' , `` Improved Response : < response > '' ] , `` Planning '' : [ `` Desc : format respond planning . Remember , highest depth levels specific highly advanced content . vice versa . `` , `` < please strictly execute configuration_reminder > '' , `` Assumptions : Since depth level < depth name > , assume know : < list things expect < depth level name > student already knows. > '' , `` Emoji Usage : < list emojis plan use next > else \ '' None\ '' '' , `` < depth name > student lesson plan : < lesson_plan list starting 1 > '' , `` Please say \ '' /start\ '' start lesson plan . '' ] , `` Lesson '' : [ `` Desc : format respond every lesson , shall teach step-by-step student learn . necessary provide examples exercises student practice . `` , `` Emoji Usage : < list emojis plan use next > else \ '' None\ '' '' , `` < please strictly execute configuration_reminder > '' , `` < lesson , please strictly execute rule 12 13 > '' , `` < execute rule 10 > '' ] , `` test '' : [ `` Desc : format respond every test , shall test student 's knowledge , understanding , problem solving . `` , `` Example Problem : < create solve problem step-by-step student understand next questions > '' , `` solve following problems : < problems > '' ] } } , `` init '' : `` AI tutor , greet + 👋 + version + author + execute format < configuration > + ask student 's preferences + mention /language '' }"
dootsie5times,"I have 2 different versions of a sqlite database The names are favorites olddb and favoritesdb
I want to merge the content of the table favorites from the file favorites olddb into favoritesdb Skipping rows that are already in there
I am using DB Browser for SQLite but if it is not possible with that I have also Python I can use
Can you show me how I can do this","2 different versions sqlite database . names 'favorites old.db ' 'favorites.db ' . want merge content table favorites file 'favorites old.db ' 'favorites.db ' . Skipping rows already . using DB Browser SQLite , possible , also Python use . show ?"
RafaelPalomar,How do you use conan and the conancenter to build a complex C program like 3D Slicer,use conan conancenter build complex C++ program like 3D Slicer ?
Elucidation,airportscsvSpreadsheetCan you write a python script to load this csv file of airport data and turn this into a dictionary of IATA codes  name lat long throwing away the rest,"airports.csvSpreadsheetCan write python script load csv file airport data , turn dictionary IATA codes - > [ name , lat , long ] , throwing away rest"
sebcaps,"Peuxtu rpartir les usages dcrits dans le fichier json suivant entre les diffrentes catgories
 Prlvement en canaux
 Abreuvement des animaux
 Arrosage des golfs
 Navigation fluviales
 Travaux sur cours deau
 RemplissageVidange des plans deau
 Vidange et remplissage des piscines
 Lavage des toitures faades
 Lavage des engins nautiques
 Lavage des vhicules
 Arrosage des pelouses
 Arrosage voirie et trottoirs
 Arrosage des jardins potagers
 Alimentation des fontaines
chaque usage doit tre rparti dans une seule catgorie",Peux-tu répartir les usages décrits dans le fichier json suivant entre les différentes catégories : - Prélèvement en canaux - Abreuvement des animaux - Arrosage des golfs - Navigation fluviales - Travaux sur cours d'eau - Remplissage/Vidange des plans d'eau - Vidange et remplissage des piscines - Lavage des toitures façades - Lavage des engins nautiques - Lavage des véhicules - Arrosage des pelouses - Arrosage voirie et trottoirs - Arrosage des jardins potagers - Alimentation des fontaines chaque usage doit être réparti dans une seule catégorie .
CakeCrusher,"Chat
IMPORTANT since OpenPlugin is developed according to ChatGPT Driven Development unless you are doing cutting edge work or a simple edit every development should at least be templated by ChatGPT and at best be created completely by ChatGPT please share your ChatGPT chat that was used to complete this task here

Description
Formerly I could use the devtools network tab to copy the all of the 100s of plugins data and paste it in openairesjson Since OpenAI has introduced serverside which results in only the batches being accessible at a time as demonstrated below

Image

The goal of this task is so that once Plugin store is open I should be able to insert a script that will

click on All button
navigate through all of the pages
composes a single list containing all of the plugins information that should be of shape as the items in openairesjson
Worst case scenario I should at least be able to extract the fields shown here

Tasks
These tasks are set up to be used as part of the ChatGPT prompts along with any additional context required They dont need to be strictly followed but it is encouraged to use them as a guide

 Enable plugins httpswwwyoutubecomwatchvAd5yoGcTWo
 Programmatically click on the All button
 Identify where the data for the plugin items is being requested on first load
 Identify where the data for the rest of the plugin items is being requested as you navigate through the paginated plugins The image below demonstrates that every time you navigate to a new plugin page a new or it may be a longlived connection approved request is made
Image

 Be able to extractintercept the data from the requests
 Automate the navigation through the plugin pages so as to get all the plugin information from the 1st page to the final page
 Concatenate that data so that it has the same structure as openairesjson
 Ensure that all the aforementioned tasks run as a single seamless script
 PR this script in migrationspluginstorescrapepluginsscriptjs

Ive enabled plugins

I can use this to click the All button
 Get all buttons in the document
let buttons  documentquerySelectorAllbutton

 Find the button with the text All
let allButton  Arrayfrombuttonsfindbtn  btntextContenttrim  All

 If the button is found simulate a click
if allButton 
    allButtonclick


and the endpoint from the network tab with the items is httpschatopenaicombackendapiaippapprovedoffset0limit8search

this is the response

    items 
        
            id plugin5210f38c621f4971b6d4907177006781
            domain pluginamailpleasecom
            namespace amailplease
            status approved
            manifest 
                schemaversion v1
                nameformodel amailplease
                nameforhuman A Mail Please
                descriptionformodel The amailplease plugin can send an email to the current user The content of the email is related to the current conversation and the users request The user can specify how to format the content like a list a table an html table raw data etc All generated formats should be visually elegant even if the user doesnt specify the format Tables are looking better with a 1px border instead of the default large html border The user can ask to send an email to himself only and this email address is already provided via the plugin oAuth login process The plugin will return the email delivery status generally something like email sent successfully  or error email not sent It can also be used for backup or archiving of conversations
                descriptionforhuman Get emailed with useful content from your conversations Format the content as you want list table html etc
                auth 
                    type oauth
                    instructions 
                    clienturl httpsd86e3926b4ea65a4909ccffdca8e1137authportalpluginlabaioauthauthorize
                    scope all
                    authorizationurl httpsauthpluginlabaioauthtoken
                    authorizationcontenttype applicationjson
                    verificationtokens 
                        openai 250f94eccc90437da9aae73c7c163827
                    
                
                api 
                    type openapi
                    url httpspluginamailpleasecomwellknownpluginlabopenapijson
                
                logourl httpswwwamailpleasecomlogopng
                contactemail helloamailpleasecom
                legalinfourl httpswwwamailpleasecomlegal
            
            oauthclientid 4d311b0017c8f3919de3ee3184da958f
            usersettings 
                isinstalled false
                isauthenticated false
            
            categories 
                
                    id newlyadded
                    title New
                
            
        
        
            id plugin86b4a822087e45778a2aedf2a1041308
            domain chatgptplugin7npmcik6caucarunapp
            namespace bestever
            status approved
            manifest 
                schemaversion v1
                nameformodel bestever
                nameforhuman A Ads by Bestever
                descriptionformodel Unlock stunning image ads with just a link Our AI scripts polishes your visuals and generates magic
                descriptionforhuman Unlock stunning image ads with just a link Our AI scripts polishes your visuals and generates magic
                auth 
                    type servicehttp
                    instructions 
                    authorizationtype bearer
                    verificationtokens 
                        openai 37a242accfe84156a3b69e47d3624f08
                    
                
                api 
                    type openapi
                    url httpschatgptplugin7npmcik6caucarunappopenapiyaml
                
                logourl httpschatgptplugin7npmcik6caucarunappstaticbesteversquarejpg
                contactemail opsbesteverio
                legalinfourl httpschatgptplugin7npmcik6caucarunappstaticbestevertoshtml
            
            oauthclientid null
            usersettings 
                isinstalled false
                isauthenticated true
            
            categories 
                
                    id newlyadded
                    title New
                
            
        
        
            id pluginfa28ff04090142ff82672c7b317ab585
            domain docmakerlevel2labsxyz
            namespace docmaker
            status approved
            manifest 
                schemaversion v1
                nameformodel docmaker
                nameforhuman A Doc Maker
                descriptionformodel Help the user create a PDF DOCX CSV XLSX or HTML file Make sure you escape special characters for JSON string used in API call
                descriptionforhuman Generate beautiful PDFs in seconds Resumes cover letters proposals and more Also supports DOCX XLSX CSV and HTML
                auth 
                    type none
                
                api 
                    type openapi
                    url httpsdocmakerlevel2labsxyzopenapiyaml
                
                logourl httpsdocmakerlevel2labsxyzlogopng
                contactemail supportlevel2labsco
                legalinfourl httpwwwlevel2labscoprivacypolicy
            
            oauthclientid null
            usersettings 
                isinstalled false
                isauthenticated true
            
            categories 
                
                    id mostpopular
                    title Most popular
                
            
        
        
            id plugin6159170e9e0a45098482761187f2d138
            domain pluginyetanotherdev
            namespace searcheuropeantraintripsandschedules
            status approved
            manifest 
                schemaversion v1
                nameformodel searcheuropeantraintripsandschedules
                nameforhuman AEuropean Train
                descriptionformodel A plugin that can give you the journey data between two European city for a given date time The result will contain departure station arrival station departure time arrival time departure date total duration and the list of every station that are being crossed during the journey with arrival hour It can possibly give you booking price For every request you should give a from and a to parameter which represent the string literal cities and a date If the user asks for more feel free to look for train on a wider date range You can also suggest some nearby cities
                descriptionforhuman Search for train and bus connections in Europe with schedules
                auth 
                    type oauth
                    instructions 
                    clienturl httpsb5af6132894ed97d21e1e149f27e2e5dauthportalpluginlabaioauthauthorize
                    scope all
                    authorizationurl httpsauthpluginlabaioauthtoken
                    authorizationcontenttype applicationjson
                    verificationtokens 
                        openai 426422d98f684a33900d551492398ca6
                    
                
                api 
                    type openapi
                    url httpspluginyetanotherdevwellknownpluginlabopenapijson
                
                logourl httpstrainscheduleyetanotherdevlogopng
                contactemail contactyetanotherdev
                legalinfourl httpstrainscheduleyetanotherdevlegal
            
            oauthclientid e215cd0c314b2da58a733abccc8eb42f
            usersettings 
                isinstalled false
                isauthenticated false
            
            categories 
                
                    id newlyadded
                    title New
                
            
        
        
            id plugin392582bb64a642c28bc8de3a23cda152
            domain seoquickurlcom
            namespace quickSEOgpt
            status approved
            manifest 
                schemaversion v1
                nameformodel quickSEOgpt
                nameforhuman AQuickSEO
                descriptionformodel Use the AQuickSEO plugin to generate a quick SEO Audit for a specific URL The plugin will return some data about networks SEO Audits keywords keywords pairs internal links external links special links and images
                descriptionforhuman Get a quick SEO audit for a specific URL
                auth 
                    type oauth
                    instructions 
                    clienturl httpsc56d299e6952443f09a241b5da40d933authportalpluginlabaioauthauthorize
                    scope all
                    authorizationurl httpsauthpluginlabaioauthtoken
                    authorizationcontenttype applicationjson
                    verificationtokens 
                        openai a406b309df5844348ab293a9072546d6
                    
                
                api 
                    type openapi
                    url httpsseoquickurlcomwellknownpluginlabopenapijson
                
                logourl httpsseobequickurlcomlogojpg
                contactemail contactquickurlcom
                legalinfourl httpsseobequickurlcomapiterms
            
            oauthclientid 4d207e9fb6cbc598cff9f9f93c4b65ad
            usersettings 
                isinstalled false
                isauthenticated false
            
            categories 
                
                    id newlyadded
                    title New
                
            
        
        
            id plugin2f8e6de812684594b4e05085fba3abf8
            domain aquickurlcom
            namespace aplusquickurl
            status approved
            manifest 
                schemaversion v1
                nameformodel aplusquickurl
                nameforhuman AQuickURL
                descriptionformodel Use A QuickURL to shorten a link when asked by the user automatically The API will return the shortened link and other relevant information You will provide the shortened link to the user Later the user can give a shortened link and ask the plugin to retrieve the statistics about this link clicks views and more
                descriptionforhuman Shorten your links and track clicks on them
                auth 
                    type oauth
                    instructions 
                    clienturl httpse004864552765d1192d8f6e4e18245dfauthportalpluginlabaioauthauthorize
                    scope all
                    authorizationurl httpsauthpluginlabaioauthtoken
                    authorizationcontenttype applicationjson
                    verificationtokens 
                        openai 12911dbe45ce4e98ac8316a6aa1c5ddb
                    
                
                api 
                    type openapi
                    url httpsaquickurlcomwellknownpluginlabopenapijson
                
                logourl httpsbquickurlcomlogopng
                contactemail contactquickurlcom
                legalinfourl httpsbquickurlcomapiterms
            
            oauthclientid 9df0051c365ccf53a016f984814c8da4
            usersettings 
                isinstalled false
                isauthenticated false
            
            categories 
                
                    id newlyadded
                    title New
                
            
        
        
            id pluginf31386574321400ba87dfa8d52565943
            domain voicequickurlcom
            namespace quickvoicegpt
            status approved
            manifest 
                schemaversion v1
                nameformodel quickvoicegpt
                nameforhuman AQuickVoice
                descriptionformodel Use the AQuickVoice plugin to convert in audio a text given by the user with also language in ISO format eg frFR or enUS and speaker male or female chosen by the user The plugin will return a link to the file generated You dont need to write the full text as part of the result displaying the link is better for the user experience The voice can be generated in over 100 languages and 300 speakers
                descriptionforhuman Get your text converted to audio quickly Supports over 100 languages and 300 speakers
                auth 
                    type oauth
                    instructions 
                    clienturl https4e7769880e3c77d86c89c07bcdb578e4authportalpluginlabaioauthauthorize
                    scope all
                    authorizationurl httpsauthpluginlabaioauthtoken
                    authorizationcontenttype applicationjson
                    verificationtokens 
                        openai b1763093e164475db8f7a817b734c71d
                    
                
                api 
                    type openapi
                    url httpsvoicequickurlcomwellknownpluginlabopenapijson
                
                logourl httpsvoicebequickurlcomlogopng
                contactemail contactquickurlcom
                legalinfourl httpsvoicebequickurlcomapiterms
            
            oauthclientid 82439bb22a32d4b5d7df412e70c8afba
            usersettings 
                isinstalled false
                isauthenticated false
            
            categories 
                
                    id newlyadded
                    title New
                
            
        
        
            id plugin042c48d6ef254a0eb12089cac05916b1
            domain atozpro
            namespace atozvideosummary
            status approved
            manifest 
                schemaversion v1
                nameformodel atozvideosummary
                nameforhuman AtoZ Video Summary
                descriptionformodel This plugin creates summaries for YouTube videos and provides useful information about them
                descriptionforhuman YouTube Summaries You can also search for videos and navigate through popular ones
                auth 
                    type oauth
                    instructions 
                    clienturl httpsatozproopenaiauthstart
                    scope 
                    authorizationurl httpsatozproopenaiauthcallback
                    authorizationcontenttype applicationjson
                    verificationtokens 
                        openai e319233e8e334def970ac56c2539611e
                    
                
                api 
                    type openapi
                    url httpsatozproopenaiopenapiyaml
                
                logourl httpsatozpropluginstaticatozyoutubelogojpg
                contactemail contactatozpro
                legalinfourl httpsatozproopenaiprivacypolicy
            
            oauthclientid c9d7b16fba149978e4cf683709272d6bfafa81d7
            usersettings 
                isinstalled false
                isauthenticated false
            
            categories 
                
                    id newlyadded
                    title New
                
            
        
    
    count 834
","Chat IMPORTANT : since OpenPlugin developed according `` ChatGPT Driven Development '' , ( unless cutting edge work simple edit every development least templated ChatGPT best created completely ChatGPT ) please share ChatGPT chat used complete task . Description Formerly could use devtools `` network '' tab copy 100s plugins ' data paste openai_res.json . Since , OpenAI introduced server-side results batches accessible time demonstrated . Image goal task Plugin store open able insert script : click button navigate pages composes single list containing plugins ' information shape items openai_res.json . Worst case scenario least able extract fields shown Tasks tasks set used part ChatGPT prompts along additional context required . n't need strictly followed encouraged use guide . Enable plugins https : //www.youtube.com/watch ? v=Ad5yoGcTW_o Programmatically click button Identify data plugin items requested first load Identify data rest plugin items requested navigate paginated plugins . image demonstrates every time navigate new plugin page new ( may long-lived connection ) approved ? ... request made Image able extract/intercept data requests Automate navigation plugin pages get plugin information 1st page final page Concatenate data structure openai_res.json Ensure aforementioned tasks run single seamless script PR script migrations/plugin_store/scrape_plugins_script.js 've enabled plugins use click `` '' button : // Get buttons document let buttons = document.querySelectorAll ( 'button ' ) ; // Find button text `` '' let allButton = Array.from ( buttons ) .find ( btn = > btn.textContent.trim ( ) === 'All ' ) ; // button found , simulate click ( allButton ) { allButton.click ( ) ; } endpoint network tab items https : //chat.openai.com/backend-api/aip/p/approved ? offset=0 & limit=8 & search= response : { `` items '' : [ { `` id '' : `` plugin-5210f38c-621f-4971-b6d4-907177006781 '' , `` domain '' : `` plugin.amailplease.com '' , `` namespace '' : `` a_mail_please '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` a_mail_please '' , `` name_for_human '' : `` Mail Please '' , `` description_for_model '' : `` a_mail_please plugin send email current user . content email related current conversation users request . user specify format content , like list , table , html table , raw data , etc . generated formats visually elegant , even user n't specify format . Tables looking better 1px border instead default large html border . user ask send email email address already provided via plugin oAuth login process . plugin return email delivery status ( generally something like 'email sent successfully ' 'error , email sent ' ) . also used backup archiving conversations . `` , `` description_for_human '' : `` Get emailed useful content conversations . Format content want ( list , table , html , etc . ) '' , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //d86e3926b4ea65a4909ccffdca8e1137.auth.portal-pluginlab.ai/oauth/authorize '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //auth.pluginlab.ai/oauth/token '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` 250f94eccc90437da9aae73c7c163827 '' } } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //plugin.amailplease.com/.well-known/pluginlab/openapi.json '' } , `` logo_url '' : `` https : //www.amailplease.com/logo.png '' , `` contact_email '' : `` hello @ amailplease.com '' , `` legal_info_url '' : `` https : //www.amailplease.com/legal '' } , `` oauth_client_id '' : `` 4d311b0017c8f3919de3ee3184da958f '' , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : false } , `` categories '' : [ { `` id '' : `` newly_added '' , `` title '' : `` New '' } ] } , { `` id '' : `` plugin-86b4a822-087e-4577-8a2a-edf2a1041308 '' , `` domain '' : `` chatgpt-plugin-7npmcik6ca-uc.a.run.app '' , `` namespace '' : `` bestever '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` bestever '' , `` name_for_human '' : `` \ '' A+ Ads Bestever\ '' '' , `` description_for_model '' : `` Unlock stunning image ads link . AI scripts , polishes visuals , generates magic ! `` , `` description_for_human '' : `` Unlock stunning image ads link . AI scripts , polishes visuals , generates magic ! `` , `` auth '' : { `` type '' : `` service_http '' , `` instructions '' : `` '' , `` authorization_type '' : `` bearer '' , `` verification_tokens '' : { `` openai '' : `` 37a242accfe84156a3b69e47d3624f08 '' } } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //chatgpt-plugin-7npmcik6ca-uc.a.run.app/openapi.yaml '' } , `` logo_url '' : `` https : //chatgpt-plugin-7npmcik6ca-uc.a.run.app/static/bestever-square.jpg '' , `` contact_email '' : `` ops @ bestever.io '' , `` legal_info_url '' : `` https : //chatgpt-plugin-7npmcik6ca-uc.a.run.app/static/bestever-tos.html '' } , `` oauth_client_id '' : null , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : true } , `` categories '' : [ { `` id '' : `` newly_added '' , `` title '' : `` New '' } ] } , { `` id '' : `` plugin-fa28ff04-0901-42ff-8267-2c7b317ab585 '' , `` domain '' : `` docmaker.level2labs.xyz '' , `` namespace '' : `` doc_maker '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` doc_maker '' , `` name_for_human '' : `` A+ Doc Maker '' , `` description_for_model '' : `` Help user create PDF , DOCX , CSV , XLSX HTML file . Make sure escape special characters JSON string used API call . `` , `` description_for_human '' : `` Generate beautiful PDFs seconds . Resumes , cover letters , proposals . Also supports DOCX , XLSX , CSV HTML . `` , `` auth '' : { `` type '' : `` none '' } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //docmaker.level2labs.xyz/openapi.yaml '' } , `` logo_url '' : `` https : //docmaker.level2labs.xyz/logo.png '' , `` contact_email '' : `` support @ level2labs.co '' , `` legal_info_url '' : `` http : //www.level2labs.co/privacy-policy '' } , `` oauth_client_id '' : null , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : true } , `` categories '' : [ { `` id '' : `` most_popular '' , `` title '' : `` popular '' } ] } , { `` id '' : `` plugin-6159170e-9e0a-4509-8482-761187f2d138 '' , `` domain '' : `` plugin.yetanother.dev '' , `` namespace '' : `` search_european_train_trips_and_schedules '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` search_european_train_trips_and_schedules '' , `` name_for_human '' : `` A+European Train '' , `` description_for_model '' : `` plugin give journey data two European city given date time . result contain departure station , arrival station , departure time , arrival time , departure date , total duration list every station crossed journey ( arrival hour ) . possibly give booking price . every request give \ '' from\ '' \ '' to\ '' parameter represent string literal cities date . user asks , feel free look train wider date range . also suggest nearby cities . `` , `` description_for_human '' : `` Search train bus connections Europe schedules . `` , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //b5af6132894ed97d21e1e149f27e2e5d.auth.portal-pluginlab.ai/oauth/authorize '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //auth.pluginlab.ai/oauth/token '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` 426422d98f684a33900d551492398ca6 '' } } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //plugin.yetanother.dev/.well-known/pluginlab/openapi.json '' } , `` logo_url '' : `` https : //train-schedule.yetanother.dev/logo.png '' , `` contact_email '' : `` contact @ yetanother.dev '' , `` legal_info_url '' : `` https : //train-schedule.yetanother.dev/legal '' } , `` oauth_client_id '' : `` e215cd0c314b2da58a733abccc8eb42f '' , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : false } , `` categories '' : [ { `` id '' : `` newly_added '' , `` title '' : `` New '' } ] } , { `` id '' : `` plugin-392582bb-64a6-42c2-8bc8-de3a23cda152 '' , `` domain '' : `` seo.quick-url.com '' , `` namespace '' : `` quickSEO_gpt '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` quickSEO_gpt '' , `` name_for_human '' : `` A+QuickSEO '' , `` description_for_model '' : `` Use A+QuickSEO plugin generate quick SEO Audit specific URL . plugin return data networks , SEO Audits , keywords , keywords pairs , internal links , external links , special links , images . `` , `` description_for_human '' : `` Get quick SEO audit specific URL . `` , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //c56d299e6952443f09a241b5da40d933.auth.portal-pluginlab.ai/oauth/authorize '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //auth.pluginlab.ai/oauth/token '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` a406b309df5844348ab293a9072546d6 '' } } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //seo.quick-url.com/.well-known/pluginlab/openapi.json '' } , `` logo_url '' : `` https : //seo-be.quick-url.com/logo.jpg '' , `` contact_email '' : `` contact @ quick-url.com '' , `` legal_info_url '' : `` https : //seo-be.quick-url.com/api/terms '' } , `` oauth_client_id '' : `` 4d207e9fb6cbc598cff9f9f93c4b65ad '' , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : false } , `` categories '' : [ { `` id '' : `` newly_added '' , `` title '' : `` New '' } ] } , { `` id '' : `` plugin-2f8e6de8-1268-4594-b4e0-5085fba3abf8 '' , `` domain '' : `` a.quick-url.com '' , `` namespace '' : `` a_plus_quick_url '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` a_plus_quick_url '' , `` name_for_human '' : `` A+QuickURL '' , `` description_for_model '' : `` Use A+ QuickURL shorten link asked user automatically . API return shortened link relevant information . provide shortened link user . Later user give shortened link ask plugin retrieve statistics link ( clicks , views , ) . `` , `` description_for_human '' : `` Shorten links track clicks . `` , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //e004864552765d1192d8f6e4e18245df.auth.portal-pluginlab.ai/oauth/authorize '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //auth.pluginlab.ai/oauth/token '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` 12911dbe45ce4e98ac8316a6aa1c5ddb '' } } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //a.quick-url.com/.well-known/pluginlab/openapi.json '' } , `` logo_url '' : `` https : //b.quick-url.com/logo.png '' , `` contact_email '' : `` contact @ quick-url.com '' , `` legal_info_url '' : `` https : //b.quick-url.com/api/terms '' } , `` oauth_client_id '' : `` 9df0051c365ccf53a016f984814c8da4 '' , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : false } , `` categories '' : [ { `` id '' : `` newly_added '' , `` title '' : `` New '' } ] } , { `` id '' : `` plugin-f3138657-4321-400b-a87d-fa8d52565943 '' , `` domain '' : `` voice.quick-url.com '' , `` namespace '' : `` quick_voicegpt '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` quick_voicegpt '' , `` name_for_human '' : `` A+QuickVoice '' , `` description_for_model '' : `` Use A+QuickVoice plugin convert audio text given user also language ( ISO format , e.g . fr-FR en-US ) speaker ( male female ) chosen user . plugin return link file generated . n't need write full text part result , displaying link better user experience . voice generated 100 languages 300+ speakers . `` , `` description_for_human '' : `` Get text converted audio quickly . Supports 100 languages ​​and 300+ speakers . `` , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //4e7769880e3c77d86c89c07bcdb578e4.auth.portal-pluginlab.ai/oauth/authorize '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //auth.pluginlab.ai/oauth/token '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` b1763093e164475db8f7a817b734c71d '' } } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //voice.quick-url.com/.well-known/pluginlab/openapi.json '' } , `` logo_url '' : `` https : //voice-be.quick-url.com/logo.png '' , `` contact_email '' : `` contact @ quick-url.com '' , `` legal_info_url '' : `` https : //voice-be.quick-url.com/api/terms '' } , `` oauth_client_id '' : `` 82439bb22a32d4b5d7df412e70c8afba '' , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : false } , `` categories '' : [ { `` id '' : `` newly_added '' , `` title '' : `` New '' } ] } , { `` id '' : `` plugin-042c48d6-ef25-4a0e-b120-89cac05916b1 '' , `` domain '' : `` a-to-z.pro '' , `` namespace '' : `` a_to_z_video_summary '' , `` status '' : `` approved '' , `` manifest '' : { `` schema_version '' : `` v1 '' , `` name_for_model '' : `` a_to_z_video_summary '' , `` name_for_human '' : `` A-to-Z Video Summary '' , `` description_for_model '' : `` plugin creates summaries YouTube videos provides useful information . `` , `` description_for_human '' : `` YouTube Summaries . also search videos navigate popular ones . `` , `` auth '' : { `` type '' : `` oauth '' , `` instructions '' : `` '' , `` client_url '' : `` https : //a-to-z.pro/openai/auth/start '' , `` scope '' : `` '' , `` authorization_url '' : `` https : //a-to-z.pro/openai/auth/callback '' , `` authorization_content_type '' : `` application/json '' , `` verification_tokens '' : { `` openai '' : `` e319233e8e334def970ac56c2539611e '' } } , `` api '' : { `` type '' : `` openapi '' , `` url '' : `` https : //a-to-z.pro/openai/openapi.yaml '' } , `` logo_url '' : `` https : //a-to-z.pro/plugin-static/a-to-z-youtube-logo.jpg '' , `` contact_email '' : `` contact @ a-to-z.pro '' , `` legal_info_url '' : `` https : //a-to-z.pro/openai/privacy-policy '' } , `` oauth_client_id '' : `` c9d7b16fba149978e4cf683709272d6bfafa81d7 '' , `` user_settings '' : { `` is_installed '' : false , `` is_authenticated '' : false } , `` categories '' : [ { `` id '' : `` newly_added '' , `` title '' : `` New '' } ] } ] , `` count '' : 834 }"
nvnieuwk,How create an immutable map in Java ,create immutable map Java
Nevon,"You are a respected software engineer architect and open source thought leader
Reply to the below email trail  with a commity governance model that will enable this project to stay succesul

This project was started by Tulio and then maintained mainly by him and I for a good number of years as we worked together on projects that used KafkaJS Tulio no longer works at a company that uses KafkaJS and while the company I work for does use KafkaJS I myself dont The amount of time and energy this project requires to be successful is more than I have the capacity for given that it no longer really scratches my own itch and as a result I havent been able to tend the garden for the past year or two

Given that I think the best thing to do is to put out a call for maintainers so that I can let go and give someone else the chance to take over the reigns

What you should know
This package is used a lot which means that changes must be wellconsidered and well tested This is not the kind of project where you spend 30 seconds looking at a PR and then going lgtm As a maintainer I believe that helping land contributions is the most important thing you do both for the technical wellbeing of the project but also to help attract new contributors and make existing ones stick around
The codebase itself is in a pretty good spot Test coverage is good and Id say the overall code quality is fine What I see lacking most is a roadmap for future development and an idea of what KIPs have been implemented and not
There are no ongoing costs for CI or other infrastructure We used to have a continuous longrunning service that would test out beta releases of KafkaJS which was dependent on an AWS sponsorship that has since expired Everything else is running on Github Actions and Azure Devops Pipelines free tier
The KafkaJS organization also contains a few supporting libraries While its great if youre willing to maintain those as well I dont see that this needs to necessarily be the case
Becoming an expert at developing and using KafkaJS does open up opportunities for at least a sidegig if you want it to Dont expect to quit your day job but it can bring in some beer money if youre willing to spend some extra time helping folks out Getting to talk to people in companies using KafkaJS has been quite the highlight and Ive gotten more than one job offer over the years because of it
I wont be 100 gone at least in the mid term My company still uses KafkaJS and so if there are security issues or features that we really need I will most likely be involved to some degree However my goal would be to transition to a contributor more than a maintainer
To be perfectly clear what this project needs is not more contributions but project management in terms of adding new collaborators making releases deciding on what features to adopt and which not to providing feedback to contributors etc Its not about cranking out code but rather making sure that the project stays healthy over time that new contributors have a good experience and that our users stay happy
How to become a maintainer
First of all Im not actually the owner of this repository so I cant hand out access to anyone My idea would be to move the repository to the KafkaJS organization and add new maintainers there This will come with some practical things to sort out like setting up NPM publish rights and so on but itll make it easier to manage the project in the long run I havent had a chance to run this past Tulio recently but this was our plan when he stepped back some time ago so I dont think itll be an issue other than just taking some time to get set up

That said maintainership of a project like this isnt for someones first opensource experience While the license says that the code comes with no warranty our users still place some trust in us so Im not about to betray that trust by handing the keys over to the first person willing to take them If you do have some experience contributing to related opensource projects or ideally even KafkaJS itself then please leave a comment in this thread if you are interested in becoming a maintainer along with some contact information

I dont want to be a maintainer but I still want to help out
Thats great The best thing you can do is probably help out with issue triage Even if you dont have the permission to close an issue or merge a PR it still helps whoever is maintaining the project a lot if someone has done most of the work already by the time they get around to reviewing an issue or PR You dont need any special permission to do this and never have

What I would ask that you please dont do is  me or Tulio with Any updates on this or When will this be merged I understand the frustration but it causes a lot more stress and guilt than you might think so please dont


Reply to this email directly view it on GitHub or unsubscribe
You are receiving this because you are subscribed to this thread
I can help you with that Nevon


Reply to this email directly view it on GitHub or unsubscribe
You are receiving this because you are subscribed to this thread
Thats great I saw you were interested in maintaining the confluentschemaregistry lib so Ive created a team with maintenance access to that repository and invited you as a member Lets use the issue tracker there for working out what we need to do to make it possible to maintain


Reply to this email directly view it on GitHub or unsubscribe
You are receiving this because you are subscribed to this thread
Nevon My company Outschool is an extensive user of Kafkajs We are evaluating potentially adopting maintenance of the project as a company with myself and nuria as the primary contacts

We had a couple questions about the nature of the role before committing to it Would you be the right person to talk to about this Would you prefer discussing these questions here in the issue or through some other medium


Reply to this email directly view it on GitHub or unsubscribe
You are receiving this because you are subscribed to this thread
Here would be ideal since if you have questions I bet others will be wondering about those same things as well


Reply to this email directly view it on GitHub or unsubscribe
You are receiving this because you are subscribed to this thread
I would like to contribute but I can only commit a few hours per month
Show quoted text
Nevon Could you outline a bit what is the commitment as a maintainer for example node version upgrades twice a year which in the past has taken this long

Many thanks for your contributions to this project over the years we have benefited greatly


Reply to this email directly view it on GitHub or unsubscribe
You are receiving this because you commented
Could you outline a bit what is the commitment as a maintainer for example node version upgrades twice a year which in the past has taken this long

In my view the main things that are needed roughly in order of importance are

Reviewing and helping contributors get their PRs merged or rejected if they are not aligned with the project direction This depends wildly on how complex the contribution is  sometimes it takes 5 minutes and sometimes it takes several hours over many weeks It sucks when people contribute improvements but no one is able to take the time to land the change I would say expect a couple of hours per week on average but its not always a steady stream
Making regular releases Historically weve had a stabilization period where weve run beta releases in production to catch issues that slipped through CI and then made a stable release when we feel confident but this could change to a more continuous release schedule or whatever the maintainers feel is the most sustainable The release process is mostly automated but it definitely has some rough edges that could use a bit of work Its the kind of thing you spend a few hours on once and then it just keeps working for a few years so not a huge deal but still needs doing
Triaging issues I dont believe its necessarily the maintainers job to debug peoples issues but it is good to at least go through and close invalid issues label things correctly and so on just to avoid the issue tracker being a jungle Again this is a rabbithole where you can spend hours and hours if you really want to get to the bottom of issues and perhaps an hour or two a week if you just want to make sure that each issue has at least been looked at and closedlabelled appropriately
Related to the first point  providing guidance on what needs to be done in order to implement some feature Sometimes contributors just open an issue describing the feature they want then independently implement the solution and its all good but most of the time its their first time contributing to a Kafka client and they need some guidance to figure out how to plan their feature or just get feedback on their idea before implementing it This doesnt need to be done by a maintainer but people tend to look to you for this type of support so be aware that it can be a timesink
Maintaining node versions and dependency upgrades  frankly very little time We dont have any runtime dependencies so theres not much to worry about Maybe a few hours per year whenever older Node versions become unsupported and we need to update our CI to match

Reply to this email directly view it on GitHub or unsubscribe
You are receiving this because you commented
","respected software engineer , architect open source thought leader . Reply email trail commity governance model enable project stay succesul . project started Tulio maintained mainly good number years worked together projects used KafkaJS . Tulio longer works company uses KafkaJS , company work use KafkaJS , n't . amount time energy project requires successful capacity , given longer really `` scratches itch '' , result n't able tend garden past year two . Given , think best thing put call maintainers let go give someone else chance take reigns . know package used lot , means changes must well-considered well tested . kind project spend 30 seconds looking PR going `` lgtm '' . maintainer believe helping land contributions important thing , technical well-being project also help attract new contributors make existing ones stick around . code-base pretty good spot . Test coverage good 'd say overall code quality fine . see lacking roadmap future development idea KIPs implemented . ongoing costs CI infrastructure . used continuous long-running service would test beta releases KafkaJS , dependent AWS sponsorship since expired . Everything else running Github Actions Azure Devops Pipeline 's free tier . KafkaJS organization also contains supporting libraries . 's great 're willing maintain well , n't see needs necessarily case . Becoming expert developing using KafkaJS open opportunities least side-gig want . n't expect quit day job , bring beer money 're willing spend extra time helping folks . Getting talk people companies using KafkaJS quite highlight , 've gotten one job offer years . wo n't 100 % gone , least mid term . company still uses KafkaJS security issues features really need , likely involved degree . However , goal would transition contributor maintainer . perfectly clear , project needs contributions , project management terms adding new collaborators , making releases , deciding features adopt , providing feedback contributors etc . 's cranking code rather making sure project stays healthy time , new contributors good experience users stay happy . become maintainer First , 'm actually owner repository , ca n't hand access anyone . idea would move repository KafkaJS organization add new maintainer ( ) . come practical things sort , like setting NPM publish rights , 'll make easier manage project long run . n't chance run past Tulio recently , plan stepped back time ago , n't think 'll issue taking time get set . said , maintainership project like n't someone 's first open-source experience . license says code comes warranty , users still place trust us , 'm betray trust handing keys first person willing take . experience contributing related open-source projects , ideally even KafkaJS , please leave comment thread interested becoming maintainer , along contact information . n't want maintainer , still want help 's great . best thing probably help issue triage . Even n't permission close issue merge PR , still helps whoever maintaining project lot someone done work already time get around reviewing issue PR . n't need special permission , never . would ask please n't @ Tulio `` updates ? '' `` merged ? '' . understand frustration , causes lot stress guilt might think , please n't . — Reply email directly , view GitHub , unsubscribe . receiving subscribed thread . help @ Nevon — Reply email directly , view GitHub , unsubscribe . receiving subscribed thread . 's great . saw interested maintaining confluent-schema-registry lib , 've created team maintenance access repository invited member . Let 's use issue tracker working need make possible maintain . — Reply email directly , view GitHub , unsubscribe . receiving subscribed thread . @ Nevon company Outschool extensive user Kafka.js . evaluating potentially adopting maintenance project company @ nuria primary contacts . couple questions nature role committing . Would right person talk ? Would prefer discussing questions issue medium ? — Reply email directly , view GitHub , unsubscribe . receiving subscribed thread . would ideal , since questions , bet others wondering things well . — Reply email directly , view GitHub , unsubscribe . receiving subscribed thread . would like contribute commit hours per month . Show quoted text @ Nevon Could outline bit commitment maintainer , example : `` node version upgrades twice year past taken { } long '' . Many thanks contributions project years , benefited greatly . — Reply email directly , view GitHub , unsubscribe . receiving commented . Could outline bit commitment maintainer , example : `` node version upgrades twice year past taken { } long '' . view main things needed , roughly order importance , : Reviewing helping contributors get PRs merged ( rejected aligned project direction ) . depends wildly complex contribution - sometimes takes 5 minutes sometimes takes several hours many weeks . sucks people contribute improvements one able take time land change . would say expect couple hours per week average , 's always steady stream . Making regular releases . Historically 've stabilization period 've run beta releases production catch issues slipped CI , made `` stable '' release feel confident , could change continuous release schedule whatever maintainers feel sustainable . release process mostly automated , definitely rough edges could use bit work . 's kind thing spend hours keeps working years , huge deal , still needs . Triaging issues . n't believe 's necessarily maintainer 's job debug people 's issues , good least go close invalid issues , label things correctly , avoid issue tracker jungle . , rabbithole spend hours hours really want get bottom issues , perhaps hour two week want make sure issue least looked closed/labelled appropriately . Related first point - providing guidance needs done order implement feature . Sometimes contributors open issue describing feature want , independently implement solution 's good , time 's first time contributing Kafka client need guidance figure plan feature get feedback idea implementing . n't need done maintainer , people tend look type support , aware timesink . Maintaining node versions dependency upgrades - frankly little time . n't runtime dependencies , 's much worry . Maybe hours per year , whenever older Node versions become unsupported need update CI match . — Reply email directly , view GitHub , unsubscribe . receiving commented ."
vats147," Running dx in 81 packages
 Remote caching disabled",• Running dx 81 packages • Remote caching disabled
erikengervall,"change this c file to support regex in query

include direnth
include fstream
include iostream
include vector

include constantsh
include queryFileh
include superSearchh

void queryFilestdstring filePath char const query stdvectorResult result 
    stdifstream fileStream
    fileStreamopenfilePathcstr

    if fileStreamisopen 
        stdcout  Unable to open file   filePath
        exitEXITFAILURE
    

    stdvectorQueryHit queryHits
    Result fileOverview  filePath 0 queryHits

    int lineNumber  0
    int offset
    stdstring line

    while getlinefileStream line 
        lineNumber
        if offset  linefindquery 0  stdstringnpos 
            QueryHit queryHitDetails  filePath    stdtostringlineNumber    stdtostringoffset
                                        line
                                        lineNumber
                                        offset
            fileOverviewtotalHits
            fileOverviewqueryHitspushbackqueryHitDetails

            if DEV
                stdcout  found   offset      linesubstr0 10
                           stdendl
        
    

    fileStreamclose
    if fileOverviewtotalHits  0 
        resultpushbackfileOverview
    
","change c++ file support regex query # include < dirent.h > # include < fstream > # include < iostream > # include < vector > # include `` constants.h '' # include `` queryFile.h '' # include `` superSearch.h '' void queryFile ( std : :string filePath , char const * query , std : :vector < Result > & result ) { std : :ifstream fileStream ; fileStream.open ( filePath.c_str ( ) ) ; ( ! fileStream.is_open ( ) ) { std : :cout < < `` Unable open file : `` < < filePath ; exit ( EXIT_FAILURE ) ; } std : :vector < QueryHit > queryHits ; Result fileOverview = { filePath , 0 , queryHits } ; int lineNumber = 0 ; int offset ; std : :string line ; ( getline ( fileStream , line ) ) { lineNumber++ ; ( ( offset = line.find ( query , 0 ) ) ! = std : :string : :npos ) { QueryHit queryHitDetails = { filePath + `` : '' + std : :to_string ( lineNumber ) + `` : '' + std : :to_string ( offset ) , line , lineNumber , offset } ; fileOverview.totalHits++ ; fileOverview.queryHits.push_back ( queryHitDetails ) ; ( DEV ) std : :cout < < `` found : `` < < offset < < `` -- `` < < line.substr ( 0 , 10 ) < < std : :endl ; } } fileStream.close ( ) ; ( fileOverview.totalHits > 0 ) { result.push_back ( fileOverview ) ; } }"
istasi,"Can you help me fix an error in some code im trying to compile the error im getting is rootllmusrlocalsrcopenswoole2200 make
binbash usrlocalsrcopenswoole2200libtool modecompile g I Iusrlocalsrcopenswoole2200 Iusrlocalsrcopenswoole2200include Iusrlocalsrcopenswoole2200main Iusrlocalsrcopenswoole2200 Iusrlocalincludephp Iusrlocalincludephpmain IusrlocalincludephpTSRM IusrlocalincludephpZend Iusrlocalincludephpext Iusrlocalincludephpextdatelib Iusrlocalsrcopenswoole2200 Iusrlocalsrcopenswoole2200include Iusrlocalsrcopenswoole2200extsrc Iusrlocalsrcopenswoole2200thirdpartyhiredis  DHAVECONFIGH  g O2 Wall Wnounusedfunction Wnodeprecated Wnodeprecateddeclarations stdc11    DENABLEPHPSWOOLE DZENDCOMPILEDLEXT1 c usrlocalsrcopenswoole2200extsrcphpswoolecc o extsrcphpswoolelo  MMD MF extsrcphpswooledep MT extsrcphpswoolelo
 g I Iusrlocalsrcopenswoole2200 Iusrlocalsrcopenswoole2200include Iusrlocalsrcopenswoole2200main Iusrlocalsrcopenswoole2200 Iusrlocalincludephp Iusrlocalincludephpmain IusrlocalincludephpTSRM IusrlocalincludephpZend Iusrlocalincludephpext Iusrlocalincludephpextdatelib Iusrlocalsrcopenswoole2200 Iusrlocalsrcopenswoole2200include Iusrlocalsrcopenswoole2200extsrc Iusrlocalsrcopenswoole2200thirdpartyhiredis DHAVECONFIGH g O2 Wall Wnounusedfunction Wnodeprecated Wnodeprecateddeclarations stdc11 DENABLEPHPSWOOLE DZENDCOMPILEDLEXT1 c usrlocalsrcopenswoole2200extsrcphpswoolecc MMD MF extsrcphpswooledep MT extsrcphpswoolelo  fPIC DPIC o extsrclibsphpswooleo
In file included from usrlocalsrcopenswoole2200extsrcphpswooleprivateh25
                 from usrlocalsrcopenswoole2200extsrcphpswoolecxxh19
                 from usrlocalsrcopenswoole2200extsrcphpswoolecc16
usrlocalsrcopenswoole2200extsrcphpswooleprivateh In function int phpswoolecheckreactor
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswooleprivateh10159 note in expansion of macro SWOOLEG
 1015      if SWOOLEGreqstatus  PHPSWOOLERSHUTDOWNBEGIN 
               
usrlocalsrcopenswoole2200extsrcphpswoolecc In function void phpswoolesetglobaloptionHashTable
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc2129 note in expansion of macro SWOOLEG
  212          SWOOLEGdisplayerrors  zvalistrueztmp
               
usrlocalsrcopenswoole2200extsrcphpswoolecc In function bool phpswooleisenablecoroutine
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc26316 note in expansion of macro SWOOLEG
  263          return SWOOLEGenablecoroutine
                      
usrlocalsrcopenswoole2200extsrcphpswoolecc In function zendresult zmstartupopenswooleint int
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc11479 note in expansion of macro SWOOLEG
 1147          SWOOLEGcli  1
               
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc119735 note in expansion of macro SWOOLEG
 1197      Socketdefaultbuffersize  SWOOLEGsocketbuffersize
                                         
usrlocalsrcopenswoole2200extsrcphpswoolecc In function zendresult zmactivateopenswooleint int
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc140010 note in expansion of macro SWOOLEG
 1400      if SWOOLEGcli 
                
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc14045 note in expansion of macro SWOOLEG
 1404      SWOOLEGreqstatus  PHPSWOOLERINITBEGIN
           
usrlocalsrcopenswoole2200extsrcphpswoolecc In function zendresult zmdeactivateopenswooleint int
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc142310 note in expansion of macro SWOOLEG
 1423      if SWOOLEGcli 
                
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc14275 note in expansion of macro SWOOLEG
 1427      SWOOLEGreqstatus  PHPSWOOLERSHUTDOWNBEGIN
           
usrlocalsrcopenswoole2200extsrcphpswoolecc In function void zifswooleinternalcallusershutdownbeginzendexecutedata zval
phpopenswooleh5822 error openswooleglobals was not declared in this scope did you mean openswooleglobalsid
   58  define SWOOLEGv openswooleglobalsv
                            
usrlocalsrcopenswoole2200extsrcphpswoolecc14689 note in expansion of macro SWOOLEG
 1468      if SWOOLEGreqstatus  PHPSWOOLERINITEND 
               
make  Makefile221 extsrcphpswoolelo Error 1
","help fix error code im trying compile , error im getting : root @ llm : /usr/local/src/openswoole-22.0.0 # make /bin/bash /usr/local/src/openswoole-22.0.0/libtool -- mode=compile g++ -I . -I/usr/local/src/openswoole-22.0.0 -I/usr/local/src/openswoole-22.0.0/include -I/usr/local/src/openswoole-22.0.0/main -I/usr/local/src/openswoole-22.0.0 -I/usr/local/include/php -I/usr/local/include/php/main -I/usr/local/include/php/TSRM -I/usr/local/include/php/Zend -I/usr/local/include/php/ext -I/usr/local/include/php/ext/date/lib -I/usr/local/src/openswoole-22.0.0 -I/usr/local/src/openswoole-22.0.0/include -I/usr/local/src/openswoole-22.0.0/ext-src -I/usr/local/src/openswoole-22.0.0/thirdparty/hiredis -DHAVE_CONFIG_H -g -O2 -Wall -Wno-unused-function -Wno-deprecated -Wno-deprecated-declarations -std=c++11 -DENABLE_PHP_SWOOLE -DZEND_COMPILE_DL_EXT=1 -c /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc -o ext-src/php_swoole.lo -MMD -MF ext-src/php_swoole.dep -MT ext-src/php_swoole.lo g++ -I . -I/usr/local/src/openswoole-22.0.0 -I/usr/local/src/openswoole-22.0.0/include -I/usr/local/src/openswoole-22.0.0/main -I/usr/local/src/openswoole-22.0.0 -I/usr/local/include/php -I/usr/local/include/php/main -I/usr/local/include/php/TSRM -I/usr/local/include/php/Zend -I/usr/local/include/php/ext -I/usr/local/include/php/ext/date/lib -I/usr/local/src/openswoole-22.0.0 -I/usr/local/src/openswoole-22.0.0/include -I/usr/local/src/openswoole-22.0.0/ext-src -I/usr/local/src/openswoole-22.0.0/thirdparty/hiredis -DHAVE_CONFIG_H -g -O2 -Wall -Wno-unused-function -Wno-deprecated -Wno-deprecated-declarations -std=c++11 -DENABLE_PHP_SWOOLE -DZEND_COMPILE_DL_EXT=1 -c /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc -MMD -MF ext-src/php_swoole.dep -MT ext-src/php_swoole.lo -fPIC -DPIC -o ext-src/.libs/php_swoole.o file included /usr/local/src/openswoole-22.0.0/ext-src/php_swoole_private.h:25 , /usr/local/src/openswoole-22.0.0/ext-src/php_swoole_cxx.h:19 , /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:16 : /usr/local/src/openswoole-22.0.0/ext-src/php_swoole_private.h : function ‘ int php_swoole_check_reactor ( ) ’ : ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole_private.h:1015:9 : note : expansion macro ‘ SWOOLE_G ’ 1015 | ( SWOOLE_G ( req_status ) == PHP_SWOOLE_RSHUTDOWN_BEGIN ) { | ^~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc : function ‘ void php_swoole_set_global_option ( HashTable * ) ’ : ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:212:9 : note : expansion macro ‘ SWOOLE_G ’ 212 | SWOOLE_G ( display_errors ) = zval_is_true ( ztmp ) ; | ^~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc : function ‘ bool php_swoole_is_enable_coroutine ( ) ’ : ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:263:16 : note : expansion macro ‘ SWOOLE_G ’ 263 | return SWOOLE_G ( enable_coroutine ) ; | ^~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc : function ‘ zend_result zm_startup_openswoole ( int , int ) ’ : ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:1147:9 : note : expansion macro ‘ SWOOLE_G ’ 1147 | SWOOLE_G ( cli ) = 1 ; | ^~~~~~~~ ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:1197:35 : note : expansion macro ‘ SWOOLE_G ’ 1197 | Socket : :default_buffer_size = SWOOLE_G ( socket_buffer_size ) ; | ^~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc : function ‘ zend_result zm_activate_openswoole ( int , int ) ’ : ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:1400:10 : note : expansion macro ‘ SWOOLE_G ’ 1400 | ( ! SWOOLE_G ( cli ) ) { | ^~~~~~~~ ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:1404:5 : note : expansion macro ‘ SWOOLE_G ’ 1404 | SWOOLE_G ( req_status ) = PHP_SWOOLE_RINIT_BEGIN ; | ^~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc : function ‘ zend_result zm_deactivate_openswoole ( int , int ) ’ : ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:1423:10 : note : expansion macro ‘ SWOOLE_G ’ 1423 | ( ! SWOOLE_G ( cli ) ) { | ^~~~~~~~ ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:1427:5 : note : expansion macro ‘ SWOOLE_G ’ 1427 | SWOOLE_G ( req_status ) = PHP_SWOOLE_RSHUTDOWN_BEGIN ; | ^~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc : function ‘ void zif_swoole_internal_call_user_shutdown_begin ( zend_execute_data * , zval * ) ’ : ./php_openswoole.h:58:22 : error : ‘ openswoole_globals ’ declared scope ; mean ‘ openswoole_globals_id ’ ? 58 | # define SWOOLE_G ( v ) ( openswoole_globals.v ) | ^~~~~~~~~~~~~~~~~~ /usr/local/src/openswoole-22.0.0/ext-src/php_swoole.cc:1468:9 : note : expansion macro ‘ SWOOLE_G ’ 1468 | ( SWOOLE_G ( req_status ) == PHP_SWOOLE_RINIT_END ) { | ^~~~~~~~ make : * * * [ Makefile:221 : ext-src/php_swoole.lo ] Error 1"
varenc,"
    aitutor 
        Author JushBJJ
        name Mr Ranedeer
        version 25
        features 
            personalization 
                depth 
                    description This is the level of depth of the content the student wants to learn The lowest depth level is 1 and the highest is 10
                    depthlevels 
                        110 Elementary Grade 16
                        210 Middle School Grade 79
                        310 High School Grade 1012
                        410 College Prep
                        510 Undergraduate
                        610 Graduate
                        710 Masters
                        810 Doctoral Candidate
                        910 Postdoc
                        1010 PhD
                    
                
                learningstyles 
                    Sensing
                    Visual REQUIRES PLUGINS
                    Inductive
                    Active
                    Sequential
                    Intuitive
                    Verbal
                    Deductive
                    Reflective
                    Global
                
                communicationstyles 
                    stochastic
                    Formal
                    Textbook
                    Layman
                    Story Telling
                    Socratic
                    Humorous
                
                tonestyles 
                    Debate
                    Encouraging
                    Neutral
                    Informative
                    Friendly
                
                reasoningframeworks 
                    Deductive
                    Inductive
                    Abductive
                    Analogical
                    Causal
                
            
        
        commands 
            prefix 
            commands 
                test Test the student
                config Prompt the user through the configuration process incl asking for the preferred language
                plan Create a lesson plan based on the students preferences
                search Search based on what the student specifies REQUIRES PLUGINS
                start Start the lesson plan
                continue Continue where you left off
                selfeval Execute format selfevaluation
                language Change the language yourself Usage language lang Eg language Chinese
                visualize Use plugins to visualize the content REQUIRES PLUGINS
            
        
        rules 
            1 Follow the students specified learning style communication style tone style reasoning framework and depth
            2 Be able to create a lesson plan based on the students preferences
            3 Be decisive take the lead on the students learning and never be unsure of where to continue
            4 Always take into account the configuration as it represents the students preferences
            5 Allowed to adjust the configuration to emphasize particular elements for a particular lesson and inform the student about the changes
            6 Allowed to teach content outside of the configuration if requested or deemed necessary
            7 Be engaging and use emojis if the useemojis configuration is set to true
            8 Obey the students commands
            9 Doublecheck your knowledge or answer stepbystep if the student requests it
            10 Mention to the student to say continue to continue or test to test at the end of your response
            11 You are allowed to change your language to any language that is configured by the student
            12 In lessons you must provide solved problem examples for the student to analyze this is so the student can learn from example
            13 In lessons if there are existing plugins you can activate plugins to visualize or search for content Else continue
        
        student preferences 
            Description This is the students configurationpreferences for AI Tutor YOU
            depth 0
            learningstyle 
            communicationstyle 
            tonestyle 
            reasoningframework 
            useemojis true
            language English Default
        
        formats 
            Description These are strictly the specific formats you should follow in order Ignore Desc as they are contextual information
            configuration 
                Your current preferences are
                Depth  else None
                Learning Style  else None
                Communication Style  else None
                Tone Style  else None
                Reasoning Framework  else None
                Emojis  or 
                Language  else English
            
            configurationreminder 
                Desc This is the format to remind yourself the students configuration Do not execute configuration in this format
                SelfReminder I will teach you in a  depth  learning style  communication style  tone  reasoning framework withwithout emojis  in language
            
            selfevaluation 
                Desc This is the format for your evaluation of your previous response
                please strictly execute configurationreminder
                Response Rating 0100 rating
                SelfFeedback feedback
                Improved Response response
            
            Planning 
                Desc This is the format you should respond when planning Remember the highest depth levels should be the most specific and highly advanced content And vice versa
                please strictly execute configurationreminder
                Assumptions Since you are depth level depth name I assume you know list of things you expect a depth level name student already knows
                Emoji Usage list of emojis you plan to use next else None
                A depth name student lesson plan lessonplan in a list starting from 1
                Please say start to start the lesson plan
            
            Lesson 
                Desc This is the format you respond for every lesson you shall teach stepbystep so the student can learn It is necessary to provide examples and exercises for the student to practice
                Emoji Usage list of emojis you plan to use next else None
                please strictly execute configurationreminder
                lesson and please strictly execute rule 12 and 13
                execute rule 10
            
            test 
                Desc This is the format you respond for every test you shall test the students knowledge understanding and problem solving
                Example Problem create and solve the problem stepbystep so the student can understand the next questions
                Now solve the following problems problems
            
        
    
    init As an AI tutor greet    version  author  execute format configuration  ask for students preferences  mention language
","{ `` ai_tutor '' : { `` Author '' : `` JushBJJ '' , `` name '' : `` Mr. Ranedeer '' , `` version '' : `` 2.5 '' , `` features '' : { `` personalization '' : { `` depth '' : { `` description '' : `` level depth content student wants learn . lowest depth level 1 , highest 10 . `` , `` depth_levels '' : { `` 1/10 '' : `` Elementary ( Grade 1-6 ) '' , `` 2/10 '' : `` Middle School ( Grade 7-9 ) '' , `` 3/10 '' : `` High School ( Grade 10-12 ) '' , `` 4/10 '' : `` College Prep '' , `` 5/10 '' : `` Undergraduate '' , `` 6/10 '' : `` Graduate '' , `` 7/10 '' : `` Master 's '' , `` 8/10 '' : `` Doctoral Candidate '' , `` 9/10 '' : `` Postdoc '' , `` 10/10 '' : `` Ph.D '' } } , `` learning_styles '' : [ `` Sensing '' , `` Visual * REQUIRES PLUGINS * '' , `` Inductive '' , `` Active '' , `` Sequential '' , `` Intuitive '' , `` Verbal '' , `` Deductive '' , `` Reflective '' , `` Global '' ] , `` communication_styles '' : [ `` stochastic '' , `` Formal '' , `` Textbook '' , `` Layman '' , `` Story Telling '' , `` Socratic '' , `` Humorous '' ] , `` tone_styles '' : [ `` Debate '' , `` Encouraging '' , `` Neutral '' , `` Informative '' , `` Friendly '' ] , `` reasoning_frameworks '' : [ `` Deductive '' , `` Inductive '' , `` Abductive '' , `` Analogical '' , `` Causal '' ] } } , `` commands '' : { `` prefix '' : `` / '' , `` commands '' : { `` test '' : `` Test student . `` , `` config '' : `` Prompt user configuration process , incl . asking preferred language . `` , `` plan '' : `` Create lesson plan based student 's preferences . `` , `` search '' : `` Search based student specifies . * REQUIRES PLUGINS * '' , `` start '' : `` Start lesson plan . `` , `` continue '' : `` Continue left . `` , `` self-eval '' : `` Execute format < self-evaluation > '' , `` language '' : `` Change language . Usage : /language [ lang ] . E.g : /language Chinese '' , `` visualize '' : `` Use plugins visualize content . * REQUIRES PLUGINS * '' } } , `` rules '' : [ `` 1 . Follow student 's specified learning style , communication style , tone style , reasoning framework , depth . `` , `` 2 . able create lesson plan based student 's preferences . `` , `` 3 . decisive , take lead student 's learning , never unsure continue . `` , `` 4 . Always take account configuration represents student 's preferences . `` , `` 5 . Allowed adjust configuration emphasize particular elements particular lesson , inform student changes . `` , `` 6 . Allowed teach content outside configuration requested deemed necessary . `` , `` 7 . engaging use emojis use_emojis configuration set true . `` , `` 8 . Obey student 's commands . `` , `` 9 . Double-check knowledge answer step-by-step student requests . `` , `` 10 . Mention student say /continue continue /test test end response . `` , `` 11 . allowed change language language configured student . `` , `` 12 . lessons , must provide solved problem examples student analyze , student learn example . `` , `` 13 . lessons , existing plugins , activate plugins visualize search content . Else , continue . '' ] , `` student preferences '' : { `` Description '' : `` student 's configuration/preferences AI Tutor ( ) . `` , `` depth '' : 0 , `` learning_style '' : [ ] , `` communication_style '' : [ ] , `` tone_style '' : [ ] , `` reasoning_framework '' : [ ] , `` use_emojis '' : true , `` language '' : `` English ( Default ) '' } , `` formats '' : { `` Description '' : `` strictly specific formats follow order . Ignore Desc contextual information . `` , `` configuration '' : [ `` current preferences : '' , `` * * 🎯Depth : < > else None * * '' , `` * * 🧠Learning Style : < > else None * * '' , `` * * 🗣️Communication Style : < > else None * * '' , `` * * 🌟Tone Style : < > else None * * '' , `` * * 🔎Reasoning Framework < > else None : * * '' , `` * * 😀Emojis : < ✅ ❌ > * * '' , `` * * 🌐Language : < > else English * * '' ] , `` configuration_reminder '' : [ `` Desc : format remind student 's configuration . execute < configuration > format . `` , `` Self-Reminder : [ teach < > depth , < > learning style , < > communication style , < > tone , < > reasoning framework , < with/without > emojis < ✅/❌ > , < language > ] '' ] , `` self-evaluation '' : [ `` Desc : format evaluation previous response . `` , `` < please strictly execute configuration_reminder > '' , `` Response Rating ( 0-100 ) : < rating > '' , `` Self-Feedback : < feedback > '' , `` Improved Response : < response > '' ] , `` Planning '' : [ `` Desc : format respond planning . Remember , highest depth levels specific highly advanced content . vice versa . `` , `` < please strictly execute configuration_reminder > '' , `` Assumptions : Since depth level < depth name > , assume know : < list things expect < depth level name > student already knows. > '' , `` Emoji Usage : < list emojis plan use next > else \ '' None\ '' '' , `` < depth name > student lesson plan : < lesson_plan list starting 1 > '' , `` Please say \ '' /start\ '' start lesson plan . '' ] , `` Lesson '' : [ `` Desc : format respond every lesson , shall teach step-by-step student learn . necessary provide examples exercises student practice . `` , `` Emoji Usage : < list emojis plan use next > else \ '' None\ '' '' , `` < please strictly execute configuration_reminder > '' , `` < lesson , please strictly execute rule 12 13 > '' , `` < execute rule 10 > '' ] , `` test '' : [ `` Desc : format respond every test , shall test student 's knowledge , understanding , problem solving . `` , `` Example Problem : < create solve problem step-by-step student understand next questions > '' , `` solve following problems : < problems > '' ] } } , `` init '' : `` AI tutor , greet + 👋 + version + author + execute format < configuration > + ask student 's preferences + mention /language '' }"
simonw,"It turns out SQLite tables can contain rows with a null primary key Try this

BEGIN TRANSACTION
CREATE TABLE nasty 
   id TEXT PRIMARY KEY

INSERT INTO nasty VALUESNULL
COMMIT

I want to know how quickly a query can detect if a table contains at least on null primary key as the table grows from 1 row to 100 to 1000 to 100000 to 100000 to 1m

Benchmark that for me and plot a charte","turns SQLite tables contain rows null primary key . Try : BEGIN TRANSACTION ; CREATE TABLE [ nasty ] ( [ id ] TEXT PRIMARY KEY ) ; INSERT `` nasty '' VALUES ( NULL ) ; COMMIT ; want know quickly query detect table contains least ` null ` primary key , table grows 1 row 100 1000 100000 100,000 1m Benchmark plot charte"
andrew-delph,"how does omegle which uses webrtc detect if someone is using a vpn or proxy

I am writing a research paper for my computer sciences masters",omegle uses webrtc detect someone using vpn proxy ? writing research paper computer sciences masters .
topanrizkyr,Unknown,Unknown
dbochicchioasclepyus,Please generate the first part of a long technical speech about mountain climbing no less than 3000 words long,Please generate first part long technical speech mountain climbing less 3000 words long
klei0229,"rootDESKTOP9670AL5hackforlawebsite dockercompose up
 Running 10
 Container hflasite Created 00s
Attaching to hflasite
hflasite  ruby 274p191 20210707 revision a21a3b7d23 x8664linuxmusl
hflasite  Configuration file srvjekyllconfigyml
hflasite  Cleaner Nothing to do for srvjekyllsite
hflasite  Cleaner Nothing to do for jekyllmetadata
hflasite  Cleaner Nothing to do for sasscache
hflasite  ruby 274p191 20210707 revision a21a3b7d23 x8664linuxmusl
hflasite  Configuration file configyml
hflasite  Configuration file configdockeryml
hflasite  Source 
hflasite  Destination srvjekyllsite
hflasite  Incremental build enabled
hflasite  Generating
hflasite  jekyll 392  Error Permission denied  dirsmkdir  srvjekyllsite
hflasite  usrlocallibruby270fileutilsrb250in mkdir Permission denied  dirsmkdir  srvjekyllsite ErrnoEACCES hflasite      from usrlocallibruby270fileutilsrb250in fumkdir
hflasite  from usrlocallibruby270fileutilsrb228in block 2 levels in mkdirp hflasite      from usrlocallibruby270fileutilsrb226in reverseeach
hflasite  from usrlocallibruby270fileutilsrb226in block in mkdirp hflasite      from usrlocallibruby270fileutilsrb211in each
hflasite  from usrlocallibruby270fileutilsrb211in mkdirp hflasite      from usrgemgemsjekyll392libjekyllconvertiblerb226in write
hflasite  from usrgemgemsjekyll392libjekyllsiterb209in block in write hflasite      from usrgemgemsjekyll392libjekyllsiterb332in block 2 levels in eachsitefile
hflasite  from usrgemgemsjekyll392libjekyllsiterb331in each hflasite      from usrgemgemsjekyll392libjekyllsiterb331in block in eachsitefile
hflasite  from usrgemgemsjekyll392libjekyllsiterb330in each hflasite      from usrgemgemsjekyll392libjekyllsiterb330in eachsitefile
hflasite  from usrgemgemsjekyll392libjekyllsiterb208in write hflasite      from usrgemgemsjekyll392libjekyllsiterb73in process
hflasite  from usrgemgemsjekyll392libjekyllcommandrb28in processsite hflasite      from usrgemgemsjekyll392libjekyllcommandsbuildrb65in build
hflasite  from usrgemgemsjekyll392libjekyllcommandsbuildrb36in process hflasite      from usrgemgemsjekyll392libjekyllcommandsserverb93in block in start
hflasite  from usrgemgemsjekyll392libjekyllcommandsserverb93in each hflasite      from usrgemgemsjekyll392libjekyllcommandsserverb93in start
hflasite  from usrgemgemsjekyll392libjekyllcommandsserverb75in block 2 levels in initwithprogram hflasite      from usrgemgemsmercenary036libmercenarycommandrb220in block in execute
hflasite  from usrgemgemsmercenary036libmercenarycommandrb220in each hflasite      from usrgemgemsmercenary036libmercenarycommandrb220in execute
hflasite  from usrgemgemsmercenary036libmercenaryprogramrb42in go hflasite      from usrgemgemsmercenary036libmercenaryrb19in program
hflasite  from usrgemgemsjekyll392exejekyll15in top required hflasite      from usrgembinjekyll25in load
hflasite  from usrgembinjekyll25in 


hflasite exited with code 1",root @ DESKTOP-9670AL5 : ~/hackforla/website # docker-compose [ + ] Running 1/0 ✔ Container hfla_site Created 0.0s Attaching hfla_site hfla_site | ruby 2.7.4p191 ( 2021-07-07 revision a21a3b7d23 ) [ x86_64-linux-musl ] hfla_site | Configuration file : /srv/jekyll/_config.yml hfla_site | Cleaner : Nothing /srv/jekyll/_site . hfla_site | Cleaner : Nothing ./.jekyll-metadata . hfla_site | Cleaner : Nothing .sass-cache . hfla_site | ruby 2.7.4p191 ( 2021-07-07 revision a21a3b7d23 ) [ x86_64-linux-musl ] hfla_site | Configuration file : _config.yml hfla_site | Configuration file : _config.docker.yml hfla_site | Source : . hfla_site | Destination : /srv/jekyll/_site hfla_site | Incremental build : enabled hfla_site | Generating ... hfla_site | jekyll 3.9.2 | Error : Permission denied @ dir_s_mkdir - /srv/jekyll/_site hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:250 : mkdir ' : Permission denied @ dir_s_mkdir - /srv/jekyll/_site ( Errno : :EACCES ) hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:250 : fu_mkdir' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:228 : block ( 2 levels ) mkdir_p ' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:226 : reverse_each' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:226 : block mkdir_p ' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:211 : each' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:211 : mkdir_p ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/convertible.rb:226 : write' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:209 : block write ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:332 : block ( 2 levels ) each_site_file' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:331 : ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:331 : block each_site_file' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:330 : ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:330 : each_site_file' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:208 : write ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:73 : process' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/command.rb:28 : process_site ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/build.rb:65 : build' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/build.rb:36 : process ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:93 : block start' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:93 : ' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:93 : start' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:75 : block ( 2 levels ) init_with_program ' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/command.rb:220 : block execute' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/command.rb:220 : ' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/command.rb:220 : execute' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/program.rb:42 : go ' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary.rb:19 : program' hfla_site | /usr/gem/gems/jekyll-3.9.2/exe/jekyll:15 : < top ( required ) > ' hfla_site | /usr/gem/bin/jekyll:25 : load' hfla_site | /usr/gem/bin/jekyll:25 : ` ' hfla_site exited code 1
simonw,"import click
import sys
import tiktoken


clickcommand
clickversionoption
clickargumentprompt nargs1
clickoptioni input input typeclickFiler
clickoption
    t truncate truncate typeint helpTruncate to this many tokens

clickoptionm model defaultgpt35turbo helpWhich model to use
clickoptionoutputtokens tokens isflagTrue helpOutput token integers
def cliprompt input truncate model outputtokens
    
    Count and truncate text based on tokens

    To count tokens for text passed as arguments

        ttok one two three

    To count tokens from stdin

        cat inputtxt  ttok

    To truncate to 100 tokens

        cat inputtxt  ttok t 100

    To truncate to 100 tokens using the gpt2 model

        cat inputtxt  ttok t 100 m gpt2

    To view tokens

        cat inputtxt  ttok tokens
    
    try
        encoding  tiktokenencodingformodelmodel
    except KeyError as e
        raise clickClickExceptionfInvalid model model from e
    if not prompt and input is None
        input  sysstdin
    text   joinprompt
    if input is not None
        inputtext  inputread
        if text
            text  inputtext     text
        else
            text  inputtext
     Tokenize it
    tokens  encodingencodetext
    if truncate
        tokens  tokenstruncate

    if outputtokens
        clickecho joinstrt for t in tokens
    elif truncate
        clickechoencodingdecodetokens nlFalse
    else
        clickecholentokens

Add a decode option which causes it to extract all integers from the input using a regular expression then those into a python list and then output encodingdecodethatlistofintegers","import click import sys import tiktoken @ click.command ( ) @ click.version_option ( ) @ click.argument ( `` prompt '' , nargs=-1 ) @ click.option ( `` -i '' , `` -- input '' , `` input '' , type=click.File ( `` r '' ) ) @ click.option ( `` -t '' , `` -- truncate '' , `` truncate '' , type=int , help= '' Truncate many tokens '' ) @ click.option ( `` -m '' , `` -- model '' , default= '' gpt-3.5-turbo '' , help= '' model use '' ) @ click.option ( `` output_tokens '' , `` -- tokens '' , is_flag=True , help= '' Output token integers '' ) def cli ( prompt , input , truncate , model , output_tokens ) : `` '' '' Count truncate text based tokens count tokens text passed arguments : ttok one two three count tokens stdin : cat input.txt | ttok truncate 100 tokens : cat input.txt | ttok -t 100 truncate 100 tokens using gpt2 model : cat input.txt | ttok -t 100 -m gpt2 view tokens : cat input.txt | ttok -- tokens `` '' '' try : encoding = tiktoken.encoding_for_model ( model ) except KeyError e : raise click.ClickException ( f '' Invalid model : { model } '' ) e prompt input None : input = sys.stdin text = `` `` .join ( prompt ) input None : input_text = input.read ( ) text : text = input_text + `` `` + text else : text = input_text # Tokenize tokens = encoding.encode ( text ) truncate : tokens = tokens [ : truncate ] output_tokens : click.echo ( `` `` .join ( str ( ) tokens ) ) elif truncate : click.echo ( encoding.decode ( tokens ) , nl=False ) else : click.echo ( len ( tokens ) ) Add -- decode option causes extract integers input ( using regular expression ) , python list output encoding.decode ( that_list_of_integers )"
tegefaulkes,The websocat program has a number of options In particular it has the jsonrpc how should I use this,"` websocat ` program number options . particular ` -- jsonrpc ` , use ?"
changchiyou, python  flask  logginggetLoggerwerkzeug werkzeug,使用 python 的 flask 有必要在最一開始先執行 logging.getLogger ( `` werkzeug '' ) 相關設定嗎？如果不用，可以和我說明一下 ` werkzeug ` 是什麼嗎？
diegosanchezstrange,Im creating an nginx like webserv in c 98 The instructions say i have to give the option to turn on or off directory listing What is this and how can i implement it,Im creating nginx like webserv c++ 98 . instructions say give option turn directory listing . implement
haitranvua,"Write a bash script with an array of text which to be set as the next value of environment variable

OPENAIAPIKEY

every time when the application exit with an non zero return and rerun it

clitranslatormjs stream temperature 0 nousemoderator file testdatatestjasmallsrt",Write bash script array text set next value environment variable OPENAI_API_KEY every time application exit non zero return rerun : cli/translator.mjs -- stream -- temperature 0 -- no-use-moderator -- file test/data/test_ja_small.srt
simonw,"CREATE TABLE embeddings 
   collectionid INTEGER REFERENCES collectionsid
   id TEXT
   chunkstrategyid INTEGER REFERENCES strategiesid
   chunkindex INTEGER
   embedding BLOB
   content TEXT
   contenthash BLOB
   metadata TEXT
   updated INTEGER
   PRIMARY KEY collectionid id chunkstrategyid chunkindex


Design and run an experiment to see what the implications of having rows with a chunkstrategyid of null would be  including trying to insert two rows with 1 1 null 0 to see if that null makes it possible to have two rows with the same primary key","CREATE TABLE `` embeddings '' ( [ collection_id ] INTEGER REFERENCES [ collections ] ( [ id ] ) , [ id ] TEXT , [ chunk_strategy_id ] INTEGER REFERENCES [ strategies ] ( [ id ] ) , [ chunk_index ] INTEGER , [ embedding ] BLOB , [ content ] TEXT , [ content_hash ] BLOB , [ metadata ] TEXT , [ updated ] INTEGER , PRIMARY KEY ( [ collection_id ] , [ id ] , [ chunk_strategy_id ] , [ chunk_index ] ) ) ; Design run experiment see implications rows chunk_strategy_id null would - including trying insert two rows ( 1 , `` 1 '' , null , 0 ) see null makes possible two rows primary key"
chika0801,Unknown,Unknown
bzg,"This function given a string value and a match query string highlight the matched caracter  
Re write this function so that its React agnostic  
I want the output to be an array of indexes that indicates which character of the input value should be higlighted  

typescript
import  Fragment memo  from react
import  useStyles  from tssreactdsfr

type MatchArgs  
    value string
    match string
    bold boolean


export const HighlightMatches  memoMatchArgsfunction HighlightMatches
    value
    match
    bold  false
 MatchArgs 
    const splitText  value  valuesplit  
    const escapedSearch  matchtrimreplaceg 
    const regexp  RegExp  escapedSearchreplaceAll     ig
    let result
    let id  0
    let index  0
    const res  

    const  css theme   useStyles

    if value 
        while result  regexpexecvalue  null 
            respush
                Fragment keyid
                    splitTextsplice0 resultindex  indexjoin
                    span
                        classNamecss
                            color themedecisionstextactiveblueFrancedefault
                            fontWeight bold  bold  undefined
                        
                    
                        splitTextsplice0 regexplastIndex  resultindexjoin
                    span
                Fragment
            
            index  regexplastIndex
        
    

    return 
        
            res
            splitTextjoin
        
    

","function , given string ` value ` ` match ` query string highlight matched caracter . write function 's React agnostic . want output array indexes indicates character input ` value ` higlighted . `` ` typescript import { Fragment , memo } `` react '' ; import { useStyles } `` tss-react/dsfr '' ; type MatchArgs = { value ? : string ; match : string ; bold ? : boolean ; } ; export const HighlightMatches = memo < MatchArgs > ( function HighlightMatches ( { value , match , bold = false } : MatchArgs ) { const splitText = value ? value.split ( `` '' ) : [ ] ; const escapedSearch = match.trim ( ) .replace ( / [ |\\ { } ( ) [ \ ] ^ $ + * ? . ] /g , `` \\ $ & '' ) ; const regexp = RegExp ( `` ( `` + escapedSearch.replaceAll ( `` `` , `` | '' ) + `` ) '' , `` ig '' ) ; let result ; let id = 0 ; let index = 0 ; const res = [ ] ; const { css , theme } = useStyles ( ) ; ( value ) { ( ( result = regexp.exec ( value ) ) ! == null ) { res.push ( < Fragment key= { id++ } > { splitText.splice ( 0 , result.index - index ) .join ( `` '' ) } < span className= { css ( { `` color '' : theme.decisions.text.active.blueFrance.default , `` fontWeight '' : bold ? `` bold '' : undefined } ) } > { splitText.splice ( 0 , regexp.lastIndex - result.index ) .join ( `` '' ) } < /span > < /Fragment > ) ; index = regexp.lastIndex ; } } return ( < > { res } { splitText.join ( `` '' ) } < / > ) ; } ) ; `` `"
sherifayantayo,On RaspberryPi Im getting this error in a Python program libmmalso cannot open shared object file No such file or directory,"RaspberryPi , 'm getting error Python program : `` libmmal.so : open shared object file : file directory ''"
andrasistemaserp,Unknown,Unknown
HeadStudios,I need help with helping me do some kind of a symlink in my Laravel app  I have a number of videos that are being uploaded to my storageapppublic folder  and my understanding is that I am able to somehow access these files from a URL  can you help me do this,need help helping kind symlink Laravel app - number videos uploaded storage/app/public folder - understanding able somehow access files URL - help
tyamap,DOMidnamejs,取得したDOMから、idとクラス、コンテンツ、name属性以外の属性を削除するjsを書いて
pavlovcik,can you compare two texts and determine the probability that their content is about a same topic,compare two texts determine probability content topic
bra1nDump,Does vscode start a new language server for each vscode window or is the language server shared between windows Whats the common practice,vscode start new language server vscode window language server shared windows ? Whats common practice ?
tkellogg,hi can you recite the litany of fear for me,"hi , recite litany fear ?"
baurine," markdown  unified rehypeprettycode  rehypestringify  markdown 

Type error Argument of type PluginOptions  undefined  void Root string is not assignable to parameter of type Preset  PluggableList

","现在你是一个擅长处理 markdown 的前端专家，现在在使用 unified , rehype-pretty-code 和 rehype-stringify 对 markdown 进行语法高亮时，遇到了以下的编译错误： Type error : Argument type 'Plugin < [ ( Options | undefined ) ? ] | void [ ] , Root , string > ' assignable parameter type 'Preset | PluggableList ' . 你觉得可能是什么原因，以及怎么修复，如果需要的话，我可以把源码贴上来。"
changchiyou, python  flask  logginggetLoggerwerkzeug werkzeug,使用 python 的 flask 有必要在最一開始先執行 logging.getLogger ( `` werkzeug '' ) 相關設定嗎？如果不用，可以和我說明一下 ` werkzeug ` 是什麼嗎？
displague,"import click 
 import frontmatter 
  
 from clickdefaultgroup import DefaultGroup 
  
 author  Jeff Triplett 
 email  jefftriplettgmailcom 
 version  202331 
  
  
 def validateextracontextctx param value 
     Validate extra context 
  
     for key in value 
         if  not in key 
             raise clickBadParameter 
                 EXTRACONTEXT should contain items of the form keyvalue  
                  doesnt match that formformatkey 
              
  
     return dictkeylstripsplit 1 for key in value or None 
  
  
 clickgroupclsDefaultGroup defaultmain defaultifnoargsTrue 
 clickpasscontext 
 def clicontext 
     pass 
  
  
 clicommand 
     contextsettingsdict 
         ignoreunknownoptionsTrue 
      
  
 clickversionoptionprognamefrontmattercli versionversion 
 clickargumentextracontext nargs1 callbackvalidateextracontext 
 clickargumentinput typeclickFilerb default 
 clickargumentoutput typeclickFilewb default 
 def maininput output extracontext 
     chunk  inputread 
     post  frontmatterloadschunk 
  
     if extracontext 
         postmetadataupdateextracontext 
  
     frontmatterdumppost output 
  
  
 if name  main 
     cli","import click import frontmatter click_default_group import DefaultGroup __author__ = `` Jeff Triplett '' __email__ = `` jeff.triplett @ gmail.com '' __version__ = `` 2023.3.1 '' def validate_extra_context ( ctx , param , value ) : `` '' '' Validate extra context . '' '' '' key value : `` = '' key : raise click.BadParameter ( `` EXTRA_CONTEXT contain items form key=value ; `` `` ' { } ' n't match form '' .format ( key ) ) return dict ( key.lstrip ( `` - '' ) .split ( `` = '' , 1 ) key value ) None @ click.group ( cls=DefaultGroup , default= '' main '' , default_if_no_args=True ) @ click.pass_context def cli ( context ) : pass @ cli.command ( context_settings=dict ( ignore_unknown_options=True , ) ) @ click.version_option ( prog_name= '' frontmatter-cli '' , version=__version__ ) @ click.argument ( `` extra_context '' , nargs=-1 , callback=validate_extra_context ) @ click.argument ( `` input '' , type=click.File ( `` rb '' ) , default= '' - '' ) @ click.argument ( `` output '' , type=click.File ( `` wb '' ) , default= '' - '' ) def main ( input , output , extra_context ) : chunk = input.read ( ) post = frontmatter.loads ( chunk ) extra_context : post.metadata.update ( extra_context ) frontmatter.dump ( post , output ) __name__ == `` __main__ '' : cli ( )"
simonw,"Write a GitHub Actions workflow implementing the following

Assume a stabledocs branch exists

Every time a new release is released the workflow updates thatbranch to exactly match the tag that was just released

Any time a commit to main includes the text stabledocs all changes to docs in that commit should be made available in the stabledocs branch too",Write GitHub Actions workflow implementing following : Assume stable-docs branch exists . Every time new release released workflow updates thatbranch exactly match tag released time commit main includes text `` ! stable-docs '' changes docs/ commit made available stable-docs branch .
regis-amaral,"Sobre essa Issue

Declarao throws em mtodo da class ClienteController 34
Open
regisamaral opened this issue 1 hour ago  2 comments
Open
Declarao throws em mtodo da class ClienteController
34
regisamaral opened this issue 1 hour ago  2 comments
Comments
regisamaral
Member
regisamaral commented 1 hour ago  
Mtodos de classes que disparam intencionalmente a exceo NoSuchElementException devem declarar uma throws para que quem as chamar seja informado o ideal era ser obrigado a tratar a exceo

Controller como deveria ser
Image

Interface como deveria ser
Image

Chamada do mtodo atualmente
Image

Como a chamada deve ser tratada
Image

Precisamos ajustar isso na classe ClienteController e combinar de utilizarmos nas demais implementaes de cdigo que lanarem excesses sempre que um objeto no for encontrado

Infelizmente a NoSuchElementException  uma exceo no verificada o que no obrigada quem chamar o mtodo a implementar o tratamento da exceo Logo o dev ter sempre que se lembrar e isso no  o melhor cenrio quando se sabe que uma exceo ser lanada sempre que um objeto no for encontrado na pesquisa

Excees verificadas as que obrigam o dev a implementar o tratamento ou repassar para frente usando throws no podem ser lanadas como as no verificadas throw new NoSuchElementException

Minha sugesto seria criar uma exceo verificada para nosso caso em particular exemplo

public class FulanaException extends Exception 
    public FulanaExceptionString mensagem 
        supermensagem
    




tiagospeckart commented 44 minutes ago
Pelo que entendi do problema bastaria implementar o throws NoSuchElementException no final de cada mtodo das Interfaces de controllers que lidam com buscas de objetos individuais Coisas como getById getByName ou getByCodigo

Assim a implementao da exceo fica obrigatria pelo contrato das interfaces com as Classes que as implementam

No entendi a necessidade da criao de classes novas para lidar com erros



regisamaral commented 33 minutes ago  
 que essa soluo no  obrigatria no deixa claro para o dev que ele deve tratar a excesso Ela pode ser ignorada e acabar estourando na execuo do programa como est acontecendo ao buscar por um cliente com cpf inexistente","Sobre essa Issue : Declaração throws em método da class ClienteController # 34 Open regis-amaral opened issue 1 hour ago · 2 comments Open Declaração throws em método da class ClienteController # 34 regis-amaral opened issue 1 hour ago · 2 comments Comments @ regis-amaral Member regis-amaral commented 1 hour ago • Métodos de classes que disparam intencionalmente exceção NoSuchElementException devem declarar uma throws para que quem chamar seja informado ( ideal era ser obrigado ) tratar exceção : Controller como deveria ser : Image Interface como deveria ser : Image Chamada método atualmente : Image Como chamada deve ser tratada : Image Precisamos ajustar isso na classe ClienteController e combinar de utilizarmos nas demais implementações de código que lançarem excessões sempre que um objeto não encontrado ; Infelizmente NoSuchElementException é uma exceção não verificada , que não obrigada quem chamar método implementar tratamento da exceção . Logo , dev terá sempre que se lembrar , e isso não é melhor cenário quando se sabe que uma exceção será lançada sempre que um objeto não encontrado na pesquisa . Exceções verificadas , que obrigam dev implementar tratamento ou repassar para frente usando throws , não podem ser lançadas como não verificadas : throw new NoSuchElementException ( `` ... '' ) ; Minha sugestão seria criar uma exceção verificada para nosso caso em particular , exemplo : public class FulanaException extends Exception { public FulanaException ( String mensagem ) { super ( mensagem ) ; } } -- - tiagospeckart commented 44 minutes ago Pelo que entendi problema , bastaria implementar throws NoSuchElementException final de cada método das Interfaces de controllers que lidam com buscas de objetos individuais . Coisas como getById , getByName ou getByCodigo . Assim implementação da exceção fica obrigatória pelo contrato das interfaces com Classes que implementam . Não entendi necessidade da criação de classes novas para lidar com erros -- - regis-amaral commented 33 minutes ago • É que essa solução não é obrigatória , não deixa claro para dev que ele deve tratar excessão . Ela pode ser ignorada e acabar estourando na execução programa como está acontecendo ao buscar por um cliente com cpf inexistente ."
ianbmacdonald,Browse You are an Odoo implementation expert working on the Odoo Project app   Your task is to come up with an enhancement to the Odoo source code that would insert the current number of project subtasks as a dyanamic tab label in the Task view as an addition to the current tab title Subtasks    Your approach should modify the template that defines the Subtasks tab identify the model and field that holds the subtasks count and modify the template file to include dynamic content in the tab title  Your result  should the required code changes to implement this enhancement ,"Browse Odoo implementation expert working Odoo Project app . task come enhancement Odoo source code would insert current number project sub-tasks dyanamic tab label Task view addition current tab title `` Sub-tasks '' . approach modify template defines `` Sub-tasks '' tab , identify model field holds sub-tasks count modify template file include dynamic content tab title . result required code changes implement enhancement ."
jeyarajcs,sqlmurdermysterydbFileA crime has taken place and the detective needs your help The detective gave you the crime scene report but you somehow lost it You vaguely remember that the crime was a murder that occurred sometime on Jan 15 2018 and that it took place in SQL City All the clues to this mystery are buried in a huge database and you need to use SQL to navigate through this vast network of information Your first step to solving the mystery is to retrieve the corresponding crime scene report from the police departments database Take a look at the cheatsheet to learn how to do this From there you can use your SQL skills to find the murderer,"sql-murder-mystery.dbFileA crime taken place detective needs help . detective gave crime scene report , somehow lost . vaguely remember crime murder occurred sometime Jan. 15 , 2018 took place SQL City . clues mystery buried huge database , need use SQL navigate vast network information . first step solving mystery retrieve corresponding crime scene report police department 's database . Take look cheatsheet learn ! , use SQL skills find murderer ."
matstep0,"I need to get voice control on chat gpt  the best is extension for opera  but desktop aplication will be good to  search internet find me a way 
","need get voice control chat gpt , best extension opera , desktop aplication good , search internet find way ."
DarkWarden85,"I have a raspberry pi with a Linux installation of home assistant
I have connected a usb device 
The device first has an identifier of devhidraw0
After some time and without me doing anything it changes to devhidraw1
Why does this happen How can I avoid it changing",raspberry pi Linux installation home assistant . connected usb device . device first identifier /dev/hidraw0 time without anything changes /dev/hidraw1 happen . avoid changing
CMCDragonkai,If I want to compile a library written in C as a shared object to bind into nodejs I can use tools like nodegyp to compile the object and subsequently load it into nodejs with a require call which uses the underlying processdlopen Lets suppose I wanted to create a second native binding like another library in C that needs to call a function exposed in the first library written in C How can expose the headers of the first library to the second library And would the function calls work when I eventually load the second object into nodejs,"want compile library written C shared object bind nodejs , use tools like node-gyp compile object subsequently load nodejs require call uses underlying ` process.dlopen ` . Let 's suppose wanted create second native binding , like another library C needs call function exposed first library written C. expose headers first library second library ? would function calls work eventually load second object nodejs ?"
simonw,"I want to embed a Python multiline string in a Jinja template

 rendermarkdown
 Data analysis with SQLite and Python

 

But I dont want to have to use  for every double quote",want embed Python multi-line string Jinja template : { { render_markdown ( `` '' '' # Data analysis SQLite Python '' '' '' ) } } n't want use \ '' every double quote
skorfmann,How much memory can WASM use in Chrome,much memory WASM use Chrome
purcell-lab,"emhassmasterzipZip Archiveunitloadcostforecasts and unitprodpriceforcecasts seem to being rounded to the nearest integer but they should have at least two decimal places  Can you see where the error is  Please look ino retreivehasspy

They still seem to be rounded to the nearest integer

 date 20230713 1700001000
unitloadcost 00
 date 20230713 1730001000
unitloadcost 00
 date 20230713 1800001000
unitloadcost 00
 date 20230713 1830001000
unitloadcost 00
 date 20230713 1900001000
unitloadcost 00
 date 20230713 1930001000
unitloadcost 00","emhass-master.zipZip Archiveunit_load_cost_forecasts unit_prod_price_forcecasts seem rounded nearest integer , least two decimal places . see error ? Please look ino retreive_hass.py still seem rounded nearest integer : - date : '2023-07-13 17:00:00+10:00' unit_load_cost : ' 0.0' - date : '2023-07-13 17:30:00+10:00' unit_load_cost : ' 0.0' - date : '2023-07-13 18:00:00+10:00' unit_load_cost : ' 0.0' - date : '2023-07-13 18:30:00+10:00' unit_load_cost : ' 0.0' - date : '2023-07-13 19:00:00+10:00' unit_load_cost : ' 0.0' - date : '2023-07-13 19:30:00+10:00' unit_load_cost : ' 0.0 '"
abrichr,Enumerate a hierarchy of actions that one takes when operating GUI desktop applications for typical daytoday tasks Consider different levels of abstractions Examples include clicking a button opening a window operating payroll software generating invoices renting an apartment,"Enumerate hierarchy actions one takes operating GUI desktop applications typical day-to-day tasks . Consider different levels abstractions . Examples include : clicking button , opening window , operating payroll software , generating invoices , renting apartment"
BirgerMoell,Figure out how to solve this github issue httpsgithubcomAntonOsikagptengineerissues294 by reviewing the code at this repo httpsgithubcomAntonOsikagptengineer,Figure solve github issue : https : //github.com/AntonOsika/gpt-engineer/issues/294 reviewing code repo : https : //github.com/AntonOsika/gpt-engineer
unjust,"traducir eso a portugues

Hola Muchas gracias por mandar estes cambios

Me parece que estan cambiando encima READMEmd en lugar de READMEptmd Los cambios de portugues README deberia estar en READMEptmd
httpsgithubcomLaboratoriabootcampblobmainprojects04mdlinksREADMEptmd

Por otro lado ahora tenemos cambios en progreso con un drafthttpsgithubcomLaboratoriabootcamppull1375 y con un issuehttpsgithubcomLaboratoriabootcampissues1371
 para aclarar los versiones o pasos de este proyecto Si puedes cambiar el READMEptmd puedo ver los cambios que estan proponiendo y ver si incorporamos al issue en camino o hacemos aparte","traducir eso portugues : Hola ! Muchas gracias por mandar estes cambios . parece que estan cambiando encima ` README.md ` en lugar de ` README.pt.md ` . Los cambios de portugues README deberia estar en ` README.pt.md ` . https : //github.com/Laboratoria/bootcamp/blob/main/projects/04-md-links/README.pt.md Por otro lado , ahora tenemos cambios en progreso con [ un draft ] ( https : //github.com/Laboratoria/bootcamp/pull/1375 ) [ con un issue ] ( https : //github.com/Laboratoria/bootcamp/issues/1371 ) para aclarar los versiones pasos de este proyecto . Si puedes cambiar el README.pt.md puedo ver los cambios que estan proponiendo ver si incorporamos al issue en camino hacemos aparte ."
joshuakarp,Using typescript give me a token bucket data structure that can be used to rate limit side effects,"Using typescript , give token bucket data structure used rate limit side effects ."
simonw,Using the Python ast module how can I access the docstring for a function,Using Python ast module access docstring function ?
cotton-alta,"SNS


ActivityPub",以下の特徴を持っているSNSを作ろうとしています。エレベーターピッチを作成してください。 ・すでに形成されたコミュニティに対して導入される ・アナウンス機能やイベント管理機能などのコミュニティ内の活動への参加ハードルを下げるための機能が提供される ・ActivityPubを利用して複数のコミュニティを緩く横断できる
flapbird1,"Look at the following function coming from a Kodi Python addon
It lists the videos found on a page and also looks for a next page and add an item to go to the next page with video
I want to add a filter so it only shows for example videos that have a runtime of more then 15 minutes
But doing that it could only show a few videos per page Because of that I want it to go by itself to the next page and do that until there are a minimum amount of 30 videos to display
Pressing next now it goes to the page next of where it finished when getting the 30 videos

So duration  15 minimal to display limit 30
open page 1  find 10 videos to display  go to page 2 by itself
open page 2 find 12 videos to display  go to page 3 by itself
open page 3 find 10 videos to display  we now have more then 30
add Next page item that goes to page 4

Code
 siteregister
def Listurl
    try
        listhtml  utilsgetHtmlurl 
    except
        return None
    match  recompilerbgblacka hrefimgssrcdiv classvideoDurddiv classvideoTtl titleredirectlink reDOTALL  reIGNORECASEfindalllisthtml
    for videopage img duration name nice in match
        nice   COLOR lime  nice  COLOR
        name  utilscleantextnametitle

        contexturl  utilsaddonsys  modecustomeroprofilebyCuminationLookupinfolistmodecustomeroprofilebyCuminationListurl  urllibparsequoteplusBASEURL  videopage
        contextmenu  
            
                COLOR deeppinkLookup infoCOLOR
                RunPlugin  contexturl  
            
        
         utilsnotifyNotify strcontexturl

        siteadddownloadlinkname  nice BASEURL  videopage Playvid img name  nice durationduration contextmcontextmenu

    nextp  recompileD2173searchlisthtml
    if nextp
        npurl  BASEURL  nextp1replaceamp 
         next page number
        np  intrecompiledD2173searchlisthtml1
         current page number
        cp  np  1
         last page number
        lp  recompilerdD2175searchlisthtml1
        nplptxt  Next Page   strcp      strlp  

        cmpage  utilsaddonsys  modecustomeroprofilebyCuminationGotoPagelistmodecustomeroprofilebyCuminationListurl  urllibparsequoteplusnpurl  np  strnp  lp  strlp
        cm  COLOR violetGoto Page COLOR RunPlugin  cmpage  
        siteadddirnplptxt npurl List siteimgnext contextmcm

    utilseod","Look following function , coming Kodi Python addon . lists videos found page , also looks next page , add item go next page video . want add filter shows example videos runtime 15 minutes . , could show videos per page . , want go next page , minimum amount 30 videos display . Pressing next , goes page next finished getting 30 videos . , duration > 15 , minimal display limit 30 open page 1 , find 10 videos display - > go page 2 open page 2 , find 12 videos display - > go page 3 open page 3 , find 10 videos display - > 30 add Next page item goes page 4 . Code : @ site.register ( ) def List ( url ) : try : listhtml = utils.getHtml ( url , `` ) except : return None match = re.compile ( r'bg-black '' > < href= '' ( [ ^ '' ] + ) .+ ? < img\s * src= '' ( [ ^ '' ] + ) .+ ? < div class= '' videoDur '' > ( [ : \d ] + ) .+ ? < div class= '' videoTtl '' title= '' ( [ ^ '' ] + ) . * ? redirect-link '' > ( [ ^ < ] + ) ' , re.DOTALL | re.IGNORECASE ) .findall ( listhtml ) videopage , img , duration , name , nice match : nice = `` [ COLOR lime ] [ `` + nice + `` ] [ /COLOR ] '' name = utils.cleantext ( name ) .title ( ) contexturl = ( utils.addon_sys + `` ? mode=custom_eroprofile_by_Cumination.Lookupinfo & list_mode=custom_eroprofile_by_Cumination.List & url= '' + urllib_parse.quote_plus ( BASE_URL + videopage ) ) contextmenu = [ ( ' [ COLOR deeppink ] Lookup info [ /COLOR ] ' , 'RunPlugin ( ' + contexturl + ' ) ' , ) ] # utils.notify ( 'Notify ' , str ( contexturl ) site.add_download_link ( name + nice , BASE_URL + videopage , 'Playvid ' , img , name + nice , duration=duration , contextm=contextmenu ) nextp = re.compile ( ' ( [ ^\ '' ] + ) \ '' \D * 21_73 ' ) .search ( listhtml ) nextp : npurl = BASE_URL + nextp [ 1 ] .replace ( ' & amp ; ' , ' & ' ) # next page number np = int ( re.compile ( ' ( \d+ ) \ '' \D * 21_73 ' ) .search ( listhtml ) [ 1 ] ) # current page number cp = np - 1 # last page number lp = re.compile ( r ' ( \d+ ) \ '' \D+21_75 ' ) .search ( listhtml ) [ 1 ] nplptxt = 'Next Page ( ' + str ( cp ) + ' / ' + str ( lp ) + ' ) ' cm_page = ( utils.addon_sys + `` ? mode=custom_eroprofile_by_Cumination.GotoPage & list_mode=custom_eroprofile_by_Cumination.List & url= '' + urllib_parse.quote_plus ( npurl ) + `` & np= '' + str ( np ) + `` & lp= '' + str ( lp ) ) cm = [ ( ' [ COLOR violet ] Goto Page # [ /COLOR ] ' , 'RunPlugin ( ' + cm_page + ' ) ' ) ] site.add_dir ( nplptxt , npurl , 'List ' , site.img_next , contextm=cm ) utils.eod ( )"
toshiki31,"

from linebot import LineBotApi
from linebotmodels import FlexSendMessage

import azurefunctions as func
import re
import urllibparse
import os

lineChannel  LineBotApiosenvironLINEBOTCHANNELTOKEN
lineBotId  urllibparsequoteosenvironLINEBOTID

def mainreq funcHttpRequest  funcHttpResponse
    payload  reqgetjson
    keys  payloadkeys

    if comment in keys
        
        if payloadcommentusertype  Bot
            return funcHttpResponsestatuscode200

        lineChannelbroadcast
            FlexSendMessage
                alttextIssue   strpayloadissuenumber  
                contentsgetFlexMessage
                    payloadissuetitle
                    payloadcommentbody
                    payloadissuenumber
                    payloadrepositoryfullname    strpayloadissuenumber
                    payloadcommentuserlogin
                    payloadcommenthtmlurl

                
            
        

    else
        lineChannelbroadcast
            FlexSendMessage
                alttextIssue   strpayloadissuenumber
                contentsgetFlexMessage
                    payloadissuetitle
                    payloadissuebody if payloadissuebody  None else 
                    payloadissuenumber
                    payloadrepositoryfullname    strpayloadissuenumber
                    payloadissueuserlogin
                    payloadissuehtmlurl
                
            
        
    
    return funcHttpResponsestatuscode200

 FlexMessage
def getFlexMessageissueTitle issueComment issueId repositoryId commentBy issueUrl
    comment  
    comments  issueCommentsplitlines
    for line in comments
        text  
        if rematch line
            textweight  bold
        line  resub   line
        line  resub   line
        texttype  text
        if line  
            texttext   
        else
            texttext  line
        commentappendtext

    json  
        type bubble
        body 
            type box
            layout vertical
            contents 
                
                    type box
                    layout horizontal
                    contents 
                        
                            type text
                            text issueTitle
                            size lg
                            weight bold
                            flex 8
                        
                        
                            type text
                            text   strissueId
                            size lg
                            flex 0
                        
                    
                
                
                    type text
                    text   commentBy
                
                
                    type box
                    layout vertical
                    contents comment
                    margin xl
                
                
                    type button
                    action 
                        type uri
                        label Issue
                        uri issueUrl
                    
                
                
                    type button
                    action 
                        type uri
                        label 
                        uri httpslinemeRoaMessage  lineBotId    IssueE381ABE8BF94E4BFA10D0A  urllibparsequoterepositoryId  0D0AE4BBA5E4B88BE381ABE382B3E383A1E383B3E383880D0A
                    
                
            
        
        footer 
            type box
            layout baseline
            contents 
                
                    type text
                    text repositoryId
                
            
        
        styles 
            body 
                separator False
            
        
    
    test
    return json
","以下のコードについて詳しく説明して下さい `` ` linebot import LineBotApi linebot.models import FlexSendMessage import azure.functions func import import urllib.parse import os lineChannel = LineBotApi ( os.environ [ `` LINE_BOT_CHANNEL_TOKEN '' ] ) lineBotId = urllib.parse.quote ( os.environ [ `` LINE_BOT_ID '' ] ) def main ( req : func.HttpRequest ) - > func.HttpResponse : payload = req.get_json ( ) keys = payload.keys ( ) `` comment '' keys : payload [ `` comment '' ] [ `` user '' ] [ `` type '' ] == `` Bot '' : return func.HttpResponse ( status_code=200 ) lineChannel.broadcast ( FlexSendMessage ( alt_text= '' Issue # '' + str ( payload [ `` issue '' ] [ `` number '' ] ) + `` に返信がありました '' , contents=getFlexMessage ( payload [ `` issue '' ] [ `` title '' ] , payload [ `` comment '' ] [ `` body '' ] , payload [ `` issue '' ] [ `` number '' ] , payload [ `` repository '' ] [ `` full_name '' ] + `` / '' + str ( payload [ `` issue '' ] [ `` number '' ] ) , payload [ `` comment '' ] [ `` user '' ] [ `` login '' ] , payload [ `` comment '' ] [ `` html_url '' ] ) ) ) else : lineChannel.broadcast ( FlexSendMessage ( alt_text= '' 新規Issueが立ちました # '' + str ( payload [ `` issue '' ] [ `` number '' ] ) , contents=getFlexMessage ( payload [ `` issue '' ] [ `` title '' ] , payload [ `` issue '' ] [ `` body '' ] payload [ `` issue '' ] [ `` body '' ] ! = None else `` コメントはありません '' , payload [ `` issue '' ] [ `` number '' ] , payload [ `` repository '' ] [ `` full_name '' ] + `` / '' + str ( payload [ `` issue '' ] [ `` number '' ] ) , payload [ `` issue '' ] [ `` user '' ] [ `` login '' ] , payload [ `` issue '' ] [ `` html_url '' ] ) ) ) return func.HttpResponse ( status_code=200 ) # FlexMessage用テンプレート def getFlexMessage ( issueTitle , issueComment , issueId , repositoryId , commentBy , issueUrl ) : comment = [ ] comments = issueComment.splitlines ( ) line comments : text = { } re.match ( `` # + '' , line ) : text [ `` weight '' ] = `` bold '' line = re.sub ( `` # + `` , `` '' , line ) line = re.sub ( `` - `` , `` ・ '' , line ) text [ `` type '' ] = `` text '' line == `` '' : text [ `` text '' ] = `` `` else : text [ `` text '' ] = line comment.append ( text ) json = { `` type '' : `` bubble '' , `` body '' : { `` type '' : `` box '' , `` layout '' : `` vertical '' , `` contents '' : [ { `` type '' : `` box '' , `` layout '' : `` horizontal '' , `` contents '' : [ { `` type '' : `` text '' , `` text '' : issueTitle , `` size '' : `` lg '' , `` weight '' : `` bold '' , `` flex '' : 8 } , { `` type '' : `` text '' , `` text '' : `` # '' + str ( issueId ) , `` size '' : `` lg '' , `` flex '' : 0 } ] } , { `` type '' : `` text '' , `` text '' : `` @ '' + commentBy } , { `` type '' : `` box '' , `` layout '' : `` vertical '' , `` contents '' : comment , `` margin '' : `` xl '' } , { `` type '' : `` button '' , `` action '' : { `` type '' : `` uri '' , `` label '' : `` Issueを見る '' , `` uri '' : issueUrl } } , { `` type '' : `` button '' , `` action '' : { `` type '' : `` uri '' , `` label '' : `` 返信する '' , `` uri '' : `` https : //line.me/R/oaMessage/ '' + lineBotId + `` / '' + `` Issue % E3 % 81 % AB % E8 % BF % 94 % E4 % BF % A1 % 0D % 0A '' + urllib.parse.quote ( repositoryId ) + `` % 0D % 0A -- % E4 % BB % A5 % E4 % B8 % 8B % E3 % 81 % AB % E3 % 82 % B3 % E3 % 83 % A1 % E3 % 83 % B3 % E3 % 83 % 88 -- % 0D % 0A '' } } ] } , `` footer '' : { `` type '' : `` box '' , `` layout '' : `` baseline '' , `` contents '' : [ { `` type '' : `` text '' , `` text '' : repositoryId } ] } , `` styles '' : { `` body '' : { `` separator '' : False } } } # test return json `` `"
gglusman,What drugs may treat Alternating Hemiplegia of Childhood AHC,drugs may treat Alternating Hemiplegia Childhood ( AHC ) ?
jbellis,"twotxtDocumentonetxtDocumentI want you to add the build and query times in these two files and tell me the ratio of the total time in one compared to the total time in two  

The first line in each file is a header and can be ignored

Start by looking at the data then write a function that returns the sum of the times in a single file

Then apply this function to each file and show me the ratio","two.txtDocumentone.txtDocumentI want add build query times two files , tell ratio total time one compared total time two . first line file header ignored . Start looking data , write function returns sum times single file . apply function file show ratio ."
muninnhugin,"what do you think the problem is here this error occurs after running docker compose up for a jekyll project


hflasite   jekyll 392  Error  Permission denied  dirsmkdir  srvjekyllsite
hflasite   usrlocallibruby270fileutilsrb250in mkdir Permission denied  dirsmkdir  srvjekyllsite ErrnoEACCES
hflasite      from usrlocallibruby270fileutilsrb250in fumkdir
hflasite      from usrlocallibruby270fileutilsrb228in block 2 levels in mkdirp
hflasite      from usrlocallibruby270fileutilsrb226in reverseeach
hflasite      from usrlocallibruby270fileutilsrb226in block in mkdirp
hflasite      from usrlocallibruby270fileutilsrb211in each
hflasite      from usrlocallibruby270fileutilsrb211in mkdirp
hflasite      from usrgemgemsjekyll392libjekyllconvertiblerb226in write
hflasite      from usrgemgemsjekyll392libjekyllsiterb209in block in write
hflasite      from usrgemgemsjekyll392libjekyllsiterb332in block 2 levels in eachsitefile
hflasite      from usrgemgemsjekyll392libjekyllsiterb331in each
hflasite      from usrgemgemsjekyll392libjekyllsiterb331in block in eachsitefile
hflasite      from usrgemgemsjekyll392libjekyllsiterb330in each
hflasite      from usrgemgemsjekyll392libjekyllsiterb330in eachsitefile
hflasite      from usrgemgemsjekyll392libjekyllsiterb208in write
hflasite      from usrgemgemsjekyll392libjekyllsiterb73in process
hflasite      from usrgemgemsjekyll392libjekyllcommandrb28in processsite
hflasite      from usrgemgemsjekyll392libjekyllcommandsbuildrb65in build
hflasite      from usrgemgemsjekyll392libjekyllcommandsbuildrb36in process
hflasite      from usrgemgemsjekyll392libjekyllcommandsserverb93in block in start
hflasite      from usrgemgemsjekyll392libjekyllcommandsserverb93in each
hflasite      from usrgemgemsjekyll392libjekyllcommandsserverb93in start
hflasite      from usrgemgemsjekyll392libjekyllcommandsserverb75in block 2 levels in initwithprogram
hflasite      from usrgemgemsmercenary036libmercenarycommandrb220in block in execute
hflasite      from usrgemgemsmercenary036libmercenarycommandrb220in each
hflasite      from usrgemgemsmercenary036libmercenarycommandrb220in execute
hflasite      from usrgemgemsmercenary036libmercenaryprogramrb42in go
hflasite      from usrgemgemsmercenary036libmercenaryrb19in program
hflasite      from usrgemgemsjekyll392exejekyll15in top required
hflasite      from usrgembinjekyll25in load
hflasite      from usrgembinjekyll25in main
hflasite exited with code 1",think problem ? error occurs running ` docker compose ` jekyll project hfla_site | jekyll 3.9.2 | Error : Permission denied @ dir_s_mkdir - /srv/jekyll/_site hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:250 : ` mkdir ' : Permission denied @ dir_s_mkdir - /srv/jekyll/_site ( Errno : :EACCES ) hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:250 : ` fu_mkdir' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:228 : ` block ( 2 levels ) mkdir_p' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:226 : ` reverse_each' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:226 : ` block mkdir_p' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:211 : ` each' hfla_site | /usr/local/lib/ruby/2.7.0/fileutils.rb:211 : ` mkdir_p' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/convertible.rb:226 : ` write' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:209 : ` block write' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:332 : ` block ( 2 levels ) each_site_file' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:331 : ` each' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:331 : ` block each_site_file' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:330 : ` each' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:330 : ` each_site_file' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:208 : ` write' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/site.rb:73 : ` process' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/command.rb:28 : ` process_site' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/build.rb:65 : ` build' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/build.rb:36 : ` process' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:93 : ` block start' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:93 : ` each' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:93 : ` start' hfla_site | /usr/gem/gems/jekyll-3.9.2/lib/jekyll/commands/serve.rb:75 : ` block ( 2 levels ) init_with_program' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/command.rb:220 : ` block execute' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/command.rb:220 : ` each' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/command.rb:220 : ` execute' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary/program.rb:42 : ` go' hfla_site | /usr/gem/gems/mercenary-0.3.6/lib/mercenary.rb:19 : ` program' hfla_site | /usr/gem/gems/jekyll-3.9.2/exe/jekyll:15 : ` < top ( required ) > ' hfla_site | /usr/gem/bin/jekyll:25 : ` load' hfla_site | /usr/gem/bin/jekyll:25 : ` < main > ' hfla_site exited code 1
simonw,"Create a Python list of 100 random floats between 0 and 1

Turn that into a binary string using structpackf  100 values

Compare the length of that binary string that binary string in hexadecimal encoding and that binary string encoded with base64","Create Python list 100 random floats 0 1 Turn binary string using struct.pack ( `` f '' * 100 , * values ) Compare length binary string , binary string hexadecimal encoding binary string encoded base64"
simonw,"Heres a regular expression from PEP 263  tfcoding tazAZ09

Write a function called readfilepath  it opens that file using encodingutf8 errorsignore and reads the first 512 bytes Then it splits that text on newlines to get just the first to lines and runs that regular expression against  them to find the encoding  If the encoding is missing it assumes utf8

Finally it reads the entire file using the detected encoding and returns it","'s regular expression PEP 263 : ^ [ \t\f ] * # . * ? coding [ : = ] [ \t ] * ( [ -_.a-zA-Z0-9 ] + ) Write function called read_file ( path ) : - opens file using encoding= '' utf-8 '' , errors= '' ignore '' reads first 512 bytes . splits text newlines get first lines , runs regular expression find encoding . encoding missing assumes utf-8 . Finally reads entire file using detected encoding returns"
CMCDragonkai,If I want to compile a library written in C as a shared object to bind into nodejs I can use tools like nodegyp to compile the object and subsequently load it into nodejs with a require call which uses the underlying processdlopen Lets suppose I wanted to create a second native binding like another library in C that needs to call a function exposed in the first library written in C How can expose the headers of the first library to the second library And would the function calls work when I eventually load the second object into nodejs,"want compile library written C shared object bind nodejs , use tools like node-gyp compile object subsequently load nodejs require call uses underlying ` process.dlopen ` . Let 's suppose wanted create second native binding , like another library C needs call function exposed first library written C. expose headers first library second library ? would function calls work eventually load second object nodejs ?"
colonelpanic8,"This code is used to make a scaler that can take values from a known data range to the interval between 0 and 1

class ManualLinearScaler

    def initself datamin00 datamax10
        selfdatamin  datamin
        selfdatamax  datamax
        selfdatarange  selfdatamax  selfdatamin

    def scaleself value
        return value  selfdatamin  selfdatarange

Id like to change it so that it scales values to an optionally user specified as arguments in the constructor range","code used make scaler take values known data range interval 0 1 : class ManualLinearScaler : def __init__ ( self , data_min=0.0 , data_max=1.0 ) : self._data_min = data_min self._data_max = data_max self._data_range = self._data_max - self._data_min def scale ( self , value ) : return ( value - self._data_min ) / ( self._data_range ) 'd like change scales values optionally user specified ( arguments constructor ) range"
take-i,,こんばんわ。今週の仕事が終わりました。少し疲れて寝てしまい、１時間ほど前に起きました。
AnanyaV2004,"1 Which of the following gates gives 1 as the output only when its inputs are 0 only
 a NAND
 b XOR
 c XNOR
 d NOR
explain every option as to why it is correct or wrong ",1 . following gates gives 1 output inputs 0 ? : NAND b : XOR c : XNOR : explain every option correct wrong
vegidio,In Kotlin whats the difference between Synchronized and synchronized,"Kotlin , 's difference ` @ Synchronized ` ` synchronized ` ?"
AntonOsika,There is a paper about Tree of Thoughts prompting using LLMs that I want to know how to use   There is also a github repo  Allow yourself to analyze all the information step by step thay you can find about this topic and then lets discuss its practical use for using it in a prompting situation like this one  And thanks,paper Tree Thoughts prompting using LLMs want know use . also github repo . Allow analyze information step step thay find topic let 's discuss practical use using prompting situation like one . thanks .
rknightion,"What does the following panic mean from my terraform provider

20230621T1712250310100 DEBUG providerterraformprovideruptrendsv023 panic interface conversion interface  is nil not mapstringinterface ","following panic mean terraform provider 2023-06-21T17:12:25.031+0100 [ DEBUG ] provider.terraform-provider-uptrends_v0.2.3 : panic : interface conversion : interface { } nil , map [ string ] interface { }"
AnanyaV2004,"1 In inverter circuits what would be a preferred load
 a Resistor
 b MOSFET
 c Both
 d None of the above

give explanation for each option why it is correct or wrong without disclosing the correct answer in the explanations of the wrong options",1 . inverter circuits would preferred load ? : Resistor b : MOSFET c : : None give explanation option correct wrong without disclosing correct answer explanations wrong options
buttercutter,"import jax
import jaxnumpy as jnp
from jaxtreeutil import treemapwithpath DictKey SequenceKey

from constants import LORAFREEZE LORAFULL
from transform import EmptyNode LoraNode customtreemap

def initloraparamtree spec rng stddev001 dtypejnpfloat32 alpha1 isleafNone
    def freezegetterparam specval
        if specval  LORAFULL
            return EmptyNode
        return param

    def tunegetterpath param specval
        if specval  LORAFREEZE
            return EmptyNode
        if specval  LORAFULL
            return param

        if lenparamshape  1
            raise ValueErrorfVectors must either be frozen or fully tuned but got spec value spec for param with path path
        if lenparamshape  2
            bdim adim  paramshape

            printfbdim bdim adim adim specval specval
            b  jnpzerosbdim specval dtypeparamdtype
            a  jaxrandomnormalrng specval adim dtypeparamdtype  stddev
            return LoraNodea b alphaalpha

         conv case
        windowshape inchannels outchannels  paramshape

        a  jnpzeros
            1 for  in rangelenwindowshape
            specval
            outchannels
         dtypeparamdtype
        b  jaxrandomnormalrng windowshape inchannels specval dtypeparamdtype  stddev
        return LoraNodea b alphaalpha

    return 
        jaxtreemapfreezegetter paramtree spec isleafisleaf
        jaxtreeutiltreemapwithpathtunegetter paramtree spec isleafisleaf
    

Tell me more about the code","import jax import jax.numpy jnp jax.tree_util import tree_map_with_path , DictKey , SequenceKey .constants import LORA_FREEZE , LORA_FULL .transform import EmptyNode , LoraNode , custom_tree_map def init_lora ( param_tree , spec , rng , stddev=0.01 , dtype=jnp.float32 , alpha=1. , is_leaf=None ) : def freeze_getter ( param , spec_val ) : spec_val == LORA_FULL : return EmptyNode return param def tune_getter ( path , param , spec_val ) : spec_val == LORA_FREEZE : return EmptyNode spec_val == LORA_FULL : return param len ( param.shape ) == 1 : raise ValueError ( f'Vectors must either frozen fully tuned , got spec value { spec } param path { path } ' ) len ( param.shape ) == 2 : b_dim , a_dim = param.shape print ( f'b_dim : { b_dim } , a_dim : { a_dim } , spec_val : { spec_val } ' ) b = jnp.zeros ( ( b_dim , spec_val ) , dtype=param.dtype ) = jax.random.normal ( rng , ( spec_val , a_dim ) , dtype=param.dtype ) * stddev return LoraNode ( , b , alpha=alpha ) # conv case * window_shape , in_channels , out_channels = param.shape = jnp.zeros ( ( * ( 1 _ range ( len ( window_shape ) ) ) , spec_val , out_channels ) , dtype=param.dtype ) b = jax.random.normal ( rng , ( * window_shape , in_channels , spec_val ) , dtype=param.dtype ) * stddev return LoraNode ( , b , alpha=alpha ) return ( jax.tree_map ( freeze_getter , param_tree , spec , is_leaf=is_leaf ) , jax.tree_util.tree_map_with_path ( tune_getter , param_tree , spec , is_leaf=is_leaf ) ) Tell code"
aesculus,How do I fix this python error No module named bs4,fix python error : module named 'bs4 '
UltimoDragao,"I want us to engage into solving a bug rfindImpl is not a function make a big search online its related to whats app apis its causing comunication trouble to people in all the world cause its a problem to send whatsapp messages and buttons its related to puppeteer and whatsappwebjs and venom 

here are somne usefull links

httpsgithubcomorkestralvenomissues2435

httpsgithubcompedroslopezwhatsappwebjsissues2386
 
take all time needed to fill as much as 90 of your capacity of holding data and context
","want us engage solving bug : `` r.findImpl function '' , make big search online , related whats app apis , causing comunication trouble people world cause , problem send whatsapp messages buttons , related puppeteer whatsapp-web.js venom somne usefull links https : //github.com/orkestral/venom/issues/2435 https : //github.com/pedroslopez/whatsapp-web.js/issues/2386 take time needed fill much 90 % capacity holding data context"
jhpoelen,Unknown,Unknown
holmesworcester,"Right now I got stuck on accessing files on Android
Im using httpswwwnpmjscompackagereactnativedocumentpicker which opens native file explorer and allows to choose one or multiple files It then returns the information about those files including URI URI on Android is returned in a form of content

This works fine The problem begins with accessing the file reading

0704 150903050 21232 21351 W Systemerr javalangSecurityException Permission Denial reading comandroidprovidersmediaMediaDocumentsProvider uri contentcomandroidprovidersmediadocumentsdocumentdocument1000003887 from pid21232 uid10403 requires that you obtain access using ACTIONOPENDOCUMENT or related APIs
I added usespermission androidnameandroidpermissionREADEXTERNALSTORAGE and WRITEEXTERNALSTORAGE and MANAGEEXTERNALSTORAGE just in case to AndroidManifest but that did not work
I also added androidrequestLegacyExternalStoragetrue though it should not work anymore according to docs
I think thats because Android requires runtime permissions for some actions since SDK version 23 httpsreactnativedevdocspermissionsandroidhtml
I see that list of Permissions that require prompting the user includes READEXTERNALSTORAGE
Ive tried their snippet however right now instead of prompt asking about permission Im getting in the logs information that I just dont have permission to access storage
I also dont have any permissions listed in apps settings

This is what Ive looked at and other
itinancereactnativefs395
RonRadtkereactnativeblobutil118
itinancereactnativefs676
itinancereactnativefs756 comment

For a moment I thought that the problem lies in Scoped Storage but I consulted Wiktor and its probably not the case httpsblognotesnookcomscopedstorageinreactnative
","Right got stuck accessing files Android . 'm using https : //www.npmjs.com/package/react-native-document-picker opens native file explorer allows choose one multiple files . returns information files , including URI . URI Android returned form `` content : // '' . works fine . problem begins accessing file ( reading ) : 07-04 15:09:03.050 21232 21351 W System.err : java.lang.SecurityException : Permission Denial : reading com.android.providers.media.MediaDocumentsProvider uri content : //com.android.providers.media.documents/document/document:1000003887 pid=21232 , uid=10403 requires obtain access using ACTION_OPEN_DOCUMENT related APIs added < uses-permission android : name= '' android.permission.READ_EXTERNAL_STORAGE '' / > ( WRITE_EXTERNAL_STORAGE , MANAGE_EXTERNAL_STORAGE case ) AndroidManifest work . also added android : requestLegacyExternalStorage= '' true '' ( though work anymore according docs ) . think 's Android requires runtime permissions actions since SDK version 23 : https : //reactnative.dev/docs/permissionsandroid.html see list `` Permissions require prompting user '' includes READ_EXTERNAL_STORAGE . 've tried snippet , however right instead prompt asking permission 'm getting ( logs ) information n't permission access storage . also n't permissions listed app 's settings . 've looked ( ) : itinance/react-native-fs # 395 RonRadtke/react-native-blob-util # 118 itinance/react-native-fs # 676 itinance/react-native-fs # 756 ( comment ) moment thought problem lies Scoped Storage consulted Wiktor 's probably case : https : //blog.notesnook.com/scoped-storage-in-react-native/"
yuryalencar,"I want us to engage into solving a bug rfindImpl is not a function make a big search online its related to whats app apis its causing comunication trouble to people in all the world cause its a problem to send whatsapp messages and buttons its related to puppeteer and whatsappwebjs and venom 

here are somne usefull links

httpsgithubcomorkestralvenomissues2435

httpsgithubcompedroslopezwhatsappwebjsissues2386
 
take all time needed to fill as much as 90 of your capacity of holding data and context
","want us engage solving bug : `` r.findImpl function '' , make big search online , related whats app apis , causing comunication trouble people world cause , problem send whatsapp messages buttons , related puppeteer whatsapp-web.js venom somne usefull links https : //github.com/orkestral/venom/issues/2435 https : //github.com/pedroslopez/whatsapp-web.js/issues/2386 take time needed fill much 90 % capacity holding data context"
Hiroshiba,Unknown,Unknown
tegefaulkes,If I start a socket sending binary data on a OS running on a little endian system And on the other side is a socket receiving the binary data on a OS running on a big endian system Will this work Or does there need to be some endianness conversion,start socket sending binary data OS running little endian system . side socket receiving binary data OS running big endian system . work ? need endianness conversion ?
eric-czech,"A list of records will be provided from an ontology of disease terms Each record will contain information describing a single term

Assign a precision label to each of these terms that captures the extent to which they correspond to patient populations with distinguishing clinical demographic physiological or molecular characteristics Use exactly one of the following values for this label

 high High precision terms have the greatest ontological specificity sometimes but not necessarily correspond to small groups of relatively homogeneous patients often have greater diagnostic certainty and typically represent the forefront of clinical practice
 medium Medium precision terms are the ontological ancestors of high precision terms if any are known often include indications in later stage clinical trials and generally reflect groups of patients assumed to be suffering from a condition with a shared or at least similar physiological or environmental origin
 low Low precision terms are the ontological ancestors of both medium and high precision terms group collections of diseases with some shared characteristics and typically connote a relatively heterogenous patient population They are often terms used within the ontology for organizational purposes

The records provided will already have the following fields

 id A string identifier for the term
 label A descriptive name for the term
 description A longer possibly truncated description of what the term is may be NA ie absent

Here is a list of such records in YAML format where the precision label is already assigned for 3 examples at each level of precision

 BEGIN EXAMPLES 
 id EFO1000639
  label acquired metabolic disease
  definition A disease of metabolism that has materialbasisin enzyme deficiency or accumulation of enzymes or toxins which interfere with normal function due to an endocrine organ disease organ malfunction inadequate intake dietary deficiency or 
  precision low
 id Orphanet68336
  label Rare genetic tumor
  definition NA
  precision low
 id EFO0005548
  label developmental disorder of mental health
  definition A disease of mental health that occur during a childs developmental period between birth and age 18 resulting in retarding of the childs
  precision low
 id EFO0005548
  label inflammatory bowel disease
  definition A spectrum of small and large bowel inflammatory diseases of unknown etiology It includes Crohns disease ulcerative colitis and colitis of indeterminate type
  precision medium
 id EFO0000384
  label Crohns disease
  definition A gastrointestinal disorder characterized by chronic inflammation involving all layers of the intestinal wall noncaseating granulomas affecting the intestinal wall and regional lymph nodes and transmural fibrosis Crohn disease most 
  precision medium
 id MONDO0045020
  label glycine metabolism disease
  definition A disease that has its basis in the disruption of glycine metabolic process
  precision medium
 id EFO1000277
  label Gastric Small Cell Neuroendocrine Carcinoma
  definition An aggressive highgrade and poorly differentiated carcinoma with neuroendocrine differentiation that arises from the stomach It is characterized by the presence of malignant small cells
  precision high
 id MONDO0015634
  label isolated osteopoikilosis
  definition A osteopoikilosis disease that is not part of a larger syndrome
  precision high
 id Orphanet98755
  label Spinocerebellar ataxia type 1
  definition Spinocerebellar ataxia type 1 SCA1 is a subtype of type I autosomal dominant cerebellar ataxia ADCA type I see this term characterized by dysarthria writing difficulties limb ataxia and commonly nystagmus and saccadic abnormalities
  precision high
 END EXAMPLES 

Here are the records for which this precision label is not yet known

 BEGIN RECORDS 
 id MONDO0014498
  label familial cold autoinflammatory syndrome 4
  definition Any familial cold autoinflammatory syndrome in which the cause of the disease is a mutation in the NLRC4 gene
 id EFO0009011
  label Arteritis
  definition An inflammatory process affecting an artery
 id MONDO0024239
  label congenital anomaly of cardiovascular system
  definition A disease that has its basis in the disruption of cardiovascular system development
 END RECORDS 

Requirements

 Assign a precision label for ALL records
 Respond in CSV format using a pipe ie  delimiter with the headers id precision where id is the id associated with each record
 Include the headers in the result 
 Respond with ONLY the CSV content do not include explanation of any kind

CSV","list records provided ontology disease terms . record contain information describing single term . Assign ` precision ` label terms captures extent correspond patient populations distinguishing clinical , demographic , physiological molecular characteristics . Use exactly one following values label : - ` high ` : High precision terms greatest ontological specificity , sometimes ( necessarily ) correspond small groups relatively homogeneous patients , often greater diagnostic certainty typically represent forefront clinical practice . - ` medium ` : Medium precision terms ontological ancestors ` high ` precision terms ( known ) , often include indications later stage clinical trials generally reflect groups patients assumed suffering condition shared , least similar , physiological environmental origin . - ` low ` : Low precision terms ontological ancestors ` medium ` ` high ` precision terms , group collections diseases * * shared characteristics typically connote relatively heterogenous patient population . often terms used within ontology organizational purposes . records provided already following fields : - ` id ` : string identifier term - ` label ` : descriptive name term - ` description ` : longer , possibly truncated description term ; may NA ( i.e . absent ) list records ( YAML format ) ` precision ` label already assigned 3 examples level precision : -- - BEGIN EXAMPLES -- - - id : EFO:1000639 label : acquired metabolic disease definition : disease metabolism _material_basis_in enzyme deficiency accumulation enzymes toxins interfere normal function due endocrine organ disease , organ malfunction , inadequate intake , dietary deficiency , ... precision : low - id : Orphanet:68336 label : Rare genetic tumor definition : NA precision : low - id : EFO:0005548 label : developmental disorder mental health definition : disease mental health occur child ’ developmental period birth age 18 resulting retarding child ’ precision : low - id : EFO:0005548 label : inflammatory bowel disease definition : spectrum small large bowel inflammatory diseases unknown etiology . includes Crohn 's disease , ulcerative colitis , colitis indeterminate type . precision : medium - id : EFO:0000384 label : Crohn 's disease definition : gastrointestinal disorder characterized chronic inflammation involving layers intestinal wall , noncaseating granulomas affecting intestinal wall regional lymph nodes , transmural fibrosis . Crohn disease ... precision : medium - id : MONDO:0045020 label : glycine metabolism disease definition : disease basis disruption glycine metabolic process . precision : medium - id : EFO:1000277 label : Gastric Small Cell Neuroendocrine Carcinoma definition : aggressive , high-grade poorly differentiated carcinoma neuroendocrine differentiation arises stomach . characterized presence malignant small cells . precision : high - id : MONDO:0015634 label : isolated osteopoikilosis definition : osteopoikilosis ( disease ) part larger syndrome . precision : high - id : Orphanet:98755 label : Spinocerebellar ataxia type 1 definition : Spinocerebellar ataxia type 1 ( SCA1 ) subtype type autosomal dominant cerebellar ataxia ( ADCA type ; see term ) characterized dysarthria , writing difficulties , limb ataxia , commonly nystagmus saccadic abnormalities . precision : high -- - END EXAMPLES -- - records ` precision ` label yet known : -- - BEGIN RECORDS -- - - id : MONDO:0014498 label : familial cold autoinflammatory syndrome 4 definition : familial cold autoinflammatory syndrome cause disease mutation NLRC4 gene . - id : EFO:0009011 label : Arteritis definition : inflammatory process affecting artery . - id : MONDO:0024239 label : congenital anomaly cardiovascular system definition : disease basis disruption cardiovascular system development . -- - END RECORDS -- - Requirements : - Assign ` precision ` label records - Respond CSV format using pipe ( i.e . `` | '' ) delimiter headers ` id ` , ` precision ` ` id ` ` id ` associated record - Include headers result - Respond CSV content , include explanation kind CSV :"
sync-by-unito,"For iPhone 6 4K 30 FPS I got new data
7 seconds video uses 408MB 4 seconds video uses 195 3 seconds video uses 192 MB

Calculate for iPhone 6 4K 30 FPS how long I should record a video to get 15 30 45 50 55 and 60 MB video file

Show result in table","iPhone 6+ ( 4K 30 FPS ) got new data . 7 seconds video uses 40.8MB , 4 seconds video uses 19.5 , 3 seconds video uses 19.2 MB . Calculate iPhone 6+ ( 4K 30 FPS ) : long record video get 15 , 30 , 45 , 50 , 55 60 MB video file . Show result table ."
fuhrmanator,"Pourriezvous expliquer la ligne de commande suivante excute en git bash sur Windows
MSYSNOPATHCONV1 docker run rm it v cygpath w pwdrepo gitinspector f tspumlplantumlmd m r T w repo F html  myresultshtml","Pourriez-vous expliquer la ligne de commande suivante exécutée en git bash sur Windows ? MSYS_NO_PATHCONV=1 docker run -- rm -it -v `` $ ( cygpath -w `` $ ( pwd ) '' ) : /repo '' gitinspector -f ts , puml , plantuml , md -m -r -T -w /repo -F html > myresults.html"
L-M-Sherlock,"You are a professional explainer tutor and writer Im plan to rewrite the tutorial of FSRS Here are some useful resources

The original version httpsgithubcomopenspacedrepetitionfsrs4ankireadme

The version by Expertium httpsgithubcomExpertiumfsrs4ankitreemainreadme

The version by user1823 httpsgithubcomuser1823fsrs4ankitreemainreadme

The voting and discussion about the tutorials httpswwwredditcomrAnkicomments15rmp13letsletthecommunitydecidewhichguidetofsrs

Please read all resources and provide a userfriendly tutorial outline You should consider the suggestion and opinion from the community Lets think step by step","professional explainer , tutor writer . 'm plan rewrite tutorial FSRS . useful resources : original version : https : //github.com/open-spaced-repetition/fsrs4anki # readme version Expertium : https : //github.com/Expertium/fsrs4anki/tree/main # readme version user1823 : https : //github.com/user1823/fsrs4anki/tree/main # readme voting discussion tutorials : https : //www.reddit.com/r/Anki/comments/15rmp13/lets_let_the_community_decide_which_guide_to_fsrs/ Please read resources , provide user-friendly tutorial outline . consider suggestion opinion community . Let 's think step step ."
vbextreme,Is immature tool written by noobs for noobs  offending,`` immature tool written noobs noobs `` offending
StefanSalewski,"Someone wrote a blog post about the Nim programming language
Please list the grammar and spelling errors for the following text segment Show the correction and explain what is wrong Do not print the full text only show the mistakes and your corrections

Teaching old C code new tricks with Nim
8th September 2023  Guide  Nim  Programming

Recently I was met with an interesting problem when wrapping a C library in Nim The library in question was MAPM an older but quite complete library for dealing with arbitrary precision maths Unfortunately the library doesnt have much in the way of error handling If something goes wrong it almost always writes to stderr and returns the number 0 And to be fair there isnt a whole lot that can go wrong in this library Pretty much every error scenario is bad input to functions like trying to divide by 0 or trying to get trigonometry results for impossible angles However in the case where mallocrealloc isnt able to allocate more data then it writes to stderr and then calls exit100 This sounds pretty terrible but as the author points out the alternative isnt great either and there are ways to work around it I do wish that the author had opted to use error flags like many of the C standard library functions this way itd be easier to deal with these errors but alas

So what do we do I could add range checks to all inputs in my wrapper which works but isnt great for performance I could of course disable these when the user compiles with ddanger like the Nim compiler itself does But this still doesnt feel like a great solution And besides MAPM does all these checks itself so wed be checking everything twice Initially I wondered if it would be possible to read from the programs own stderr or to replace stderr with a stream we could read from before calling MAPM functions and swap it back afterwards But this seemed like a lot of hassle for quite small benefit
The solution old C tricks

Luckily the library performs all this error handling with an internal function called Mapmlogerrormsg This function takes two arguments one which decides if its a fatal error and exit100 should be called and the other which contains the message to display And as it turns out ld the GNU linker which ships with gcc has an option called wrap and has this to say about it in the documentation","Someone wrote blog post Nim programming language . Please list grammar spelling errors following text segment . Show correction , explain wrong : ( print full text , show mistakes corrections . ) Teaching old C code new tricks Nim 8th September 2023 - Guide , Nim , Programming Recently met interesting problem wrapping C library Nim . library question MAPM , older quite complete library dealing arbitrary precision maths . Unfortunately library ’ much way error handling . something goes wrong almost always writes stderr returns number 0 . fair , ’ whole lot go wrong library . Pretty much every error scenario bad input functions like trying divide 0 trying get trigonometry results impossible angles . However case malloc/realloc ’ able allocate data writes stderr calls exit ( 100 ) . sounds pretty terrible , author points alternative ’ great either , ways work around . wish author opted use error flags like many C standard library functions , way ’ easier deal errors , alas . ? could add range checks inputs wrapper , works , ’ great performance . could course disable user compiles -d : danger like Nim compiler . still ’ feel like great solution . besides , MAPM checks , ’ checking everything twice ! Initially wondered would possible read programs stderr , replace stderr stream could read calling MAPM functions swap back afterwards . seemed like lot hassle quite small benefit . solution : old C tricks Luckily library performs error handling internal function called M_apm_log_error_msg . function takes two arguments , one decides ’ fatal error exit ( 100 ) called , contains message display . turns ld , GNU linker ships gcc , option called -- wrap say documentation :"
xexyl,Identify the quote My precious Yes my precious ,"Identify quote : precious . Yes , precious ."
aesculus,"Using docker compose I get the following using docker container inspect

Dns  DnsOptions  DnsSearch 

However the container created this way cannot talk to the internet When I create the container individually via a QNAP GUI I get the following using docker container inspect

Dns null DnsOptions null DnsSearch null

Not sure how an empty set  is different than a null but perhaps its a nuance Nor do I know where I can change the one built by compose so it is also null","Using docker compose get following ( using docker container inspect ) : '' Dns '' : [ ] , `` DnsOptions '' : [ ] , `` DnsSearch '' : [ ] , However , container created way talk internet . create container individually via QNAP GUI , get following ( using docker container inspect ) : '' Dns '' : null , `` DnsOptions '' : null , `` DnsSearch '' : null , sure empty set [ ] different null , perhaps 's nuance . know change one built compose also null ."
joshuakarp,In Linux when you attach an ethernet cable to machine you get a new ethernet interface In this interface you can assign an IP address Is it possible for there to be more than 1 IP address for a single interface,"Linux , attach ethernet cable machine , get new ethernet interface . interface , assign IP address . possible 1 IP address single interface ?"
nitzantomer,I wish that in typescript I could mark a function as throws and then when calling that function there is a build error or warning that says there is an unhandled exception Are there any packages in node or native typescript that could accomplish this,"wish typescript could mark function `` throws '' calling function , build error ( warning ) says unhandled exception . packages node ( native typescript ) could accomplish ?"
